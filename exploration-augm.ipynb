{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5', '1', '4', '3', '6', '2']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir('own_dataset/1d6/train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path= ('own_dataset/1d6/train')\n",
    "test_path= ('own_dataset/1d6/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4254 images belonging to 6 classes.\n",
      "Found 834 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size_train=40  #,batch_size= batch_size_train\n",
    "batch_size_valid=40\n",
    "targetsize= 64\n",
    "datagen=ImageDataGenerator(rotation_range=180,height_shift_range=0.1,rescale=1.0/255.0\n",
    "                           ,zoom_range=[0.7,1.1],brightness_range=[0.4,1.2])\n",
    "train_batches= datagen.flow_from_directory(train_path, target_size=(targetsize,targetsize), shuffle=True,\n",
    "                                                                      classes=['5', '1', '4', '3', '6', '2'],\n",
    "                                                                      batch_size= batch_size_train)\n",
    "test_batches= datagen.flow_from_directory(test_path,  target_size=(targetsize,targetsize), shuffle=True,\n",
    "                                                                     classes=['5', '1', '4', '3', '6', '2'],\n",
    "                                                                     batch_size= batch_size_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(ims, figsize=(20,10), rows=1, interp= False, titles= None):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims= ims.transpose((0,1,2,3))\n",
    "    f= plt.figure(figsize=figsize)\n",
    "    cols= len(ims)//rows if len(ims) %2 == 0 else len(ims)//rows + 1\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=12)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "from tensorflow.keras.models import model_from_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = tf.keras.callbacks.LearningRateScheduler(lambda x: 5e-4 *0.99**x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 12294     \n",
      "=================================================================\n",
      "Total params: 1,580,870\n",
      "Trainable params: 1,580,870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(targetsize,targetsize, 3)) )\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), padding='SAME', activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding='SAME', activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding='SAME', activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding='SAME', activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-a5f70e991a29>:2: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/500\n",
      "107/107 [==============================] - 110s 1s/step - loss: 1.7917 - accuracy: 0.1824 - val_loss: 1.7890 - val_accuracy: 0.1882 - lr: 5.0000e-04\n",
      "Epoch 2/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.7894 - accuracy: 0.1869 - val_loss: 1.7880 - val_accuracy: 0.1918 - lr: 4.9500e-04\n",
      "Epoch 3/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.7899 - accuracy: 0.1866 - val_loss: 1.7893 - val_accuracy: 0.1871 - lr: 4.9005e-04\n",
      "Epoch 4/500\n",
      "107/107 [==============================] - 110s 1s/step - loss: 1.7875 - accuracy: 0.1944 - val_loss: 1.7769 - val_accuracy: 0.2026 - lr: 4.8515e-04\n",
      "Epoch 5/500\n",
      "107/107 [==============================] - 107s 997ms/step - loss: 1.7314 - accuracy: 0.2379 - val_loss: 1.6559 - val_accuracy: 0.2950 - lr: 4.8030e-04\n",
      "Epoch 6/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.6932 - accuracy: 0.2593 - val_loss: 1.6415 - val_accuracy: 0.2914 - lr: 4.7550e-04\n",
      "Epoch 7/500\n",
      "107/107 [==============================] - 105s 983ms/step - loss: 1.6145 - accuracy: 0.2877 - val_loss: 1.6124 - val_accuracy: 0.2878 - lr: 4.7074e-04\n",
      "Epoch 8/500\n",
      "107/107 [==============================] - 107s 995ms/step - loss: 1.5748 - accuracy: 0.3105 - val_loss: 1.5800 - val_accuracy: 0.3189 - lr: 4.6603e-04\n",
      "Epoch 9/500\n",
      "107/107 [==============================] - 106s 991ms/step - loss: 1.5930 - accuracy: 0.3101 - val_loss: 1.5490 - val_accuracy: 0.3118 - lr: 4.6137e-04\n",
      "Epoch 10/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.5668 - accuracy: 0.3087 - val_loss: 1.4961 - val_accuracy: 0.3345 - lr: 4.5676e-04\n",
      "Epoch 11/500\n",
      "107/107 [==============================] - 106s 993ms/step - loss: 1.5191 - accuracy: 0.3432 - val_loss: 1.5778 - val_accuracy: 0.3141 - lr: 4.5219e-04\n",
      "Epoch 12/500\n",
      "107/107 [==============================] - 106s 992ms/step - loss: 1.5241 - accuracy: 0.3439 - val_loss: 1.4782 - val_accuracy: 0.3477 - lr: 4.4767e-04\n",
      "Epoch 13/500\n",
      "107/107 [==============================] - 107s 997ms/step - loss: 1.4977 - accuracy: 0.3597 - val_loss: 1.4801 - val_accuracy: 0.3621 - lr: 4.4319e-04\n",
      "Epoch 14/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.4792 - accuracy: 0.3700 - val_loss: 1.4523 - val_accuracy: 0.3837 - lr: 4.3876e-04\n",
      "Epoch 15/500\n",
      "107/107 [==============================] - 109s 1s/step - loss: 1.4555 - accuracy: 0.3705 - val_loss: 1.4094 - val_accuracy: 0.3981 - lr: 4.3437e-04\n",
      "Epoch 16/500\n",
      "107/107 [==============================] - 107s 996ms/step - loss: 1.4447 - accuracy: 0.3912 - val_loss: 1.3773 - val_accuracy: 0.4209 - lr: 4.3003e-04\n",
      "Epoch 17/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.4383 - accuracy: 0.3872 - val_loss: 1.3748 - val_accuracy: 0.4029 - lr: 4.2573e-04\n",
      "Epoch 18/500\n",
      "107/107 [==============================] - 105s 984ms/step - loss: 1.3791 - accuracy: 0.4248 - val_loss: 1.3997 - val_accuracy: 0.4125 - lr: 4.2147e-04\n",
      "Epoch 19/500\n",
      "107/107 [==============================] - 107s 997ms/step - loss: 1.3844 - accuracy: 0.4175 - val_loss: 1.4310 - val_accuracy: 0.3981 - lr: 4.1726e-04\n",
      "Epoch 20/500\n",
      "107/107 [==============================] - 105s 983ms/step - loss: 1.3698 - accuracy: 0.4354 - val_loss: 1.3654 - val_accuracy: 0.4185 - lr: 4.1308e-04\n",
      "Epoch 21/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.3767 - accuracy: 0.4229 - val_loss: 1.3217 - val_accuracy: 0.4400 - lr: 4.0895e-04\n",
      "Epoch 22/500\n",
      "107/107 [==============================] - 107s 998ms/step - loss: 1.3593 - accuracy: 0.4241 - val_loss: 1.2936 - val_accuracy: 0.4400 - lr: 4.0486e-04\n",
      "Epoch 23/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.3425 - accuracy: 0.4372 - val_loss: 1.2387 - val_accuracy: 0.4712 - lr: 4.0082e-04\n",
      "Epoch 24/500\n",
      "107/107 [==============================] - 105s 979ms/step - loss: 1.3180 - accuracy: 0.4506 - val_loss: 1.3266 - val_accuracy: 0.4592 - lr: 3.9681e-04\n",
      "Epoch 25/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.3229 - accuracy: 0.4499 - val_loss: 1.3046 - val_accuracy: 0.4652 - lr: 3.9284e-04\n",
      "Epoch 26/500\n",
      "107/107 [==============================] - 106s 995ms/step - loss: 1.2999 - accuracy: 0.4676 - val_loss: 1.4131 - val_accuracy: 0.4281 - lr: 3.8891e-04\n",
      "Epoch 27/500\n",
      "107/107 [==============================] - 105s 979ms/step - loss: 1.2846 - accuracy: 0.4711 - val_loss: 1.1916 - val_accuracy: 0.4988 - lr: 3.8502e-04\n",
      "Epoch 28/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.2535 - accuracy: 0.4946 - val_loss: 1.2855 - val_accuracy: 0.4796 - lr: 3.8117e-04\n",
      "Epoch 29/500\n",
      "107/107 [==============================] - 107s 997ms/step - loss: 1.2404 - accuracy: 0.4880 - val_loss: 1.2426 - val_accuracy: 0.4904 - lr: 3.7736e-04\n",
      "Epoch 30/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.2518 - accuracy: 0.4890 - val_loss: 1.2843 - val_accuracy: 0.4904 - lr: 3.7359e-04\n",
      "Epoch 31/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.2437 - accuracy: 0.4868 - val_loss: 1.2708 - val_accuracy: 0.4652 - lr: 3.6985e-04\n",
      "Epoch 32/500\n",
      "107/107 [==============================] - 109s 1s/step - loss: 1.2130 - accuracy: 0.4995 - val_loss: 1.1711 - val_accuracy: 0.5264 - lr: 3.6615e-04\n",
      "Epoch 33/500\n",
      "107/107 [==============================] - 107s 1000ms/step - loss: 1.2379 - accuracy: 0.4882 - val_loss: 1.2195 - val_accuracy: 0.5060 - lr: 3.6249e-04\n",
      "Epoch 34/500\n",
      "107/107 [==============================] - 105s 981ms/step - loss: 1.1982 - accuracy: 0.5108 - val_loss: 1.2006 - val_accuracy: 0.5144 - lr: 3.5887e-04\n",
      "Epoch 35/500\n",
      "107/107 [==============================] - 106s 986ms/step - loss: 1.1803 - accuracy: 0.5230 - val_loss: 1.3074 - val_accuracy: 0.4736 - lr: 3.5528e-04\n",
      "Epoch 36/500\n",
      "107/107 [==============================] - 106s 995ms/step - loss: 1.3167 - accuracy: 0.4908 - val_loss: 1.3672 - val_accuracy: 0.4305 - lr: 3.5172e-04\n",
      "Epoch 37/500\n",
      "107/107 [==============================] - 106s 989ms/step - loss: 1.2001 - accuracy: 0.5268 - val_loss: 1.0992 - val_accuracy: 0.5683 - lr: 3.4821e-04\n",
      "Epoch 38/500\n",
      "107/107 [==============================] - 106s 990ms/step - loss: 1.1405 - accuracy: 0.5383 - val_loss: 1.0963 - val_accuracy: 0.5264 - lr: 3.4472e-04\n",
      "Epoch 39/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.1883 - accuracy: 0.5277 - val_loss: 1.2887 - val_accuracy: 0.4832 - lr: 3.4128e-04\n",
      "Epoch 40/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.1610 - accuracy: 0.5310 - val_loss: 1.0398 - val_accuracy: 0.5887 - lr: 3.3786e-04\n",
      "Epoch 41/500\n",
      "107/107 [==============================] - 106s 992ms/step - loss: 1.1536 - accuracy: 0.5362 - val_loss: 1.1516 - val_accuracy: 0.5324 - lr: 3.3449e-04\n",
      "Epoch 42/500\n",
      "107/107 [==============================] - 106s 992ms/step - loss: 1.1421 - accuracy: 0.5468 - val_loss: 1.0327 - val_accuracy: 0.5815 - lr: 3.3114e-04\n",
      "Epoch 43/500\n",
      "107/107 [==============================] - 107s 997ms/step - loss: 1.1680 - accuracy: 0.5442 - val_loss: 1.0921 - val_accuracy: 0.5731 - lr: 3.2783e-04\n",
      "Epoch 44/500\n",
      "107/107 [==============================] - 107s 997ms/step - loss: 1.1129 - accuracy: 0.5682 - val_loss: 1.1469 - val_accuracy: 0.5624 - lr: 3.2455e-04\n",
      "Epoch 45/500\n",
      "107/107 [==============================] - 105s 980ms/step - loss: 1.1654 - accuracy: 0.5550 - val_loss: 1.0310 - val_accuracy: 0.5911 - lr: 3.2131e-04\n",
      "Epoch 46/500\n",
      "107/107 [==============================] - 106s 988ms/step - loss: 1.0795 - accuracy: 0.5698 - val_loss: 1.1718 - val_accuracy: 0.5576 - lr: 3.1809e-04\n",
      "Epoch 47/500\n",
      "107/107 [==============================] - 106s 993ms/step - loss: 1.1032 - accuracy: 0.5701 - val_loss: 1.0991 - val_accuracy: 0.5659 - lr: 3.1491e-04\n",
      "Epoch 48/500\n",
      "107/107 [==============================] - 106s 988ms/step - loss: 1.1136 - accuracy: 0.5649 - val_loss: 1.0442 - val_accuracy: 0.5995 - lr: 3.1176e-04\n",
      "Epoch 49/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 106s 993ms/step - loss: 1.0184 - accuracy: 0.5914 - val_loss: 1.0236 - val_accuracy: 0.5971 - lr: 3.0865e-04\n",
      "Epoch 50/500\n",
      "107/107 [==============================] - 106s 986ms/step - loss: 1.0224 - accuracy: 0.5940 - val_loss: 1.1605 - val_accuracy: 0.5671 - lr: 3.0556e-04\n",
      "Epoch 51/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.1254 - accuracy: 0.5665 - val_loss: 1.2103 - val_accuracy: 0.5240 - lr: 3.0250e-04\n",
      "Epoch 52/500\n",
      "107/107 [==============================] - 109s 1s/step - loss: 1.1171 - accuracy: 0.5693 - val_loss: 1.0331 - val_accuracy: 0.6019 - lr: 2.9948e-04\n",
      "Epoch 53/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.0582 - accuracy: 0.5858 - val_loss: 1.3117 - val_accuracy: 0.5228 - lr: 2.9648e-04\n",
      "Epoch 54/500\n",
      "107/107 [==============================] - 106s 991ms/step - loss: 1.0650 - accuracy: 0.5882 - val_loss: 0.9772 - val_accuracy: 0.6235 - lr: 2.9352e-04\n",
      "Epoch 55/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.0446 - accuracy: 0.6039 - val_loss: 1.0753 - val_accuracy: 0.6019 - lr: 2.9058e-04\n",
      "Epoch 56/500\n",
      "107/107 [==============================] - 105s 985ms/step - loss: 1.0494 - accuracy: 0.5985 - val_loss: 1.0666 - val_accuracy: 0.5695 - lr: 2.8768e-04\n",
      "Epoch 57/500\n",
      "107/107 [==============================] - 106s 987ms/step - loss: 1.0565 - accuracy: 0.6058 - val_loss: 1.1131 - val_accuracy: 0.5959 - lr: 2.8480e-04\n",
      "Epoch 58/500\n",
      "107/107 [==============================] - 106s 989ms/step - loss: 0.9979 - accuracy: 0.6222 - val_loss: 0.9764 - val_accuracy: 0.6103 - lr: 2.8195e-04\n",
      "Epoch 59/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.0513 - accuracy: 0.6016 - val_loss: 1.0194 - val_accuracy: 0.6223 - lr: 2.7913e-04\n",
      "Epoch 60/500\n",
      "107/107 [==============================] - 105s 980ms/step - loss: 1.0083 - accuracy: 0.6164 - val_loss: 1.0496 - val_accuracy: 0.5971 - lr: 2.7634e-04\n",
      "Epoch 61/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.0228 - accuracy: 0.6215 - val_loss: 1.0371 - val_accuracy: 0.6199 - lr: 2.7358e-04\n",
      "Epoch 62/500\n",
      "107/107 [==============================] - 110s 1s/step - loss: 0.9951 - accuracy: 0.6133 - val_loss: 1.0066 - val_accuracy: 0.6043 - lr: 2.7084e-04\n",
      "Epoch 63/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.1485 - accuracy: 0.5832 - val_loss: 1.0009 - val_accuracy: 0.6271 - lr: 2.6813e-04\n",
      "Epoch 64/500\n",
      "107/107 [==============================] - 105s 983ms/step - loss: 1.0247 - accuracy: 0.6185 - val_loss: 1.0030 - val_accuracy: 0.6331 - lr: 2.6545e-04\n",
      "Epoch 65/500\n",
      "107/107 [==============================] - 107s 998ms/step - loss: 1.0159 - accuracy: 0.6218 - val_loss: 0.9521 - val_accuracy: 0.6595 - lr: 2.6280e-04\n",
      "Epoch 66/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.0115 - accuracy: 0.6316 - val_loss: 1.0426 - val_accuracy: 0.6307 - lr: 2.6017e-04\n",
      "Epoch 67/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.0030 - accuracy: 0.6354 - val_loss: 1.0619 - val_accuracy: 0.6535 - lr: 2.5757e-04\n",
      "Epoch 68/500\n",
      "107/107 [==============================] - 107s 997ms/step - loss: 1.0313 - accuracy: 0.6265 - val_loss: 1.3823 - val_accuracy: 0.5132 - lr: 2.5499e-04\n",
      "Epoch 69/500\n",
      "107/107 [==============================] - 109s 1s/step - loss: 1.0373 - accuracy: 0.6244 - val_loss: 0.9687 - val_accuracy: 0.6415 - lr: 2.5244e-04\n",
      "Epoch 70/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 0.9958 - accuracy: 0.6342 - val_loss: 1.0296 - val_accuracy: 0.6079 - lr: 2.4992e-04\n",
      "Epoch 71/500\n",
      "107/107 [==============================] - 106s 990ms/step - loss: 0.9965 - accuracy: 0.6349 - val_loss: 1.0068 - val_accuracy: 0.6427 - lr: 2.4742e-04\n",
      "Epoch 72/500\n",
      "107/107 [==============================] - 106s 995ms/step - loss: 1.0164 - accuracy: 0.6340 - val_loss: 0.9616 - val_accuracy: 0.6595 - lr: 2.4495e-04\n",
      "Epoch 73/500\n",
      "107/107 [==============================] - 109s 1s/step - loss: 1.0003 - accuracy: 0.6446 - val_loss: 0.9817 - val_accuracy: 0.6571 - lr: 2.4250e-04\n",
      "Epoch 74/500\n",
      "107/107 [==============================] - 106s 995ms/step - loss: 1.0200 - accuracy: 0.6465 - val_loss: 0.9799 - val_accuracy: 0.6487 - lr: 2.4007e-04\n",
      "Epoch 75/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.0350 - accuracy: 0.6417 - val_loss: 1.1160 - val_accuracy: 0.6091 - lr: 2.3767e-04\n",
      "Epoch 76/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 0.9651 - accuracy: 0.6448 - val_loss: 0.9771 - val_accuracy: 0.6367 - lr: 2.3529e-04\n",
      "Epoch 77/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 0.9774 - accuracy: 0.6436 - val_loss: 1.0174 - val_accuracy: 0.6343 - lr: 2.3294e-04\n",
      "Epoch 78/500\n",
      "107/107 [==============================] - 106s 991ms/step - loss: 0.9118 - accuracy: 0.6808 - val_loss: 0.9279 - val_accuracy: 0.6775 - lr: 2.3061e-04\n",
      "Epoch 79/500\n",
      "107/107 [==============================] - 106s 991ms/step - loss: 0.9900 - accuracy: 0.6523 - val_loss: 0.9531 - val_accuracy: 0.6631 - lr: 2.2830e-04\n",
      "Epoch 80/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.0114 - accuracy: 0.6526 - val_loss: 1.5106 - val_accuracy: 0.5300 - lr: 2.2602e-04\n",
      "Epoch 81/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.0824 - accuracy: 0.6269 - val_loss: 1.0167 - val_accuracy: 0.6319 - lr: 2.2376e-04\n",
      "Epoch 82/500\n",
      "107/107 [==============================] - 93s 869ms/step - loss: 1.0829 - accuracy: 0.6403 - val_loss: 1.0876 - val_accuracy: 0.6439 - lr: 2.2152e-04\n",
      "Epoch 83/500\n",
      "107/107 [==============================] - 69s 645ms/step - loss: 0.9839 - accuracy: 0.6629 - val_loss: 0.8753 - val_accuracy: 0.6894 - lr: 2.1931e-04\n",
      "Epoch 84/500\n",
      "107/107 [==============================] - 68s 640ms/step - loss: 0.9965 - accuracy: 0.6643 - val_loss: 1.2431 - val_accuracy: 0.6199 - lr: 2.1712e-04\n",
      "Epoch 85/500\n",
      "107/107 [==============================] - 70s 656ms/step - loss: 1.0839 - accuracy: 0.6417 - val_loss: 1.0108 - val_accuracy: 0.6343 - lr: 2.1494e-04\n",
      "Epoch 86/500\n",
      "107/107 [==============================] - 86s 801ms/step - loss: 0.9867 - accuracy: 0.6650 - val_loss: 1.0545 - val_accuracy: 0.6427 - lr: 2.1280e-04\n",
      "Epoch 87/500\n",
      "107/107 [==============================] - 96s 899ms/step - loss: 1.0298 - accuracy: 0.6556 - val_loss: 0.9085 - val_accuracy: 0.6799 - lr: 2.1067e-04\n",
      "Epoch 88/500\n",
      "107/107 [==============================] - 105s 983ms/step - loss: 1.0734 - accuracy: 0.6573 - val_loss: 0.9626 - val_accuracy: 0.6894 - lr: 2.0856e-04\n",
      "Epoch 89/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.0451 - accuracy: 0.6615 - val_loss: 1.2325 - val_accuracy: 0.6271 - lr: 2.0647e-04\n",
      "Epoch 90/500\n",
      "107/107 [==============================] - 110s 1s/step - loss: 1.4435 - accuracy: 0.5858 - val_loss: 1.0084 - val_accuracy: 0.6751 - lr: 2.0441e-04\n",
      "Epoch 91/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 0.9424 - accuracy: 0.6838 - val_loss: 1.0268 - val_accuracy: 0.6475 - lr: 2.0237e-04\n",
      "Epoch 92/500\n",
      "107/107 [==============================] - 110s 1s/step - loss: 0.9301 - accuracy: 0.6834 - val_loss: 0.9851 - val_accuracy: 0.6667 - lr: 2.0034e-04\n",
      "Epoch 93/500\n",
      "107/107 [==============================] - 107s 999ms/step - loss: 0.9471 - accuracy: 0.6787 - val_loss: 0.9171 - val_accuracy: 0.6775 - lr: 1.9834e-04\n",
      "Epoch 94/500\n",
      "107/107 [==============================] - 110s 1s/step - loss: 1.0249 - accuracy: 0.6662 - val_loss: 1.1534 - val_accuracy: 0.6367 - lr: 1.9636e-04\n",
      "Epoch 95/500\n",
      "107/107 [==============================] - 116s 1s/step - loss: 1.0071 - accuracy: 0.6801 - val_loss: 1.0415 - val_accuracy: 0.6691 - lr: 1.9439e-04\n",
      "Epoch 96/500\n",
      "107/107 [==============================] - 104s 971ms/step - loss: 1.0539 - accuracy: 0.6587 - val_loss: 1.0112 - val_accuracy: 0.6799 - lr: 1.9245e-04\n",
      "Epoch 97/500\n",
      "107/107 [==============================] - 105s 985ms/step - loss: 0.9088 - accuracy: 0.6998 - val_loss: 1.1450 - val_accuracy: 0.6739 - lr: 1.9052e-04\n",
      "Epoch 98/500\n",
      "107/107 [==============================] - 107s 999ms/step - loss: 1.0865 - accuracy: 0.6606 - val_loss: 1.0325 - val_accuracy: 0.6739 - lr: 1.8862e-04\n",
      "Epoch 99/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 105s 978ms/step - loss: 1.0126 - accuracy: 0.6812 - val_loss: 1.2286 - val_accuracy: 0.6547 - lr: 1.8673e-04\n",
      "Epoch 100/500\n",
      "107/107 [==============================] - 104s 976ms/step - loss: 1.1989 - accuracy: 0.6646 - val_loss: 0.8633 - val_accuracy: 0.7194 - lr: 1.8486e-04\n",
      "Epoch 101/500\n",
      "107/107 [==============================] - 105s 979ms/step - loss: 1.0349 - accuracy: 0.6876 - val_loss: 0.9958 - val_accuracy: 0.6954 - lr: 1.8302e-04\n",
      "Epoch 102/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.0969 - accuracy: 0.6700 - val_loss: 1.0380 - val_accuracy: 0.7026 - lr: 1.8119e-04\n",
      "Epoch 103/500\n",
      "107/107 [==============================] - 106s 992ms/step - loss: 1.1176 - accuracy: 0.6761 - val_loss: 1.4517 - val_accuracy: 0.6115 - lr: 1.7937e-04\n",
      "Epoch 104/500\n",
      "107/107 [==============================] - 104s 968ms/step - loss: 1.1853 - accuracy: 0.6660 - val_loss: 1.2389 - val_accuracy: 0.6679 - lr: 1.7758e-04\n",
      "Epoch 105/500\n",
      "107/107 [==============================] - 105s 983ms/step - loss: 1.0492 - accuracy: 0.6834 - val_loss: 1.0100 - val_accuracy: 0.7086 - lr: 1.7580e-04\n",
      "Epoch 106/500\n",
      "107/107 [==============================] - 106s 988ms/step - loss: 1.0557 - accuracy: 0.6819 - val_loss: 1.1789 - val_accuracy: 0.6595 - lr: 1.7405e-04\n",
      "Epoch 107/500\n",
      "107/107 [==============================] - 106s 988ms/step - loss: 1.2482 - accuracy: 0.6481 - val_loss: 1.1976 - val_accuracy: 0.6691 - lr: 1.7231e-04\n",
      "Epoch 108/500\n",
      "107/107 [==============================] - 106s 995ms/step - loss: 1.0208 - accuracy: 0.6906 - val_loss: 1.2569 - val_accuracy: 0.6595 - lr: 1.7058e-04\n",
      "Epoch 109/500\n",
      "107/107 [==============================] - 106s 988ms/step - loss: 0.9492 - accuracy: 0.7073 - val_loss: 1.0371 - val_accuracy: 0.6954 - lr: 1.6888e-04\n",
      "Epoch 110/500\n",
      "107/107 [==============================] - 107s 997ms/step - loss: 1.0820 - accuracy: 0.6930 - val_loss: 2.0083 - val_accuracy: 0.5707 - lr: 1.6719e-04\n",
      "Epoch 111/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.3778 - accuracy: 0.6474 - val_loss: 1.1346 - val_accuracy: 0.6894 - lr: 1.6552e-04\n",
      "Epoch 112/500\n",
      "107/107 [==============================] - 107s 997ms/step - loss: 1.0409 - accuracy: 0.6911 - val_loss: 0.9906 - val_accuracy: 0.6835 - lr: 1.6386e-04\n",
      "Epoch 113/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.0708 - accuracy: 0.6876 - val_loss: 1.0661 - val_accuracy: 0.7014 - lr: 1.6222e-04\n",
      "Epoch 114/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.1140 - accuracy: 0.6897 - val_loss: 1.3404 - val_accuracy: 0.6547 - lr: 1.6060e-04\n",
      "Epoch 115/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.4801 - accuracy: 0.6396 - val_loss: 1.3580 - val_accuracy: 0.6583 - lr: 1.5899e-04\n",
      "Epoch 116/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.2170 - accuracy: 0.6688 - val_loss: 1.2587 - val_accuracy: 0.6619 - lr: 1.5740e-04\n",
      "Epoch 117/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.1581 - accuracy: 0.6911 - val_loss: 1.3416 - val_accuracy: 0.6643 - lr: 1.5583e-04\n",
      "Epoch 118/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.1623 - accuracy: 0.6827 - val_loss: 0.8999 - val_accuracy: 0.7038 - lr: 1.5427e-04\n",
      "Epoch 119/500\n",
      "107/107 [==============================] - 109s 1s/step - loss: 0.9352 - accuracy: 0.7149 - val_loss: 0.8937 - val_accuracy: 0.7302 - lr: 1.5273e-04\n",
      "Epoch 120/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.1063 - accuracy: 0.7003 - val_loss: 1.1066 - val_accuracy: 0.6966 - lr: 1.5120e-04\n",
      "Epoch 121/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.1731 - accuracy: 0.6857 - val_loss: 1.2073 - val_accuracy: 0.6763 - lr: 1.4969e-04\n",
      "Epoch 122/500\n",
      "107/107 [==============================] - 105s 985ms/step - loss: 0.9903 - accuracy: 0.7125 - val_loss: 0.8755 - val_accuracy: 0.7170 - lr: 1.4819e-04\n",
      "Epoch 123/500\n",
      "107/107 [==============================] - 107s 999ms/step - loss: 1.0957 - accuracy: 0.6942 - val_loss: 1.0541 - val_accuracy: 0.7146 - lr: 1.4671e-04\n",
      "Epoch 124/500\n",
      "107/107 [==============================] - 106s 987ms/step - loss: 1.0446 - accuracy: 0.7083 - val_loss: 1.3251 - val_accuracy: 0.6559 - lr: 1.4524e-04\n",
      "Epoch 125/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.2196 - accuracy: 0.6984 - val_loss: 1.4949 - val_accuracy: 0.6355 - lr: 1.4379e-04\n",
      "Epoch 126/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.3344 - accuracy: 0.6669 - val_loss: 1.4094 - val_accuracy: 0.6571 - lr: 1.4235e-04\n",
      "Epoch 127/500\n",
      "107/107 [==============================] - 106s 986ms/step - loss: 1.1157 - accuracy: 0.7036 - val_loss: 0.9667 - val_accuracy: 0.7194 - lr: 1.4093e-04\n",
      "Epoch 128/500\n",
      "107/107 [==============================] - 106s 995ms/step - loss: 1.1278 - accuracy: 0.6991 - val_loss: 1.3140 - val_accuracy: 0.6739 - lr: 1.3952e-04\n",
      "Epoch 129/500\n",
      "107/107 [==============================] - 109s 1s/step - loss: 1.2216 - accuracy: 0.6949 - val_loss: 1.2298 - val_accuracy: 0.6823 - lr: 1.3813e-04\n",
      "Epoch 130/500\n",
      "107/107 [==============================] - 109s 1s/step - loss: 1.0238 - accuracy: 0.7144 - val_loss: 1.3358 - val_accuracy: 0.6811 - lr: 1.3674e-04\n",
      "Epoch 131/500\n",
      "107/107 [==============================] - 107s 997ms/step - loss: 1.1746 - accuracy: 0.6904 - val_loss: 1.3447 - val_accuracy: 0.6787 - lr: 1.3538e-04\n",
      "Epoch 132/500\n",
      "107/107 [==============================] - 105s 981ms/step - loss: 1.2028 - accuracy: 0.6925 - val_loss: 1.0575 - val_accuracy: 0.7242 - lr: 1.3402e-04\n",
      "Epoch 133/500\n",
      "107/107 [==============================] - 107s 996ms/step - loss: 1.2345 - accuracy: 0.6944 - val_loss: 1.1830 - val_accuracy: 0.6894 - lr: 1.3268e-04\n",
      "Epoch 134/500\n",
      "107/107 [==============================] - 107s 997ms/step - loss: 1.2456 - accuracy: 0.6916 - val_loss: 1.2343 - val_accuracy: 0.6799 - lr: 1.3136e-04\n",
      "Epoch 135/500\n",
      "107/107 [==============================] - 105s 983ms/step - loss: 1.4171 - accuracy: 0.6775 - val_loss: 1.2544 - val_accuracy: 0.6978 - lr: 1.3004e-04\n",
      "Epoch 136/500\n",
      "107/107 [==============================] - 106s 992ms/step - loss: 1.1790 - accuracy: 0.7094 - val_loss: 1.1161 - val_accuracy: 0.7122 - lr: 1.2874e-04\n",
      "Epoch 137/500\n",
      "107/107 [==============================] - 106s 993ms/step - loss: 1.4001 - accuracy: 0.6782 - val_loss: 1.1277 - val_accuracy: 0.7278 - lr: 1.2745e-04\n",
      "Epoch 138/500\n",
      "107/107 [==============================] - 107s 997ms/step - loss: 1.0439 - accuracy: 0.7278 - val_loss: 1.0098 - val_accuracy: 0.7098 - lr: 1.2618e-04\n",
      "Epoch 139/500\n",
      "107/107 [==============================] - 106s 994ms/step - loss: 1.0628 - accuracy: 0.7271 - val_loss: 1.6113 - val_accuracy: 0.6871 - lr: 1.2492e-04\n",
      "Epoch 140/500\n",
      "107/107 [==============================] - 104s 976ms/step - loss: 1.1847 - accuracy: 0.7163 - val_loss: 1.2699 - val_accuracy: 0.6595 - lr: 1.2367e-04\n",
      "Epoch 141/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.2610 - accuracy: 0.6949 - val_loss: 1.0665 - val_accuracy: 0.7362 - lr: 1.2243e-04\n",
      "Epoch 142/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.3315 - accuracy: 0.6885 - val_loss: 1.4213 - val_accuracy: 0.6631 - lr: 1.2121e-04\n",
      "Epoch 143/500\n",
      "107/107 [==============================] - 103s 962ms/step - loss: 1.2732 - accuracy: 0.6989 - val_loss: 1.8767 - val_accuracy: 0.6643 - lr: 1.2000e-04\n",
      "Epoch 144/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.3111 - accuracy: 0.7000 - val_loss: 1.4641 - val_accuracy: 0.7002 - lr: 1.1880e-04\n",
      "Epoch 145/500\n",
      "107/107 [==============================] - 104s 976ms/step - loss: 1.1891 - accuracy: 0.7205 - val_loss: 1.3913 - val_accuracy: 0.6847 - lr: 1.1761e-04\n",
      "Epoch 146/500\n",
      "107/107 [==============================] - 106s 994ms/step - loss: 1.1783 - accuracy: 0.7118 - val_loss: 1.2488 - val_accuracy: 0.6882 - lr: 1.1643e-04\n",
      "Epoch 147/500\n",
      "107/107 [==============================] - 109s 1s/step - loss: 1.2346 - accuracy: 0.7181 - val_loss: 1.5783 - val_accuracy: 0.6811 - lr: 1.1527e-04\n",
      "Epoch 148/500\n",
      "107/107 [==============================] - 109s 1s/step - loss: 1.3574 - accuracy: 0.6942 - val_loss: 1.2088 - val_accuracy: 0.7338 - lr: 1.1412e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.1360 - accuracy: 0.7318 - val_loss: 1.4074 - val_accuracy: 0.6799 - lr: 1.1297e-04\n",
      "Epoch 150/500\n",
      "107/107 [==============================] - 107s 997ms/step - loss: 1.2555 - accuracy: 0.7179 - val_loss: 1.0653 - val_accuracy: 0.7266 - lr: 1.1184e-04\n",
      "Epoch 151/500\n",
      "107/107 [==============================] - 106s 994ms/step - loss: 1.1948 - accuracy: 0.7118 - val_loss: 1.2846 - val_accuracy: 0.6978 - lr: 1.1073e-04\n",
      "Epoch 152/500\n",
      "107/107 [==============================] - 106s 990ms/step - loss: 1.3049 - accuracy: 0.7151 - val_loss: 1.4431 - val_accuracy: 0.7014 - lr: 1.0962e-04\n",
      "Epoch 153/500\n",
      "107/107 [==============================] - 106s 990ms/step - loss: 1.2720 - accuracy: 0.7149 - val_loss: 1.0151 - val_accuracy: 0.7326 - lr: 1.0852e-04\n",
      "Epoch 154/500\n",
      "107/107 [==============================] - 105s 984ms/step - loss: 1.1569 - accuracy: 0.7311 - val_loss: 1.0025 - val_accuracy: 0.7386 - lr: 1.0744e-04\n",
      "Epoch 155/500\n",
      "107/107 [==============================] - 105s 983ms/step - loss: 1.2591 - accuracy: 0.7160 - val_loss: 1.9247 - val_accuracy: 0.6487 - lr: 1.0636e-04\n",
      "Epoch 156/500\n",
      "107/107 [==============================] - 106s 993ms/step - loss: 1.3071 - accuracy: 0.7092 - val_loss: 1.1735 - val_accuracy: 0.7350 - lr: 1.0530e-04\n",
      "Epoch 157/500\n",
      "107/107 [==============================] - 106s 991ms/step - loss: 1.2608 - accuracy: 0.7219 - val_loss: 1.3749 - val_accuracy: 0.7050 - lr: 1.0425e-04\n",
      "Epoch 158/500\n",
      "107/107 [==============================] - 106s 992ms/step - loss: 1.3275 - accuracy: 0.7113 - val_loss: 1.2403 - val_accuracy: 0.7374 - lr: 1.0320e-04\n",
      "Epoch 159/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.3594 - accuracy: 0.7094 - val_loss: 1.4324 - val_accuracy: 0.7158 - lr: 1.0217e-04\n",
      "Epoch 160/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.2729 - accuracy: 0.7073 - val_loss: 1.6263 - val_accuracy: 0.6811 - lr: 1.0115e-04\n",
      "Epoch 161/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.3815 - accuracy: 0.7059 - val_loss: 1.2018 - val_accuracy: 0.7470 - lr: 1.0014e-04\n",
      "Epoch 162/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.3303 - accuracy: 0.7125 - val_loss: 1.4280 - val_accuracy: 0.7062 - lr: 9.9137e-05\n",
      "Epoch 163/500\n",
      "107/107 [==============================] - 106s 993ms/step - loss: 1.2741 - accuracy: 0.7280 - val_loss: 1.3054 - val_accuracy: 0.7314 - lr: 9.8146e-05\n",
      "Epoch 164/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.1862 - accuracy: 0.7301 - val_loss: 1.5191 - val_accuracy: 0.6823 - lr: 9.7164e-05\n",
      "Epoch 165/500\n",
      "107/107 [==============================] - 105s 982ms/step - loss: 1.2899 - accuracy: 0.7243 - val_loss: 1.3035 - val_accuracy: 0.7266 - lr: 9.6193e-05\n",
      "Epoch 166/500\n",
      "107/107 [==============================] - 105s 985ms/step - loss: 1.2673 - accuracy: 0.7245 - val_loss: 1.6044 - val_accuracy: 0.6715 - lr: 9.5231e-05\n",
      "Epoch 167/500\n",
      "107/107 [==============================] - 106s 987ms/step - loss: 1.3956 - accuracy: 0.7127 - val_loss: 1.3949 - val_accuracy: 0.7350 - lr: 9.4278e-05\n",
      "Epoch 168/500\n",
      "107/107 [==============================] - 105s 978ms/step - loss: 1.4699 - accuracy: 0.7085 - val_loss: 1.4005 - val_accuracy: 0.7254 - lr: 9.3336e-05\n",
      "Epoch 169/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.3589 - accuracy: 0.7191 - val_loss: 1.3701 - val_accuracy: 0.7218 - lr: 9.2402e-05\n",
      "Epoch 170/500\n",
      "107/107 [==============================] - 106s 989ms/step - loss: 1.3628 - accuracy: 0.7087 - val_loss: 1.6422 - val_accuracy: 0.6942 - lr: 9.1478e-05\n",
      "Epoch 171/500\n",
      "107/107 [==============================] - 107s 999ms/step - loss: 1.4548 - accuracy: 0.7146 - val_loss: 1.8706 - val_accuracy: 0.6679 - lr: 9.0563e-05\n",
      "Epoch 172/500\n",
      "107/107 [==============================] - 106s 994ms/step - loss: 1.5150 - accuracy: 0.7055 - val_loss: 1.3920 - val_accuracy: 0.7194 - lr: 8.9658e-05\n",
      "Epoch 173/500\n",
      "107/107 [==============================] - 106s 993ms/step - loss: 1.2859 - accuracy: 0.7259 - val_loss: 1.2486 - val_accuracy: 0.7338 - lr: 8.8761e-05\n",
      "Epoch 174/500\n",
      "107/107 [==============================] - 106s 995ms/step - loss: 1.4191 - accuracy: 0.7170 - val_loss: 1.3362 - val_accuracy: 0.7278 - lr: 8.7874e-05\n",
      "Epoch 175/500\n",
      "107/107 [==============================] - 106s 990ms/step - loss: 1.2858 - accuracy: 0.7348 - val_loss: 1.1240 - val_accuracy: 0.7374 - lr: 8.6995e-05\n",
      "Epoch 176/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.1663 - accuracy: 0.7355 - val_loss: 1.2379 - val_accuracy: 0.7410 - lr: 8.6125e-05\n",
      "Epoch 177/500\n",
      "107/107 [==============================] - 106s 994ms/step - loss: 1.4841 - accuracy: 0.7163 - val_loss: 1.3529 - val_accuracy: 0.7242 - lr: 8.5264e-05\n",
      "Epoch 178/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.3782 - accuracy: 0.7292 - val_loss: 1.4773 - val_accuracy: 0.7182 - lr: 8.4411e-05\n",
      "Epoch 179/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.3977 - accuracy: 0.7219 - val_loss: 1.6771 - val_accuracy: 0.7110 - lr: 8.3567e-05\n",
      "Epoch 180/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.3768 - accuracy: 0.7278 - val_loss: 1.5190 - val_accuracy: 0.6990 - lr: 8.2731e-05\n",
      "Epoch 181/500\n",
      "107/107 [==============================] - 107s 998ms/step - loss: 1.4942 - accuracy: 0.7203 - val_loss: 1.3655 - val_accuracy: 0.7350 - lr: 8.1904e-05\n",
      "Epoch 182/500\n",
      "107/107 [==============================] - 106s 992ms/step - loss: 1.4371 - accuracy: 0.7268 - val_loss: 1.5702 - val_accuracy: 0.6918 - lr: 8.1085e-05\n",
      "Epoch 183/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.3049 - accuracy: 0.7501 - val_loss: 1.6705 - val_accuracy: 0.7302 - lr: 8.0274e-05\n",
      "Epoch 184/500\n",
      "107/107 [==============================] - 107s 996ms/step - loss: 1.3693 - accuracy: 0.7374 - val_loss: 1.5848 - val_accuracy: 0.7230 - lr: 7.9471e-05\n",
      "Epoch 185/500\n",
      "107/107 [==============================] - 104s 975ms/step - loss: 1.3774 - accuracy: 0.7290 - val_loss: 1.5296 - val_accuracy: 0.7170 - lr: 7.8677e-05\n",
      "Epoch 186/500\n",
      "107/107 [==============================] - 106s 986ms/step - loss: 1.4116 - accuracy: 0.7280 - val_loss: 1.5991 - val_accuracy: 0.7146 - lr: 7.7890e-05\n",
      "Epoch 187/500\n",
      "107/107 [==============================] - 106s 993ms/step - loss: 1.4398 - accuracy: 0.7200 - val_loss: 1.2532 - val_accuracy: 0.7530 - lr: 7.7111e-05\n",
      "Epoch 188/500\n",
      "107/107 [==============================] - 107s 996ms/step - loss: 1.5127 - accuracy: 0.7165 - val_loss: 1.6234 - val_accuracy: 0.7038 - lr: 7.6340e-05\n",
      "Epoch 189/500\n",
      "107/107 [==============================] - 106s 989ms/step - loss: 1.3450 - accuracy: 0.7271 - val_loss: 1.4306 - val_accuracy: 0.7302 - lr: 7.5576e-05\n",
      "Epoch 190/500\n",
      "107/107 [==============================] - 106s 986ms/step - loss: 1.5130 - accuracy: 0.7181 - val_loss: 1.5928 - val_accuracy: 0.7050 - lr: 7.4821e-05\n",
      "Epoch 191/500\n",
      "107/107 [==============================] - 106s 994ms/step - loss: 1.6144 - accuracy: 0.7163 - val_loss: 1.5386 - val_accuracy: 0.7122 - lr: 7.4072e-05\n",
      "Epoch 192/500\n",
      "107/107 [==============================] - 105s 983ms/step - loss: 1.4942 - accuracy: 0.7191 - val_loss: 1.9087 - val_accuracy: 0.6871 - lr: 7.3332e-05\n",
      "Epoch 193/500\n",
      "107/107 [==============================] - 107s 998ms/step - loss: 1.4172 - accuracy: 0.7386 - val_loss: 1.3098 - val_accuracy: 0.7386 - lr: 7.2598e-05\n",
      "Epoch 194/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.4246 - accuracy: 0.7280 - val_loss: 1.4303 - val_accuracy: 0.7098 - lr: 7.1872e-05\n",
      "Epoch 195/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.4390 - accuracy: 0.7346 - val_loss: 1.5584 - val_accuracy: 0.7194 - lr: 7.1154e-05\n",
      "Epoch 196/500\n",
      "107/107 [==============================] - 107s 997ms/step - loss: 1.4586 - accuracy: 0.7238 - val_loss: 1.5359 - val_accuracy: 0.7122 - lr: 7.0442e-05\n",
      "Epoch 197/500\n",
      "107/107 [==============================] - 105s 983ms/step - loss: 1.5595 - accuracy: 0.7238 - val_loss: 1.6363 - val_accuracy: 0.7230 - lr: 6.9738e-05\n",
      "Epoch 198/500\n",
      "107/107 [==============================] - 106s 994ms/step - loss: 1.4666 - accuracy: 0.7374 - val_loss: 1.5638 - val_accuracy: 0.7038 - lr: 6.9040e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.4428 - accuracy: 0.7330 - val_loss: 1.6056 - val_accuracy: 0.6966 - lr: 6.8350e-05\n",
      "Epoch 200/500\n",
      "107/107 [==============================] - 107s 1000ms/step - loss: 1.5354 - accuracy: 0.7212 - val_loss: 1.5003 - val_accuracy: 0.7266 - lr: 6.7667e-05\n",
      "Epoch 201/500\n",
      "107/107 [==============================] - 106s 994ms/step - loss: 1.4918 - accuracy: 0.7287 - val_loss: 1.8381 - val_accuracy: 0.7086 - lr: 6.6990e-05\n",
      "Epoch 202/500\n",
      "107/107 [==============================] - 106s 988ms/step - loss: 1.4934 - accuracy: 0.7257 - val_loss: 1.6348 - val_accuracy: 0.7218 - lr: 6.6320e-05\n",
      "Epoch 203/500\n",
      "107/107 [==============================] - 105s 982ms/step - loss: 1.4449 - accuracy: 0.7445 - val_loss: 1.7001 - val_accuracy: 0.7050 - lr: 6.5657e-05\n",
      "Epoch 204/500\n",
      "107/107 [==============================] - 107s 996ms/step - loss: 1.3375 - accuracy: 0.7546 - val_loss: 1.5142 - val_accuracy: 0.7422 - lr: 6.5000e-05\n",
      "Epoch 205/500\n",
      "107/107 [==============================] - 106s 991ms/step - loss: 1.4589 - accuracy: 0.7395 - val_loss: 1.2660 - val_accuracy: 0.7506 - lr: 6.4350e-05\n",
      "Epoch 206/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.4554 - accuracy: 0.7360 - val_loss: 1.3463 - val_accuracy: 0.7434 - lr: 6.3707e-05\n",
      "Epoch 207/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.5117 - accuracy: 0.7388 - val_loss: 1.6262 - val_accuracy: 0.7566 - lr: 6.3070e-05\n",
      "Epoch 208/500\n",
      "107/107 [==============================] - 104s 976ms/step - loss: 1.6041 - accuracy: 0.7266 - val_loss: 1.8530 - val_accuracy: 0.6990 - lr: 6.2439e-05\n",
      "Epoch 209/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.6248 - accuracy: 0.7308 - val_loss: 1.9076 - val_accuracy: 0.7182 - lr: 6.1815e-05\n",
      "Epoch 210/500\n",
      "107/107 [==============================] - 105s 984ms/step - loss: 1.3987 - accuracy: 0.7449 - val_loss: 1.6027 - val_accuracy: 0.7170 - lr: 6.1196e-05\n",
      "Epoch 211/500\n",
      "107/107 [==============================] - 106s 990ms/step - loss: 1.5381 - accuracy: 0.7285 - val_loss: 1.8918 - val_accuracy: 0.7050 - lr: 6.0584e-05\n",
      "Epoch 212/500\n",
      "107/107 [==============================] - 107s 998ms/step - loss: 1.4861 - accuracy: 0.7351 - val_loss: 1.8539 - val_accuracy: 0.7122 - lr: 5.9979e-05\n",
      "Epoch 213/500\n",
      "107/107 [==============================] - 106s 992ms/step - loss: 1.5395 - accuracy: 0.7351 - val_loss: 1.6180 - val_accuracy: 0.7326 - lr: 5.9379e-05\n",
      "Epoch 214/500\n",
      "107/107 [==============================] - 105s 977ms/step - loss: 1.7495 - accuracy: 0.7200 - val_loss: 1.8701 - val_accuracy: 0.6930 - lr: 5.8785e-05\n",
      "Epoch 215/500\n",
      "107/107 [==============================] - 106s 994ms/step - loss: 1.7651 - accuracy: 0.7142 - val_loss: 2.3858 - val_accuracy: 0.6859 - lr: 5.8197e-05\n",
      "Epoch 216/500\n",
      "107/107 [==============================] - 105s 983ms/step - loss: 1.7602 - accuracy: 0.7189 - val_loss: 1.7462 - val_accuracy: 0.7290 - lr: 5.7615e-05\n",
      "Epoch 217/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.5219 - accuracy: 0.7445 - val_loss: 1.7960 - val_accuracy: 0.7026 - lr: 5.7039e-05\n",
      "Epoch 218/500\n",
      "107/107 [==============================] - 105s 985ms/step - loss: 1.5566 - accuracy: 0.7318 - val_loss: 1.5505 - val_accuracy: 0.7206 - lr: 5.6469e-05\n",
      "Epoch 219/500\n",
      "107/107 [==============================] - 109s 1s/step - loss: 1.6317 - accuracy: 0.7388 - val_loss: 1.1881 - val_accuracy: 0.7890 - lr: 5.5904e-05\n",
      "Epoch 220/500\n",
      "107/107 [==============================] - 106s 992ms/step - loss: 1.6042 - accuracy: 0.7217 - val_loss: 1.8533 - val_accuracy: 0.7230 - lr: 5.5345e-05\n",
      "Epoch 221/500\n",
      "107/107 [==============================] - 107s 996ms/step - loss: 1.6214 - accuracy: 0.7250 - val_loss: 1.6540 - val_accuracy: 0.7338 - lr: 5.4791e-05\n",
      "Epoch 222/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.6340 - accuracy: 0.7181 - val_loss: 2.1040 - val_accuracy: 0.7026 - lr: 5.4244e-05\n",
      "Epoch 223/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.5768 - accuracy: 0.7362 - val_loss: 1.5172 - val_accuracy: 0.7590 - lr: 5.3701e-05\n",
      "Epoch 224/500\n",
      "107/107 [==============================] - 104s 972ms/step - loss: 1.5588 - accuracy: 0.7297 - val_loss: 2.0784 - val_accuracy: 0.6906 - lr: 5.3164e-05\n",
      "Epoch 225/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.5910 - accuracy: 0.7339 - val_loss: 1.3986 - val_accuracy: 0.7410 - lr: 5.2632e-05\n",
      "Epoch 226/500\n",
      "107/107 [==============================] - 104s 976ms/step - loss: 1.4876 - accuracy: 0.7468 - val_loss: 1.5468 - val_accuracy: 0.7386 - lr: 5.2106e-05\n",
      "Epoch 227/500\n",
      "107/107 [==============================] - 105s 983ms/step - loss: 1.4952 - accuracy: 0.7426 - val_loss: 1.6692 - val_accuracy: 0.7350 - lr: 5.1585e-05\n",
      "Epoch 228/500\n",
      "107/107 [==============================] - 105s 982ms/step - loss: 1.7329 - accuracy: 0.7252 - val_loss: 1.8773 - val_accuracy: 0.7098 - lr: 5.1069e-05\n",
      "Epoch 229/500\n",
      "107/107 [==============================] - 106s 992ms/step - loss: 1.8008 - accuracy: 0.7106 - val_loss: 1.6936 - val_accuracy: 0.7230 - lr: 5.0559e-05\n",
      "Epoch 230/500\n",
      "107/107 [==============================] - 107s 1000ms/step - loss: 1.6244 - accuracy: 0.7379 - val_loss: 1.7115 - val_accuracy: 0.7362 - lr: 5.0053e-05\n",
      "Epoch 231/500\n",
      "107/107 [==============================] - 107s 997ms/step - loss: 1.7884 - accuracy: 0.7151 - val_loss: 1.7680 - val_accuracy: 0.7326 - lr: 4.9552e-05\n",
      "Epoch 232/500\n",
      "107/107 [==============================] - 106s 990ms/step - loss: 1.6972 - accuracy: 0.7311 - val_loss: 1.6651 - val_accuracy: 0.7398 - lr: 4.9057e-05\n",
      "Epoch 233/500\n",
      "107/107 [==============================] - 104s 971ms/step - loss: 1.6191 - accuracy: 0.7306 - val_loss: 1.7582 - val_accuracy: 0.7398 - lr: 4.8566e-05\n",
      "Epoch 234/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.7528 - accuracy: 0.7290 - val_loss: 1.7707 - val_accuracy: 0.7278 - lr: 4.8081e-05\n",
      "Epoch 235/500\n",
      "107/107 [==============================] - 106s 991ms/step - loss: 1.6812 - accuracy: 0.7374 - val_loss: 1.8681 - val_accuracy: 0.7242 - lr: 4.7600e-05\n",
      "Epoch 236/500\n",
      "107/107 [==============================] - 104s 974ms/step - loss: 1.6551 - accuracy: 0.7362 - val_loss: 1.9055 - val_accuracy: 0.7206 - lr: 4.7124e-05\n",
      "Epoch 237/500\n",
      "107/107 [==============================] - 104s 972ms/step - loss: 1.6279 - accuracy: 0.7377 - val_loss: 2.1180 - val_accuracy: 0.7146 - lr: 4.6653e-05\n",
      "Epoch 238/500\n",
      "107/107 [==============================] - 107s 999ms/step - loss: 1.7196 - accuracy: 0.7355 - val_loss: 1.5376 - val_accuracy: 0.7290 - lr: 4.6186e-05\n",
      "Epoch 239/500\n",
      "107/107 [==============================] - 105s 984ms/step - loss: 1.5777 - accuracy: 0.7431 - val_loss: 1.8218 - val_accuracy: 0.7146 - lr: 4.5724e-05\n",
      "Epoch 240/500\n",
      "107/107 [==============================] - 106s 989ms/step - loss: 1.6471 - accuracy: 0.7301 - val_loss: 1.6200 - val_accuracy: 0.7314 - lr: 4.5267e-05\n",
      "Epoch 241/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.7797 - accuracy: 0.7294 - val_loss: 1.9517 - val_accuracy: 0.7122 - lr: 4.4814e-05\n",
      "Epoch 242/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.6945 - accuracy: 0.7323 - val_loss: 1.9556 - val_accuracy: 0.7194 - lr: 4.4366e-05\n",
      "Epoch 243/500\n",
      "107/107 [==============================] - 105s 986ms/step - loss: 1.6467 - accuracy: 0.7362 - val_loss: 1.9435 - val_accuracy: 0.7470 - lr: 4.3923e-05\n",
      "Epoch 244/500\n",
      "107/107 [==============================] - 105s 985ms/step - loss: 1.6104 - accuracy: 0.7431 - val_loss: 1.9878 - val_accuracy: 0.7062 - lr: 4.3483e-05\n",
      "Epoch 245/500\n",
      "107/107 [==============================] - 106s 990ms/step - loss: 1.8791 - accuracy: 0.7172 - val_loss: 1.9813 - val_accuracy: 0.7362 - lr: 4.3048e-05\n",
      "Epoch 246/500\n",
      "107/107 [==============================] - 103s 964ms/step - loss: 1.6012 - accuracy: 0.7391 - val_loss: 2.0994 - val_accuracy: 0.7038 - lr: 4.2618e-05\n",
      "Epoch 247/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.7884 - accuracy: 0.7214 - val_loss: 1.4774 - val_accuracy: 0.7566 - lr: 4.2192e-05\n",
      "Epoch 248/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 106s 993ms/step - loss: 1.7069 - accuracy: 0.7325 - val_loss: 1.9291 - val_accuracy: 0.7242 - lr: 4.1770e-05\n",
      "Epoch 249/500\n",
      "107/107 [==============================] - 104s 972ms/step - loss: 1.6012 - accuracy: 0.7417 - val_loss: 1.5758 - val_accuracy: 0.7302 - lr: 4.1352e-05\n",
      "Epoch 250/500\n",
      "107/107 [==============================] - 109s 1s/step - loss: 1.7267 - accuracy: 0.7435 - val_loss: 2.3560 - val_accuracy: 0.7134 - lr: 4.0939e-05\n",
      "Epoch 251/500\n",
      "107/107 [==============================] - 106s 987ms/step - loss: 1.7594 - accuracy: 0.7379 - val_loss: 1.5404 - val_accuracy: 0.7614 - lr: 4.0529e-05\n",
      "Epoch 252/500\n",
      "107/107 [==============================] - 106s 992ms/step - loss: 1.6841 - accuracy: 0.7431 - val_loss: 1.6733 - val_accuracy: 0.7434 - lr: 4.0124e-05\n",
      "Epoch 253/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.6865 - accuracy: 0.7414 - val_loss: 1.6137 - val_accuracy: 0.7374 - lr: 3.9723e-05\n",
      "Epoch 254/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.7047 - accuracy: 0.7393 - val_loss: 1.7494 - val_accuracy: 0.7434 - lr: 3.9325e-05\n",
      "Epoch 255/500\n",
      "107/107 [==============================] - 106s 988ms/step - loss: 1.6074 - accuracy: 0.7480 - val_loss: 1.7031 - val_accuracy: 0.7422 - lr: 3.8932e-05\n",
      "Epoch 256/500\n",
      "107/107 [==============================] - 107s 995ms/step - loss: 1.6353 - accuracy: 0.7381 - val_loss: 1.6260 - val_accuracy: 0.7470 - lr: 3.8543e-05\n",
      "Epoch 257/500\n",
      "107/107 [==============================] - 106s 991ms/step - loss: 1.7223 - accuracy: 0.7374 - val_loss: 2.0794 - val_accuracy: 0.7038 - lr: 3.8157e-05\n",
      "Epoch 258/500\n",
      "107/107 [==============================] - 107s 995ms/step - loss: 1.5814 - accuracy: 0.7555 - val_loss: 1.8952 - val_accuracy: 0.7218 - lr: 3.7776e-05\n",
      "Epoch 259/500\n",
      "107/107 [==============================] - 107s 996ms/step - loss: 1.8207 - accuracy: 0.7360 - val_loss: 2.2856 - val_accuracy: 0.7170 - lr: 3.7398e-05\n",
      "Epoch 260/500\n",
      "107/107 [==============================] - 106s 988ms/step - loss: 1.7080 - accuracy: 0.7358 - val_loss: 1.9072 - val_accuracy: 0.7410 - lr: 3.7024e-05\n",
      "Epoch 261/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.8966 - accuracy: 0.7362 - val_loss: 2.1661 - val_accuracy: 0.7242 - lr: 3.6654e-05\n",
      "Epoch 262/500\n",
      "107/107 [==============================] - 105s 978ms/step - loss: 1.7146 - accuracy: 0.7461 - val_loss: 1.9718 - val_accuracy: 0.7062 - lr: 3.6287e-05\n",
      "Epoch 263/500\n",
      "107/107 [==============================] - 106s 989ms/step - loss: 1.7549 - accuracy: 0.7398 - val_loss: 1.9673 - val_accuracy: 0.7386 - lr: 3.5925e-05\n",
      "Epoch 264/500\n",
      "107/107 [==============================] - 105s 984ms/step - loss: 1.7262 - accuracy: 0.7409 - val_loss: 1.9278 - val_accuracy: 0.7422 - lr: 3.5565e-05\n",
      "Epoch 265/500\n",
      "107/107 [==============================] - 106s 992ms/step - loss: 1.7830 - accuracy: 0.7367 - val_loss: 1.8317 - val_accuracy: 0.7386 - lr: 3.5210e-05\n",
      "Epoch 266/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.7259 - accuracy: 0.7407 - val_loss: 2.0055 - val_accuracy: 0.7278 - lr: 3.4858e-05\n",
      "Epoch 267/500\n",
      "107/107 [==============================] - 106s 988ms/step - loss: 1.7714 - accuracy: 0.7395 - val_loss: 1.9751 - val_accuracy: 0.7302 - lr: 3.4509e-05\n",
      "Epoch 268/500\n",
      "107/107 [==============================] - 107s 996ms/step - loss: 1.6892 - accuracy: 0.7459 - val_loss: 1.7598 - val_accuracy: 0.7410 - lr: 3.4164e-05\n",
      "Epoch 269/500\n",
      "107/107 [==============================] - 106s 993ms/step - loss: 1.7912 - accuracy: 0.7388 - val_loss: 1.6106 - val_accuracy: 0.7566 - lr: 3.3822e-05\n",
      "Epoch 270/500\n",
      "107/107 [==============================] - 105s 984ms/step - loss: 1.7581 - accuracy: 0.7426 - val_loss: 1.8484 - val_accuracy: 0.7302 - lr: 3.3484e-05\n",
      "Epoch 271/500\n",
      "107/107 [==============================] - 105s 979ms/step - loss: 1.8158 - accuracy: 0.7440 - val_loss: 1.8464 - val_accuracy: 0.7254 - lr: 3.3149e-05\n",
      "Epoch 272/500\n",
      "107/107 [==============================] - 105s 978ms/step - loss: 1.9167 - accuracy: 0.7297 - val_loss: 1.6472 - val_accuracy: 0.7626 - lr: 3.2818e-05\n",
      "Epoch 273/500\n",
      "107/107 [==============================] - 104s 975ms/step - loss: 1.7941 - accuracy: 0.7344 - val_loss: 1.9364 - val_accuracy: 0.7158 - lr: 3.2489e-05\n",
      "Epoch 274/500\n",
      "107/107 [==============================] - 106s 989ms/step - loss: 1.8107 - accuracy: 0.7353 - val_loss: 2.0017 - val_accuracy: 0.7218 - lr: 3.2165e-05\n",
      "Epoch 275/500\n",
      "107/107 [==============================] - 106s 990ms/step - loss: 1.8706 - accuracy: 0.7384 - val_loss: 2.0255 - val_accuracy: 0.7206 - lr: 3.1843e-05\n",
      "Epoch 276/500\n",
      "107/107 [==============================] - 107s 996ms/step - loss: 1.8295 - accuracy: 0.7355 - val_loss: 1.8062 - val_accuracy: 0.7338 - lr: 3.1525e-05\n",
      "Epoch 277/500\n",
      "107/107 [==============================] - 107s 1000ms/step - loss: 1.8036 - accuracy: 0.7384 - val_loss: 2.1181 - val_accuracy: 0.7146 - lr: 3.1209e-05\n",
      "Epoch 278/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.9261 - accuracy: 0.7318 - val_loss: 1.9340 - val_accuracy: 0.7254 - lr: 3.0897e-05\n",
      "Epoch 279/500\n",
      "107/107 [==============================] - 107s 996ms/step - loss: 1.8491 - accuracy: 0.7351 - val_loss: 1.8425 - val_accuracy: 0.7446 - lr: 3.0588e-05\n",
      "Epoch 280/500\n",
      "107/107 [==============================] - 105s 985ms/step - loss: 1.7611 - accuracy: 0.7454 - val_loss: 2.1742 - val_accuracy: 0.7302 - lr: 3.0282e-05\n",
      "Epoch 281/500\n",
      "107/107 [==============================] - 106s 993ms/step - loss: 1.8963 - accuracy: 0.7348 - val_loss: 1.8470 - val_accuracy: 0.7374 - lr: 2.9980e-05\n",
      "Epoch 282/500\n",
      "107/107 [==============================] - 105s 982ms/step - loss: 1.8394 - accuracy: 0.7398 - val_loss: 1.9386 - val_accuracy: 0.7182 - lr: 2.9680e-05\n",
      "Epoch 283/500\n",
      "107/107 [==============================] - 104s 976ms/step - loss: 1.8246 - accuracy: 0.7304 - val_loss: 1.7930 - val_accuracy: 0.7494 - lr: 2.9383e-05\n",
      "Epoch 284/500\n",
      "107/107 [==============================] - 105s 984ms/step - loss: 1.9100 - accuracy: 0.7419 - val_loss: 2.1323 - val_accuracy: 0.7050 - lr: 2.9089e-05\n",
      "Epoch 285/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.7785 - accuracy: 0.7428 - val_loss: 2.1074 - val_accuracy: 0.7350 - lr: 2.8798e-05\n",
      "Epoch 286/500\n",
      "107/107 [==============================] - 105s 979ms/step - loss: 1.8302 - accuracy: 0.7487 - val_loss: 1.7157 - val_accuracy: 0.7506 - lr: 2.8510e-05\n",
      "Epoch 287/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.9273 - accuracy: 0.7355 - val_loss: 2.2343 - val_accuracy: 0.7278 - lr: 2.8225e-05\n",
      "Epoch 288/500\n",
      "107/107 [==============================] - 106s 990ms/step - loss: 1.9477 - accuracy: 0.7332 - val_loss: 1.9069 - val_accuracy: 0.7422 - lr: 2.7943e-05\n",
      "Epoch 289/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.7893 - accuracy: 0.7367 - val_loss: 2.0457 - val_accuracy: 0.7158 - lr: 2.7663e-05\n",
      "Epoch 290/500\n",
      "107/107 [==============================] - 109s 1s/step - loss: 1.9982 - accuracy: 0.7261 - val_loss: 1.9007 - val_accuracy: 0.7542 - lr: 2.7387e-05\n",
      "Epoch 291/500\n",
      "107/107 [==============================] - 105s 980ms/step - loss: 1.8727 - accuracy: 0.7290 - val_loss: 2.2360 - val_accuracy: 0.6882 - lr: 2.7113e-05\n",
      "Epoch 292/500\n",
      "107/107 [==============================] - 106s 989ms/step - loss: 1.8846 - accuracy: 0.7346 - val_loss: 1.9724 - val_accuracy: 0.7362 - lr: 2.6842e-05\n",
      "Epoch 293/500\n",
      "107/107 [==============================] - 106s 988ms/step - loss: 1.9831 - accuracy: 0.7304 - val_loss: 2.1192 - val_accuracy: 0.7266 - lr: 2.6573e-05\n",
      "Epoch 294/500\n",
      "107/107 [==============================] - 107s 998ms/step - loss: 1.9449 - accuracy: 0.7268 - val_loss: 1.7174 - val_accuracy: 0.7506 - lr: 2.6308e-05\n",
      "Epoch 295/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.9170 - accuracy: 0.7245 - val_loss: 1.8317 - val_accuracy: 0.7398 - lr: 2.6045e-05\n",
      "Epoch 296/500\n",
      "107/107 [==============================] - 105s 982ms/step - loss: 1.8732 - accuracy: 0.7365 - val_loss: 1.8905 - val_accuracy: 0.7410 - lr: 2.5784e-05\n",
      "Epoch 297/500\n",
      "107/107 [==============================] - 106s 993ms/step - loss: 1.9324 - accuracy: 0.7318 - val_loss: 2.1945 - val_accuracy: 0.7242 - lr: 2.5526e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 298/500\n",
      "107/107 [==============================] - 107s 996ms/step - loss: 1.8312 - accuracy: 0.7381 - val_loss: 1.8720 - val_accuracy: 0.7242 - lr: 2.5271e-05\n",
      "Epoch 299/500\n",
      "107/107 [==============================] - 106s 991ms/step - loss: 1.8321 - accuracy: 0.7379 - val_loss: 1.9192 - val_accuracy: 0.7374 - lr: 2.5018e-05\n",
      "Epoch 300/500\n",
      "107/107 [==============================] - 106s 990ms/step - loss: 1.9450 - accuracy: 0.7365 - val_loss: 1.9500 - val_accuracy: 0.7542 - lr: 2.4768e-05\n",
      "Epoch 301/500\n",
      "107/107 [==============================] - 107s 1000ms/step - loss: 1.9199 - accuracy: 0.7466 - val_loss: 2.0134 - val_accuracy: 0.7338 - lr: 2.4520e-05\n",
      "Epoch 302/500\n",
      "107/107 [==============================] - 106s 990ms/step - loss: 1.9792 - accuracy: 0.7268 - val_loss: 1.8566 - val_accuracy: 0.7542 - lr: 2.4275e-05\n",
      "Epoch 303/500\n",
      "107/107 [==============================] - 105s 984ms/step - loss: 1.9288 - accuracy: 0.7308 - val_loss: 2.0384 - val_accuracy: 0.7554 - lr: 2.4032e-05\n",
      "Epoch 304/500\n",
      "107/107 [==============================] - 106s 995ms/step - loss: 2.0022 - accuracy: 0.7358 - val_loss: 1.7874 - val_accuracy: 0.7470 - lr: 2.3792e-05\n",
      "Epoch 305/500\n",
      "107/107 [==============================] - 105s 980ms/step - loss: 2.0631 - accuracy: 0.7290 - val_loss: 2.3212 - val_accuracy: 0.7122 - lr: 2.3554e-05\n",
      "Epoch 306/500\n",
      "107/107 [==============================] - 105s 985ms/step - loss: 2.1151 - accuracy: 0.7391 - val_loss: 2.1691 - val_accuracy: 0.7026 - lr: 2.3319e-05\n",
      "Epoch 307/500\n",
      "107/107 [==============================] - 107s 996ms/step - loss: 2.0936 - accuracy: 0.7283 - val_loss: 2.3984 - val_accuracy: 0.7158 - lr: 2.3086e-05\n",
      "Epoch 308/500\n",
      "107/107 [==============================] - 104s 975ms/step - loss: 1.9874 - accuracy: 0.7365 - val_loss: 1.8571 - val_accuracy: 0.7494 - lr: 2.2855e-05\n",
      "Epoch 309/500\n",
      "107/107 [==============================] - 105s 985ms/step - loss: 1.9627 - accuracy: 0.7264 - val_loss: 2.1086 - val_accuracy: 0.7206 - lr: 2.2626e-05\n",
      "Epoch 310/500\n",
      "107/107 [==============================] - 106s 991ms/step - loss: 1.8703 - accuracy: 0.7407 - val_loss: 2.3225 - val_accuracy: 0.7098 - lr: 2.2400e-05\n",
      "Epoch 311/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 2.1050 - accuracy: 0.7290 - val_loss: 2.1063 - val_accuracy: 0.7158 - lr: 2.2176e-05\n",
      "Epoch 312/500\n",
      "107/107 [==============================] - 107s 997ms/step - loss: 1.9388 - accuracy: 0.7447 - val_loss: 1.9971 - val_accuracy: 0.7410 - lr: 2.1954e-05\n",
      "Epoch 313/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 1.9803 - accuracy: 0.7268 - val_loss: 2.0653 - val_accuracy: 0.7422 - lr: 2.1735e-05\n",
      "Epoch 314/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 2.0087 - accuracy: 0.7348 - val_loss: 2.1015 - val_accuracy: 0.7230 - lr: 2.1517e-05\n",
      "Epoch 315/500\n",
      "107/107 [==============================] - 106s 993ms/step - loss: 1.9900 - accuracy: 0.7353 - val_loss: 1.8671 - val_accuracy: 0.7458 - lr: 2.1302e-05\n",
      "Epoch 316/500\n",
      "107/107 [==============================] - 105s 985ms/step - loss: 1.9375 - accuracy: 0.7355 - val_loss: 1.9505 - val_accuracy: 0.7194 - lr: 2.1089e-05\n",
      "Epoch 317/500\n",
      "107/107 [==============================] - 105s 979ms/step - loss: 1.9873 - accuracy: 0.7435 - val_loss: 2.0650 - val_accuracy: 0.7254 - lr: 2.0878e-05\n",
      "Epoch 318/500\n",
      "107/107 [==============================] - 105s 980ms/step - loss: 2.0208 - accuracy: 0.7360 - val_loss: 2.1325 - val_accuracy: 0.7458 - lr: 2.0669e-05\n",
      "Epoch 319/500\n",
      "107/107 [==============================] - 107s 1000ms/step - loss: 2.1058 - accuracy: 0.7160 - val_loss: 2.2530 - val_accuracy: 0.7050 - lr: 2.0463e-05\n",
      "Epoch 320/500\n",
      "107/107 [==============================] - 106s 992ms/step - loss: 1.9559 - accuracy: 0.7440 - val_loss: 1.9724 - val_accuracy: 0.7230 - lr: 2.0258e-05\n",
      "Epoch 321/500\n",
      "107/107 [==============================] - 105s 983ms/step - loss: 2.0033 - accuracy: 0.7391 - val_loss: 2.5580 - val_accuracy: 0.7134 - lr: 2.0055e-05\n",
      "Epoch 322/500\n",
      "107/107 [==============================] - 105s 985ms/step - loss: 2.0212 - accuracy: 0.7323 - val_loss: 2.1160 - val_accuracy: 0.7302 - lr: 1.9855e-05\n",
      "Epoch 323/500\n",
      "107/107 [==============================] - 106s 988ms/step - loss: 1.9862 - accuracy: 0.7424 - val_loss: 2.0997 - val_accuracy: 0.7386 - lr: 1.9656e-05\n",
      "Epoch 324/500\n",
      "107/107 [==============================] - 105s 984ms/step - loss: 1.9844 - accuracy: 0.7395 - val_loss: 1.8599 - val_accuracy: 0.7458 - lr: 1.9460e-05\n",
      "Epoch 325/500\n",
      "107/107 [==============================] - 106s 992ms/step - loss: 2.0278 - accuracy: 0.7315 - val_loss: 2.0153 - val_accuracy: 0.7314 - lr: 1.9265e-05\n",
      "Epoch 326/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 2.0382 - accuracy: 0.7318 - val_loss: 2.0891 - val_accuracy: 0.7506 - lr: 1.9073e-05\n",
      "Epoch 327/500\n",
      "107/107 [==============================] - 104s 975ms/step - loss: 1.9284 - accuracy: 0.7480 - val_loss: 2.3060 - val_accuracy: 0.7074 - lr: 1.8882e-05\n",
      "Epoch 328/500\n",
      "107/107 [==============================] - 107s 996ms/step - loss: 1.9243 - accuracy: 0.7409 - val_loss: 2.3715 - val_accuracy: 0.7014 - lr: 1.8693e-05\n",
      "Epoch 329/500\n",
      "107/107 [==============================] - 106s 994ms/step - loss: 1.9781 - accuracy: 0.7388 - val_loss: 1.9360 - val_accuracy: 0.7182 - lr: 1.8506e-05\n",
      "Epoch 330/500\n",
      "107/107 [==============================] - 105s 979ms/step - loss: 1.9253 - accuracy: 0.7494 - val_loss: 2.0995 - val_accuracy: 0.7362 - lr: 1.8321e-05\n",
      "Epoch 331/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 2.0012 - accuracy: 0.7292 - val_loss: 2.2975 - val_accuracy: 0.7254 - lr: 1.8138e-05\n",
      "Epoch 332/500\n",
      "107/107 [==============================] - 104s 970ms/step - loss: 2.0865 - accuracy: 0.7327 - val_loss: 2.0783 - val_accuracy: 0.7266 - lr: 1.7956e-05\n",
      "Epoch 333/500\n",
      "107/107 [==============================] - 105s 986ms/step - loss: 2.0083 - accuracy: 0.7452 - val_loss: 1.9766 - val_accuracy: 0.7422 - lr: 1.7777e-05\n",
      "Epoch 334/500\n",
      "107/107 [==============================] - 106s 993ms/step - loss: 1.9464 - accuracy: 0.7379 - val_loss: 2.2638 - val_accuracy: 0.7218 - lr: 1.7599e-05\n",
      "Epoch 335/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 1.8684 - accuracy: 0.7398 - val_loss: 2.3255 - val_accuracy: 0.7146 - lr: 1.7423e-05\n",
      "Epoch 336/500\n",
      "107/107 [==============================] - 106s 986ms/step - loss: 1.9583 - accuracy: 0.7402 - val_loss: 2.1320 - val_accuracy: 0.7326 - lr: 1.7249e-05\n",
      "Epoch 337/500\n",
      "107/107 [==============================] - 106s 987ms/step - loss: 1.9191 - accuracy: 0.7400 - val_loss: 2.1573 - val_accuracy: 0.7410 - lr: 1.7076e-05\n",
      "Epoch 338/500\n",
      "107/107 [==============================] - 107s 999ms/step - loss: 2.1181 - accuracy: 0.7264 - val_loss: 2.1047 - val_accuracy: 0.7218 - lr: 1.6906e-05\n",
      "Epoch 339/500\n",
      "107/107 [==============================] - 105s 984ms/step - loss: 2.0234 - accuracy: 0.7381 - val_loss: 2.0971 - val_accuracy: 0.7146 - lr: 1.6737e-05\n",
      "Epoch 340/500\n",
      "107/107 [==============================] - 105s 977ms/step - loss: 1.9742 - accuracy: 0.7318 - val_loss: 2.2663 - val_accuracy: 0.7026 - lr: 1.6569e-05\n",
      "Epoch 341/500\n",
      "107/107 [==============================] - 106s 995ms/step - loss: 2.0322 - accuracy: 0.7485 - val_loss: 1.8881 - val_accuracy: 0.7626 - lr: 1.6403e-05\n",
      "Epoch 342/500\n",
      "107/107 [==============================] - 107s 997ms/step - loss: 1.9518 - accuracy: 0.7428 - val_loss: 2.2111 - val_accuracy: 0.7038 - lr: 1.6239e-05\n",
      "Epoch 343/500\n",
      "107/107 [==============================] - 106s 989ms/step - loss: 2.0775 - accuracy: 0.7250 - val_loss: 2.0651 - val_accuracy: 0.7074 - lr: 1.6077e-05\n",
      "Epoch 344/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 2.1276 - accuracy: 0.7245 - val_loss: 2.1214 - val_accuracy: 0.7518 - lr: 1.5916e-05\n",
      "Epoch 345/500\n",
      "107/107 [==============================] - 104s 976ms/step - loss: 2.1553 - accuracy: 0.7362 - val_loss: 2.2183 - val_accuracy: 0.7290 - lr: 1.5757e-05\n",
      "Epoch 346/500\n",
      "107/107 [==============================] - 106s 988ms/step - loss: 2.0086 - accuracy: 0.7346 - val_loss: 2.4183 - val_accuracy: 0.7182 - lr: 1.5600e-05\n",
      "Epoch 347/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 106s 989ms/step - loss: 2.0070 - accuracy: 0.7313 - val_loss: 2.0198 - val_accuracy: 0.7254 - lr: 1.5444e-05\n",
      "Epoch 348/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 2.0028 - accuracy: 0.7449 - val_loss: 2.1358 - val_accuracy: 0.7218 - lr: 1.5289e-05\n",
      "Epoch 349/500\n",
      "107/107 [==============================] - 107s 996ms/step - loss: 2.1125 - accuracy: 0.7301 - val_loss: 2.2428 - val_accuracy: 0.7290 - lr: 1.5136e-05\n",
      "Epoch 350/500\n",
      "107/107 [==============================] - 106s 994ms/step - loss: 2.0556 - accuracy: 0.7395 - val_loss: 2.1935 - val_accuracy: 0.7446 - lr: 1.4985e-05\n",
      "Epoch 351/500\n",
      "107/107 [==============================] - 106s 989ms/step - loss: 2.0784 - accuracy: 0.7417 - val_loss: 2.1314 - val_accuracy: 0.7326 - lr: 1.4835e-05\n",
      "Epoch 352/500\n",
      "107/107 [==============================] - 105s 985ms/step - loss: 2.0804 - accuracy: 0.7344 - val_loss: 2.1846 - val_accuracy: 0.7266 - lr: 1.4687e-05\n",
      "Epoch 353/500\n",
      "107/107 [==============================] - 105s 983ms/step - loss: 1.9699 - accuracy: 0.7346 - val_loss: 1.8991 - val_accuracy: 0.7446 - lr: 1.4540e-05\n",
      "Epoch 354/500\n",
      "107/107 [==============================] - 106s 989ms/step - loss: 1.9348 - accuracy: 0.7435 - val_loss: 2.2218 - val_accuracy: 0.7278 - lr: 1.4394e-05\n",
      "Epoch 355/500\n",
      "107/107 [==============================] - 105s 984ms/step - loss: 2.0648 - accuracy: 0.7421 - val_loss: 2.3991 - val_accuracy: 0.7170 - lr: 1.4250e-05\n",
      "Epoch 356/500\n",
      "107/107 [==============================] - 104s 975ms/step - loss: 2.1758 - accuracy: 0.7337 - val_loss: 2.2002 - val_accuracy: 0.7470 - lr: 1.4108e-05\n",
      "Epoch 357/500\n",
      "107/107 [==============================] - 107s 997ms/step - loss: 2.0126 - accuracy: 0.7388 - val_loss: 2.0208 - val_accuracy: 0.7302 - lr: 1.3967e-05\n",
      "Epoch 358/500\n",
      "107/107 [==============================] - 105s 977ms/step - loss: 2.0669 - accuracy: 0.7405 - val_loss: 2.1259 - val_accuracy: 0.7338 - lr: 1.3827e-05\n",
      "Epoch 359/500\n",
      "107/107 [==============================] - 105s 977ms/step - loss: 2.0243 - accuracy: 0.7414 - val_loss: 2.4009 - val_accuracy: 0.7350 - lr: 1.3689e-05\n",
      "Epoch 360/500\n",
      "107/107 [==============================] - 106s 995ms/step - loss: 1.9064 - accuracy: 0.7541 - val_loss: 1.9969 - val_accuracy: 0.7374 - lr: 1.3552e-05\n",
      "Epoch 361/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 2.1185 - accuracy: 0.7245 - val_loss: 2.2154 - val_accuracy: 0.7362 - lr: 1.3417e-05\n",
      "Epoch 362/500\n",
      "107/107 [==============================] - 106s 992ms/step - loss: 2.1346 - accuracy: 0.7468 - val_loss: 2.3087 - val_accuracy: 0.7218 - lr: 1.3282e-05\n",
      "Epoch 363/500\n",
      "107/107 [==============================] - 105s 981ms/step - loss: 2.1379 - accuracy: 0.7273 - val_loss: 1.9755 - val_accuracy: 0.7434 - lr: 1.3150e-05\n",
      "Epoch 364/500\n",
      "107/107 [==============================] - 106s 994ms/step - loss: 2.1071 - accuracy: 0.7325 - val_loss: 2.2076 - val_accuracy: 0.7398 - lr: 1.3018e-05\n",
      "Epoch 365/500\n",
      "107/107 [==============================] - 104s 972ms/step - loss: 1.9031 - accuracy: 0.7449 - val_loss: 2.2214 - val_accuracy: 0.7326 - lr: 1.2888e-05\n",
      "Epoch 366/500\n",
      "107/107 [==============================] - 107s 999ms/step - loss: 2.0385 - accuracy: 0.7391 - val_loss: 2.1399 - val_accuracy: 0.7482 - lr: 1.2759e-05\n",
      "Epoch 367/500\n",
      "107/107 [==============================] - 106s 995ms/step - loss: 2.1174 - accuracy: 0.7377 - val_loss: 2.2216 - val_accuracy: 0.7254 - lr: 1.2631e-05\n",
      "Epoch 368/500\n",
      "107/107 [==============================] - 104s 976ms/step - loss: 2.0482 - accuracy: 0.7433 - val_loss: 2.3917 - val_accuracy: 0.7170 - lr: 1.2505e-05\n",
      "Epoch 369/500\n",
      "107/107 [==============================] - 106s 995ms/step - loss: 2.1122 - accuracy: 0.7454 - val_loss: 2.1446 - val_accuracy: 0.7206 - lr: 1.2380e-05\n",
      "Epoch 370/500\n",
      "107/107 [==============================] - 104s 976ms/step - loss: 2.0646 - accuracy: 0.7348 - val_loss: 2.3332 - val_accuracy: 0.7170 - lr: 1.2256e-05\n",
      "Epoch 371/500\n",
      "107/107 [==============================] - 105s 985ms/step - loss: 2.1330 - accuracy: 0.7320 - val_loss: 2.6511 - val_accuracy: 0.7230 - lr: 1.2134e-05\n",
      "Epoch 372/500\n",
      "107/107 [==============================] - 106s 987ms/step - loss: 2.0966 - accuracy: 0.7409 - val_loss: 1.9802 - val_accuracy: 0.7482 - lr: 1.2012e-05\n",
      "Epoch 373/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 2.0914 - accuracy: 0.7365 - val_loss: 2.6605 - val_accuracy: 0.7014 - lr: 1.1892e-05\n",
      "Epoch 374/500\n",
      "107/107 [==============================] - 105s 982ms/step - loss: 2.0679 - accuracy: 0.7421 - val_loss: 2.2981 - val_accuracy: 0.7278 - lr: 1.1773e-05\n",
      "Epoch 375/500\n",
      "107/107 [==============================] - 106s 994ms/step - loss: 1.9858 - accuracy: 0.7433 - val_loss: 2.2775 - val_accuracy: 0.7206 - lr: 1.1656e-05\n",
      "Epoch 376/500\n",
      "107/107 [==============================] - 107s 995ms/step - loss: 2.1621 - accuracy: 0.7315 - val_loss: 2.1028 - val_accuracy: 0.7518 - lr: 1.1539e-05\n",
      "Epoch 377/500\n",
      "107/107 [==============================] - 105s 984ms/step - loss: 2.1490 - accuracy: 0.7259 - val_loss: 2.4727 - val_accuracy: 0.7110 - lr: 1.1424e-05\n",
      "Epoch 378/500\n",
      "107/107 [==============================] - 104s 975ms/step - loss: 2.1222 - accuracy: 0.7245 - val_loss: 2.0637 - val_accuracy: 0.7350 - lr: 1.1309e-05\n",
      "Epoch 379/500\n",
      "107/107 [==============================] - 105s 982ms/step - loss: 2.1078 - accuracy: 0.7339 - val_loss: 2.4795 - val_accuracy: 0.7194 - lr: 1.1196e-05\n",
      "Epoch 380/500\n",
      "107/107 [==============================] - 106s 990ms/step - loss: 2.0662 - accuracy: 0.7351 - val_loss: 2.3315 - val_accuracy: 0.6978 - lr: 1.1084e-05\n",
      "Epoch 381/500\n",
      "107/107 [==============================] - 106s 992ms/step - loss: 2.2143 - accuracy: 0.7247 - val_loss: 2.0986 - val_accuracy: 0.7266 - lr: 1.0973e-05\n",
      "Epoch 382/500\n",
      "107/107 [==============================] - 106s 992ms/step - loss: 2.1094 - accuracy: 0.7320 - val_loss: 2.0516 - val_accuracy: 0.7362 - lr: 1.0864e-05\n",
      "Epoch 383/500\n",
      "107/107 [==============================] - 106s 988ms/step - loss: 2.1981 - accuracy: 0.7304 - val_loss: 2.1992 - val_accuracy: 0.7206 - lr: 1.0755e-05\n",
      "Epoch 384/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 2.0541 - accuracy: 0.7405 - val_loss: 2.0450 - val_accuracy: 0.7458 - lr: 1.0648e-05\n",
      "Epoch 385/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 2.0755 - accuracy: 0.7405 - val_loss: 2.2786 - val_accuracy: 0.7170 - lr: 1.0541e-05\n",
      "Epoch 386/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 2.1055 - accuracy: 0.7315 - val_loss: 2.4730 - val_accuracy: 0.7362 - lr: 1.0436e-05\n",
      "Epoch 387/500\n",
      "107/107 [==============================] - 107s 999ms/step - loss: 2.1260 - accuracy: 0.7370 - val_loss: 2.2286 - val_accuracy: 0.7566 - lr: 1.0331e-05\n",
      "Epoch 388/500\n",
      "107/107 [==============================] - 106s 995ms/step - loss: 2.0733 - accuracy: 0.7400 - val_loss: 2.1719 - val_accuracy: 0.7326 - lr: 1.0228e-05\n",
      "Epoch 389/500\n",
      "107/107 [==============================] - 106s 994ms/step - loss: 2.0901 - accuracy: 0.7407 - val_loss: 2.2069 - val_accuracy: 0.7290 - lr: 1.0126e-05\n",
      "Epoch 390/500\n",
      "107/107 [==============================] - 106s 988ms/step - loss: 2.1340 - accuracy: 0.7391 - val_loss: 2.3869 - val_accuracy: 0.6954 - lr: 1.0024e-05\n",
      "Epoch 391/500\n",
      "107/107 [==============================] - 107s 998ms/step - loss: 2.2375 - accuracy: 0.7442 - val_loss: 2.4124 - val_accuracy: 0.7158 - lr: 9.9242e-06\n",
      "Epoch 392/500\n",
      "107/107 [==============================] - 106s 994ms/step - loss: 2.1092 - accuracy: 0.7358 - val_loss: 2.2708 - val_accuracy: 0.7278 - lr: 9.8250e-06\n",
      "Epoch 393/500\n",
      "107/107 [==============================] - 106s 990ms/step - loss: 2.2110 - accuracy: 0.7393 - val_loss: 2.2109 - val_accuracy: 0.7518 - lr: 9.7267e-06\n",
      "Epoch 394/500\n",
      "107/107 [==============================] - 107s 999ms/step - loss: 2.1510 - accuracy: 0.7330 - val_loss: 2.4827 - val_accuracy: 0.7338 - lr: 9.6294e-06\n",
      "Epoch 395/500\n",
      "107/107 [==============================] - 105s 983ms/step - loss: 2.1771 - accuracy: 0.7374 - val_loss: 2.1101 - val_accuracy: 0.7302 - lr: 9.5332e-06\n",
      "Epoch 396/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 107s 996ms/step - loss: 2.0685 - accuracy: 0.7452 - val_loss: 2.2079 - val_accuracy: 0.7326 - lr: 9.4378e-06\n",
      "Epoch 397/500\n",
      "107/107 [==============================] - 109s 1s/step - loss: 2.1742 - accuracy: 0.7431 - val_loss: 2.0226 - val_accuracy: 0.7518 - lr: 9.3434e-06\n",
      "Epoch 398/500\n",
      "107/107 [==============================] - 107s 999ms/step - loss: 2.1586 - accuracy: 0.7351 - val_loss: 2.2845 - val_accuracy: 0.7278 - lr: 9.2500e-06\n",
      "Epoch 399/500\n",
      "107/107 [==============================] - 105s 984ms/step - loss: 2.0922 - accuracy: 0.7365 - val_loss: 2.2844 - val_accuracy: 0.7398 - lr: 9.1575e-06\n",
      "Epoch 400/500\n",
      "107/107 [==============================] - 106s 986ms/step - loss: 2.1161 - accuracy: 0.7334 - val_loss: 2.2164 - val_accuracy: 0.7446 - lr: 9.0659e-06\n",
      "Epoch 401/500\n",
      "107/107 [==============================] - 106s 993ms/step - loss: 2.2735 - accuracy: 0.7280 - val_loss: 2.3107 - val_accuracy: 0.7338 - lr: 8.9753e-06\n",
      "Epoch 402/500\n",
      "107/107 [==============================] - 106s 990ms/step - loss: 2.0851 - accuracy: 0.7442 - val_loss: 2.1778 - val_accuracy: 0.7182 - lr: 8.8855e-06\n",
      "Epoch 403/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 2.1888 - accuracy: 0.7379 - val_loss: 2.5054 - val_accuracy: 0.7434 - lr: 8.7967e-06\n",
      "Epoch 404/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 2.1374 - accuracy: 0.7424 - val_loss: 2.3969 - val_accuracy: 0.7290 - lr: 8.7087e-06\n",
      "Epoch 405/500\n",
      "107/107 [==============================] - 105s 983ms/step - loss: 1.9671 - accuracy: 0.7457 - val_loss: 2.1604 - val_accuracy: 0.7338 - lr: 8.6216e-06\n",
      "Epoch 406/500\n",
      "107/107 [==============================] - 105s 982ms/step - loss: 2.1165 - accuracy: 0.7384 - val_loss: 2.2982 - val_accuracy: 0.7182 - lr: 8.5354e-06\n",
      "Epoch 407/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 2.1592 - accuracy: 0.7452 - val_loss: 2.1953 - val_accuracy: 0.7266 - lr: 8.4500e-06\n",
      "Epoch 408/500\n",
      "107/107 [==============================] - 107s 999ms/step - loss: 2.2001 - accuracy: 0.7332 - val_loss: 1.9915 - val_accuracy: 0.7578 - lr: 8.3655e-06\n",
      "Epoch 409/500\n",
      "107/107 [==============================] - 106s 989ms/step - loss: 2.1836 - accuracy: 0.7294 - val_loss: 2.4609 - val_accuracy: 0.7122 - lr: 8.2819e-06\n",
      "Epoch 410/500\n",
      "107/107 [==============================] - 107s 996ms/step - loss: 2.0751 - accuracy: 0.7365 - val_loss: 2.0138 - val_accuracy: 0.7446 - lr: 8.1991e-06\n",
      "Epoch 411/500\n",
      "107/107 [==============================] - 106s 992ms/step - loss: 2.0568 - accuracy: 0.7374 - val_loss: 2.1372 - val_accuracy: 0.7434 - lr: 8.1171e-06\n",
      "Epoch 412/500\n",
      "107/107 [==============================] - 105s 986ms/step - loss: 2.2706 - accuracy: 0.7318 - val_loss: 2.1344 - val_accuracy: 0.7386 - lr: 8.0359e-06\n",
      "Epoch 413/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 2.1989 - accuracy: 0.7384 - val_loss: 2.3616 - val_accuracy: 0.7170 - lr: 7.9555e-06\n",
      "Epoch 414/500\n",
      "107/107 [==============================] - 105s 986ms/step - loss: 2.0382 - accuracy: 0.7358 - val_loss: 2.2113 - val_accuracy: 0.7242 - lr: 7.8760e-06\n",
      "Epoch 415/500\n",
      "107/107 [==============================] - 104s 971ms/step - loss: 2.0670 - accuracy: 0.7419 - val_loss: 2.1192 - val_accuracy: 0.7158 - lr: 7.7972e-06\n",
      "Epoch 416/500\n",
      "107/107 [==============================] - 106s 988ms/step - loss: 2.1787 - accuracy: 0.7285 - val_loss: 2.2986 - val_accuracy: 0.7086 - lr: 7.7193e-06\n",
      "Epoch 417/500\n",
      "107/107 [==============================] - 106s 994ms/step - loss: 2.0341 - accuracy: 0.7402 - val_loss: 2.2145 - val_accuracy: 0.7518 - lr: 7.6421e-06\n",
      "Epoch 418/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 2.1219 - accuracy: 0.7466 - val_loss: 2.4987 - val_accuracy: 0.6978 - lr: 7.5656e-06\n",
      "Epoch 419/500\n",
      "107/107 [==============================] - 103s 966ms/step - loss: 2.0811 - accuracy: 0.7287 - val_loss: 2.3458 - val_accuracy: 0.7194 - lr: 7.4900e-06\n",
      "Epoch 420/500\n",
      "107/107 [==============================] - 105s 979ms/step - loss: 2.2504 - accuracy: 0.7259 - val_loss: 2.4677 - val_accuracy: 0.7374 - lr: 7.4151e-06\n",
      "Epoch 421/500\n",
      "107/107 [==============================] - 106s 990ms/step - loss: 2.1136 - accuracy: 0.7405 - val_loss: 3.0984 - val_accuracy: 0.6811 - lr: 7.3409e-06\n",
      "Epoch 422/500\n",
      "107/107 [==============================] - 106s 994ms/step - loss: 2.1004 - accuracy: 0.7377 - val_loss: 2.0920 - val_accuracy: 0.7410 - lr: 7.2675e-06\n",
      "Epoch 423/500\n",
      "107/107 [==============================] - 105s 985ms/step - loss: 2.0283 - accuracy: 0.7454 - val_loss: 1.9899 - val_accuracy: 0.7506 - lr: 7.1949e-06\n",
      "Epoch 424/500\n",
      "107/107 [==============================] - 107s 999ms/step - loss: 2.1797 - accuracy: 0.7381 - val_loss: 2.1259 - val_accuracy: 0.7170 - lr: 7.1229e-06\n",
      "Epoch 425/500\n",
      "107/107 [==============================] - 105s 979ms/step - loss: 2.0755 - accuracy: 0.7447 - val_loss: 2.3882 - val_accuracy: 0.7266 - lr: 7.0517e-06\n",
      "Epoch 426/500\n",
      "107/107 [==============================] - 107s 996ms/step - loss: 2.0451 - accuracy: 0.7480 - val_loss: 2.1479 - val_accuracy: 0.7506 - lr: 6.9812e-06\n",
      "Epoch 427/500\n",
      "107/107 [==============================] - 107s 999ms/step - loss: 2.0615 - accuracy: 0.7409 - val_loss: 2.5405 - val_accuracy: 0.7158 - lr: 6.9114e-06\n",
      "Epoch 428/500\n",
      "107/107 [==============================] - 106s 990ms/step - loss: 2.0373 - accuracy: 0.7367 - val_loss: 2.0975 - val_accuracy: 0.7506 - lr: 6.8422e-06\n",
      "Epoch 429/500\n",
      "107/107 [==============================] - 105s 982ms/step - loss: 2.0466 - accuracy: 0.7468 - val_loss: 2.1823 - val_accuracy: 0.7194 - lr: 6.7738e-06\n",
      "Epoch 430/500\n",
      "107/107 [==============================] - 106s 995ms/step - loss: 2.2056 - accuracy: 0.7414 - val_loss: 2.2689 - val_accuracy: 0.7254 - lr: 6.7061e-06\n",
      "Epoch 431/500\n",
      "107/107 [==============================] - 105s 985ms/step - loss: 2.1462 - accuracy: 0.7417 - val_loss: 1.9889 - val_accuracy: 0.7422 - lr: 6.6390e-06\n",
      "Epoch 432/500\n",
      "107/107 [==============================] - 107s 999ms/step - loss: 2.1160 - accuracy: 0.7365 - val_loss: 2.3344 - val_accuracy: 0.7362 - lr: 6.5726e-06\n",
      "Epoch 433/500\n",
      "107/107 [==============================] - 106s 994ms/step - loss: 2.1857 - accuracy: 0.7482 - val_loss: 1.9876 - val_accuracy: 0.7686 - lr: 6.5069e-06\n",
      "Epoch 434/500\n",
      "107/107 [==============================] - 106s 994ms/step - loss: 2.1286 - accuracy: 0.7339 - val_loss: 2.2346 - val_accuracy: 0.7182 - lr: 6.4418e-06\n",
      "Epoch 435/500\n",
      "107/107 [==============================] - 107s 998ms/step - loss: 2.2029 - accuracy: 0.7313 - val_loss: 2.3219 - val_accuracy: 0.7326 - lr: 6.3774e-06\n",
      "Epoch 436/500\n",
      "107/107 [==============================] - 106s 990ms/step - loss: 2.1623 - accuracy: 0.7370 - val_loss: 2.2366 - val_accuracy: 0.7278 - lr: 6.3136e-06\n",
      "Epoch 437/500\n",
      "107/107 [==============================] - 105s 977ms/step - loss: 1.9705 - accuracy: 0.7475 - val_loss: 2.5339 - val_accuracy: 0.6942 - lr: 6.2505e-06\n",
      "Epoch 438/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 2.1296 - accuracy: 0.7421 - val_loss: 2.0069 - val_accuracy: 0.7626 - lr: 6.1880e-06\n",
      "Epoch 439/500\n",
      "107/107 [==============================] - 106s 990ms/step - loss: 2.1974 - accuracy: 0.7353 - val_loss: 2.2139 - val_accuracy: 0.7254 - lr: 6.1261e-06\n",
      "Epoch 440/500\n",
      "107/107 [==============================] - 107s 998ms/step - loss: 2.0632 - accuracy: 0.7386 - val_loss: 1.9815 - val_accuracy: 0.7518 - lr: 6.0649e-06\n",
      "Epoch 441/500\n",
      "107/107 [==============================] - 105s 981ms/step - loss: 2.2037 - accuracy: 0.7341 - val_loss: 2.4180 - val_accuracy: 0.7242 - lr: 6.0042e-06\n",
      "Epoch 442/500\n",
      "107/107 [==============================] - 106s 990ms/step - loss: 2.1404 - accuracy: 0.7424 - val_loss: 2.1289 - val_accuracy: 0.7554 - lr: 5.9442e-06\n",
      "Epoch 443/500\n",
      "107/107 [==============================] - 106s 993ms/step - loss: 2.1096 - accuracy: 0.7311 - val_loss: 2.3215 - val_accuracy: 0.7254 - lr: 5.8847e-06\n",
      "Epoch 444/500\n",
      "107/107 [==============================] - 104s 972ms/step - loss: 2.1349 - accuracy: 0.7457 - val_loss: 1.8904 - val_accuracy: 0.7554 - lr: 5.8259e-06\n",
      "Epoch 445/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 107s 1s/step - loss: 2.0696 - accuracy: 0.7412 - val_loss: 2.3831 - val_accuracy: 0.7278 - lr: 5.7676e-06\n",
      "Epoch 446/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 2.1579 - accuracy: 0.7358 - val_loss: 2.4699 - val_accuracy: 0.7098 - lr: 5.7099e-06\n",
      "Epoch 447/500\n",
      "107/107 [==============================] - 105s 986ms/step - loss: 2.0147 - accuracy: 0.7426 - val_loss: 2.4635 - val_accuracy: 0.7218 - lr: 5.6528e-06\n",
      "Epoch 448/500\n",
      "107/107 [==============================] - 103s 967ms/step - loss: 2.1189 - accuracy: 0.7351 - val_loss: 2.2302 - val_accuracy: 0.7230 - lr: 5.5963e-06\n",
      "Epoch 449/500\n",
      "107/107 [==============================] - 105s 984ms/step - loss: 2.1789 - accuracy: 0.7370 - val_loss: 2.2219 - val_accuracy: 0.7530 - lr: 5.5403e-06\n",
      "Epoch 450/500\n",
      "107/107 [==============================] - 105s 979ms/step - loss: 2.0995 - accuracy: 0.7402 - val_loss: 2.1800 - val_accuracy: 0.7314 - lr: 5.4849e-06\n",
      "Epoch 451/500\n",
      "107/107 [==============================] - 107s 996ms/step - loss: 2.1654 - accuracy: 0.7374 - val_loss: 2.4709 - val_accuracy: 0.7338 - lr: 5.4301e-06\n",
      "Epoch 452/500\n",
      "107/107 [==============================] - 107s 997ms/step - loss: 2.0785 - accuracy: 0.7520 - val_loss: 1.9847 - val_accuracy: 0.7434 - lr: 5.3758e-06\n",
      "Epoch 453/500\n",
      "107/107 [==============================] - 106s 990ms/step - loss: 2.1950 - accuracy: 0.7280 - val_loss: 2.5604 - val_accuracy: 0.7338 - lr: 5.3220e-06\n",
      "Epoch 454/500\n",
      "107/107 [==============================] - 107s 997ms/step - loss: 2.1670 - accuracy: 0.7412 - val_loss: 2.2044 - val_accuracy: 0.7266 - lr: 5.2688e-06\n",
      "Epoch 455/500\n",
      "107/107 [==============================] - 106s 995ms/step - loss: 2.0246 - accuracy: 0.7457 - val_loss: 2.1480 - val_accuracy: 0.7362 - lr: 5.2161e-06\n",
      "Epoch 456/500\n",
      "107/107 [==============================] - 105s 981ms/step - loss: 2.0730 - accuracy: 0.7348 - val_loss: 2.3762 - val_accuracy: 0.7314 - lr: 5.1640e-06\n",
      "Epoch 457/500\n",
      "107/107 [==============================] - 106s 992ms/step - loss: 2.1349 - accuracy: 0.7407 - val_loss: 2.2604 - val_accuracy: 0.7350 - lr: 5.1123e-06\n",
      "Epoch 458/500\n",
      "107/107 [==============================] - 107s 997ms/step - loss: 2.1690 - accuracy: 0.7508 - val_loss: 2.6095 - val_accuracy: 0.7170 - lr: 5.0612e-06\n",
      "Epoch 459/500\n",
      "107/107 [==============================] - 105s 977ms/step - loss: 2.0437 - accuracy: 0.7445 - val_loss: 2.4679 - val_accuracy: 0.7170 - lr: 5.0106e-06\n",
      "Epoch 460/500\n",
      "107/107 [==============================] - 106s 993ms/step - loss: 2.1836 - accuracy: 0.7435 - val_loss: 2.3742 - val_accuracy: 0.7206 - lr: 4.9605e-06\n",
      "Epoch 461/500\n",
      "107/107 [==============================] - 106s 995ms/step - loss: 2.2472 - accuracy: 0.7346 - val_loss: 2.2290 - val_accuracy: 0.7122 - lr: 4.9109e-06\n",
      "Epoch 462/500\n",
      "107/107 [==============================] - 105s 981ms/step - loss: 2.2312 - accuracy: 0.7365 - val_loss: 2.5129 - val_accuracy: 0.7026 - lr: 4.8618e-06\n",
      "Epoch 463/500\n",
      "107/107 [==============================] - 104s 974ms/step - loss: 2.1120 - accuracy: 0.7471 - val_loss: 2.6257 - val_accuracy: 0.7026 - lr: 4.8132e-06\n",
      "Epoch 464/500\n",
      "107/107 [==============================] - 109s 1s/step - loss: 2.0230 - accuracy: 0.7576 - val_loss: 2.3123 - val_accuracy: 0.7506 - lr: 4.7650e-06\n",
      "Epoch 465/500\n",
      "107/107 [==============================] - 104s 971ms/step - loss: 2.1617 - accuracy: 0.7395 - val_loss: 2.3892 - val_accuracy: 0.7470 - lr: 4.7174e-06\n",
      "Epoch 466/500\n",
      "107/107 [==============================] - 107s 997ms/step - loss: 2.0554 - accuracy: 0.7424 - val_loss: 2.3316 - val_accuracy: 0.7218 - lr: 4.6702e-06\n",
      "Epoch 467/500\n",
      "107/107 [==============================] - 103s 966ms/step - loss: 2.2436 - accuracy: 0.7454 - val_loss: 2.1005 - val_accuracy: 0.7446 - lr: 4.6235e-06\n",
      "Epoch 468/500\n",
      "107/107 [==============================] - 106s 990ms/step - loss: 2.2385 - accuracy: 0.7285 - val_loss: 2.3152 - val_accuracy: 0.7278 - lr: 4.5773e-06\n",
      "Epoch 469/500\n",
      "107/107 [==============================] - 108s 1s/step - loss: 2.2614 - accuracy: 0.7243 - val_loss: 2.0988 - val_accuracy: 0.7494 - lr: 4.5315e-06\n",
      "Epoch 470/500\n",
      "107/107 [==============================] - 106s 989ms/step - loss: 2.1978 - accuracy: 0.7339 - val_loss: 2.2953 - val_accuracy: 0.7158 - lr: 4.4862e-06\n",
      "Epoch 471/500\n",
      "107/107 [==============================] - 106s 987ms/step - loss: 2.0364 - accuracy: 0.7529 - val_loss: 2.3109 - val_accuracy: 0.7398 - lr: 4.4413e-06\n",
      "Epoch 472/500\n",
      "107/107 [==============================] - 106s 993ms/step - loss: 2.1522 - accuracy: 0.7379 - val_loss: 2.2597 - val_accuracy: 0.7386 - lr: 4.3969e-06\n",
      "Epoch 473/500\n",
      "107/107 [==============================] - 104s 976ms/step - loss: 2.1333 - accuracy: 0.7412 - val_loss: 2.1528 - val_accuracy: 0.7614 - lr: 4.3529e-06\n",
      "Epoch 474/500\n",
      "107/107 [==============================] - 104s 976ms/step - loss: 2.0380 - accuracy: 0.7341 - val_loss: 2.1350 - val_accuracy: 0.7326 - lr: 4.3094e-06\n",
      "Epoch 475/500\n",
      "107/107 [==============================] - 104s 971ms/step - loss: 2.2000 - accuracy: 0.7276 - val_loss: 2.3643 - val_accuracy: 0.7254 - lr: 4.2663e-06\n",
      "Epoch 476/500\n",
      "107/107 [==============================] - 106s 994ms/step - loss: 2.1229 - accuracy: 0.7449 - val_loss: 2.1602 - val_accuracy: 0.7362 - lr: 4.2236e-06\n",
      "Epoch 477/500\n",
      "107/107 [==============================] - 104s 969ms/step - loss: 2.2238 - accuracy: 0.7374 - val_loss: 2.3816 - val_accuracy: 0.7338 - lr: 4.1814e-06\n",
      "Epoch 478/500\n",
      "107/107 [==============================] - 106s 990ms/step - loss: 2.1742 - accuracy: 0.7355 - val_loss: 1.9801 - val_accuracy: 0.7494 - lr: 4.1396e-06\n",
      "Epoch 479/500\n",
      "107/107 [==============================] - 106s 989ms/step - loss: 2.3465 - accuracy: 0.7327 - val_loss: 2.3474 - val_accuracy: 0.7446 - lr: 4.0982e-06\n",
      "Epoch 480/500\n",
      "107/107 [==============================] - 106s 990ms/step - loss: 2.0753 - accuracy: 0.7421 - val_loss: 2.3116 - val_accuracy: 0.7290 - lr: 4.0572e-06\n",
      "Epoch 481/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 2.3244 - accuracy: 0.7261 - val_loss: 2.3169 - val_accuracy: 0.7266 - lr: 4.0166e-06\n",
      "Epoch 482/500\n",
      "107/107 [==============================] - 107s 996ms/step - loss: 2.1597 - accuracy: 0.7454 - val_loss: 2.4213 - val_accuracy: 0.7266 - lr: 3.9765e-06\n",
      "Epoch 483/500\n",
      "107/107 [==============================] - 106s 990ms/step - loss: 2.2035 - accuracy: 0.7332 - val_loss: 2.0153 - val_accuracy: 0.7302 - lr: 3.9367e-06\n",
      "Epoch 484/500\n",
      "107/107 [==============================] - 104s 972ms/step - loss: 2.2497 - accuracy: 0.7250 - val_loss: 2.7060 - val_accuracy: 0.7218 - lr: 3.8973e-06\n",
      "Epoch 485/500\n",
      "107/107 [==============================] - 105s 980ms/step - loss: 2.1979 - accuracy: 0.7360 - val_loss: 2.0253 - val_accuracy: 0.7302 - lr: 3.8584e-06\n",
      "Epoch 486/500\n",
      "107/107 [==============================] - 106s 988ms/step - loss: 2.2836 - accuracy: 0.7285 - val_loss: 2.0069 - val_accuracy: 0.7218 - lr: 3.8198e-06\n",
      "Epoch 487/500\n",
      "107/107 [==============================] - 106s 991ms/step - loss: 2.2788 - accuracy: 0.7311 - val_loss: 2.2225 - val_accuracy: 0.7446 - lr: 3.7816e-06\n",
      "Epoch 488/500\n",
      "107/107 [==============================] - 102s 955ms/step - loss: 2.2747 - accuracy: 0.7297 - val_loss: 2.5273 - val_accuracy: 0.7350 - lr: 3.7438e-06\n",
      "Epoch 489/500\n",
      "107/107 [==============================] - 106s 995ms/step - loss: 2.0960 - accuracy: 0.7388 - val_loss: 2.6001 - val_accuracy: 0.7062 - lr: 3.7063e-06\n",
      "Epoch 490/500\n",
      "107/107 [==============================] - 105s 979ms/step - loss: 2.2216 - accuracy: 0.7276 - val_loss: 2.3112 - val_accuracy: 0.7386 - lr: 3.6693e-06\n",
      "Epoch 491/500\n",
      "107/107 [==============================] - 103s 966ms/step - loss: 2.1414 - accuracy: 0.7409 - val_loss: 1.9573 - val_accuracy: 0.7650 - lr: 3.6326e-06\n",
      "Epoch 492/500\n",
      "107/107 [==============================] - 105s 978ms/step - loss: 2.2793 - accuracy: 0.7285 - val_loss: 3.0005 - val_accuracy: 0.7014 - lr: 3.5963e-06\n",
      "Epoch 493/500\n",
      "107/107 [==============================] - 107s 1s/step - loss: 2.1164 - accuracy: 0.7362 - val_loss: 2.2126 - val_accuracy: 0.7230 - lr: 3.5603e-06\n",
      "Epoch 494/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 108s 1s/step - loss: 2.2474 - accuracy: 0.7367 - val_loss: 2.2612 - val_accuracy: 0.7470 - lr: 3.5247e-06\n",
      "Epoch 495/500\n",
      "107/107 [==============================] - 106s 989ms/step - loss: 2.0715 - accuracy: 0.7464 - val_loss: 2.4015 - val_accuracy: 0.7206 - lr: 3.4894e-06\n",
      "Epoch 496/500\n",
      "107/107 [==============================] - 104s 976ms/step - loss: 2.3660 - accuracy: 0.7247 - val_loss: 2.2027 - val_accuracy: 0.7290 - lr: 3.4545e-06\n",
      "Epoch 497/500\n",
      "107/107 [==============================] - 103s 965ms/step - loss: 2.0783 - accuracy: 0.7379 - val_loss: 2.4881 - val_accuracy: 0.7122 - lr: 3.4200e-06\n",
      "Epoch 498/500\n",
      "107/107 [==============================] - 106s 995ms/step - loss: 2.3293 - accuracy: 0.7250 - val_loss: 2.6133 - val_accuracy: 0.7242 - lr: 3.3858e-06\n",
      "Epoch 499/500\n",
      "107/107 [==============================] - 105s 978ms/step - loss: 2.2615 - accuracy: 0.7365 - val_loss: 2.4878 - val_accuracy: 0.7230 - lr: 3.3519e-06\n",
      "Epoch 500/500\n",
      "107/107 [==============================] - 106s 990ms/step - loss: 2.2415 - accuracy: 0.7334 - val_loss: 2.2454 - val_accuracy: 0.7530 - lr: 3.3184e-06\n"
     ]
    }
   ],
   "source": [
    "model.compile(Adam(lr=.0002), loss='categorical_crossentropy', metrics= ['accuracy'])\n",
    "history2= model.fit_generator(train_batches, steps_per_epoch= len(train_batches) , callbacks=[reduce_lr],\n",
    "                             validation_data=test_batches, validation_steps= len(test_batches), \n",
    "                             epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/save-load-keras-deep-learning-models/\n",
    "\n",
    "model.save('/home/ordovas/IRONHACK/dice-scores-recognition/model_d6_augmented.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/home/ordovas/IRONHACK/dice-scores-recognition/model_d6_augmented.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
