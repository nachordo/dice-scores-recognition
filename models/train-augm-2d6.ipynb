{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "from tensorflow.keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5', '1', '4', '3', '6', '2']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir('../own_dataset/2d6/train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path= ('../own_dataset/2d6/train')\n",
    "test_path= ('../own_dataset/2d6/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3790 images belonging to 6 classes.\n",
      "Found 771 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size_train=30  #,batch_size= batch_size_train\n",
    "batch_size_valid=30\n",
    "targetsize= 100\n",
    "datagen=ImageDataGenerator(rotation_range=180,height_shift_range=0.1,rescale=1.0/255.0\n",
    "                           ,zoom_range=[0.7,1.1],brightness_range=[0.4,1.2])\n",
    "train_batches= datagen.flow_from_directory(train_path, target_size=(targetsize,targetsize), \n",
    "                                                                      classes=os.listdir('../own_dataset/2d6/train'),\n",
    "                                                                      batch_size= batch_size_train)\n",
    "test_batches= datagen.flow_from_directory(test_path,  target_size=(targetsize,targetsize), \n",
    "                                                                     classes=os.listdir('../own_dataset/2d6/train'),\n",
    "                                                                     batch_size= batch_size_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(ims, figsize=(20,10), rows=1, interp= False, titles= None):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims= ims.transpose((0,1,2,3))\n",
    "    f= plt.figure(figsize=figsize)\n",
    "    cols= len(ims)//rows if len(ims) %2 == 0 else len(ims)//rows + 1\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=12)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-3 *0.95**x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nnfilters = [8, 16]\\nkernel_sizes = [(4,4), (2,2)]\\n\\n\\nmodel = Sequential()\\n# CONV1 (ReLU) > POOL1\\nmodel.add(Conv2D(nfilters[0], kernel_sizes[0], # 8 filters, 4x4\\n                 strides=(1,1),\\n                 padding='same', \\n                 input_shape=(targetsize,targetsize, 3),activation='relu'))\\nmodel.add(MaxPooling2D(pool_size=(8,8),\\n                       strides=(8,8),\\n                       padding='same'))\\n# CONV2 (ReLU) > POOL2\\nmodel.add(Conv2D(nfilters[1], kernel_sizes[1], # 16 filters, 2x2\\n                 strides=(1,1),\\n                 padding='same',activation='relu'))\\nmodel.add(MaxPooling2D(pool_size=(4,4),\\n                       strides=(4,4),\\n                       padding='same'))\\n\\n# Fully connected layer with softmax\\nmodel.add(Flatten())\\nmodel.add(Dense(6, activation='softmax'))\\nmodel.summary()\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "nfilters = [8, 16]\n",
    "kernel_sizes = [(4,4), (2,2)]\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "# CONV1 (ReLU) > POOL1\n",
    "model.add(Conv2D(nfilters[0], kernel_sizes[0], # 8 filters, 4x4\n",
    "                 strides=(1,1),\n",
    "                 padding='same', \n",
    "                 input_shape=(targetsize,targetsize, 3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(8,8),\n",
    "                       strides=(8,8),\n",
    "                       padding='same'))\n",
    "# CONV2 (ReLU) > POOL2\n",
    "model.add(Conv2D(nfilters[1], kernel_sizes[1], # 16 filters, 2x2\n",
    "                 strides=(1,1),\n",
    "                 padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(4,4),\n",
    "                       strides=(4,4),\n",
    "                       padding='same'))\n",
    "\n",
    "# Fully connected layer with softmax\n",
    "model.add(Flatten())\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.summary()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmodel.compile(Adam(lr=.0002), loss='categorical_crossentropy', metrics= ['accuracy'])\\nhistory= model.fit_generator(train_batches, steps_per_epoch= len(train_batches) , callbacks=[reduce_lr],\\n                             validation_data=train_batches, validation_steps= len(train_batches), \\n                             epochs=500)\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "model.compile(Adam(lr=.0002), loss='categorical_crossentropy', metrics= ['accuracy'])\n",
    "history= model.fit_generator(train_batches, steps_per_epoch= len(train_batches) , callbacks=[reduce_lr],\n",
    "                             validation_data=train_batches, validation_steps= len(train_batches), \n",
    "                             epochs=500)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cp_callback=tf.keras.callbacks.ModelCheckpoint(filepath=os.getcwd(),save_weights_only=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('/home/ordovas/IRONHACK/dice-scores-recognition/model_d6_augmented_c1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 100, 100, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 50, 50, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 25, 25, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 55302     \n",
      "=================================================================\n",
      "Total params: 443,718\n",
      "Trainable params: 443,718\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(targetsize,targetsize, 3)) )\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model2.add(Conv2D(filters=64, kernel_size=(3,3), padding='SAME', activation='relu'))\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "model2.add(Conv2D(filters=128, kernel_size=(3,3), padding='SAME', activation='relu'))\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model2.add(Conv2D(filters=256, kernel_size=(3,3), padding='SAME', activation='relu'))\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "#model2.add(Conv2D(filters=512, kernel_size=(3,3), padding='SAME', activation='relu'))\n",
    "#model2.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(6, activation='softmax'))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-4172cec10be9>:2: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/500\n",
      "127/127 [==============================] - 104s 823ms/step - loss: 1.7833 - accuracy: 0.1887 - val_loss: 1.7776 - val_accuracy: 0.1907\n",
      "Epoch 2/500\n",
      "127/127 [==============================] - 96s 753ms/step - loss: 1.7763 - accuracy: 0.2037 - val_loss: 1.7706 - val_accuracy: 0.2179\n",
      "Epoch 3/500\n",
      "127/127 [==============================] - 104s 818ms/step - loss: 1.7669 - accuracy: 0.2150 - val_loss: 1.7569 - val_accuracy: 0.2140\n",
      "Epoch 4/500\n",
      "127/127 [==============================] - 104s 817ms/step - loss: 1.7641 - accuracy: 0.2116 - val_loss: 1.7524 - val_accuracy: 0.2140\n",
      "Epoch 5/500\n",
      "127/127 [==============================] - 103s 808ms/step - loss: 1.7470 - accuracy: 0.2251 - val_loss: 1.7017 - val_accuracy: 0.2724\n",
      "Epoch 6/500\n",
      "127/127 [==============================] - 99s 778ms/step - loss: 1.7033 - accuracy: 0.2723 - val_loss: 1.6326 - val_accuracy: 0.3165\n",
      "Epoch 7/500\n",
      "127/127 [==============================] - 104s 816ms/step - loss: 1.5858 - accuracy: 0.3404 - val_loss: 1.5025 - val_accuracy: 0.3658\n",
      "Epoch 8/500\n",
      "127/127 [==============================] - 103s 807ms/step - loss: 1.4422 - accuracy: 0.4087 - val_loss: 1.4366 - val_accuracy: 0.4034\n",
      "Epoch 9/500\n",
      "127/127 [==============================] - 98s 773ms/step - loss: 1.3981 - accuracy: 0.4208 - val_loss: 1.2951 - val_accuracy: 0.4721\n",
      "Epoch 10/500\n",
      "127/127 [==============================] - 104s 817ms/step - loss: 1.3082 - accuracy: 0.4596 - val_loss: 1.3273 - val_accuracy: 0.4540\n",
      "Epoch 11/500\n",
      "127/127 [==============================] - 103s 810ms/step - loss: 1.2732 - accuracy: 0.4731 - val_loss: 1.2151 - val_accuracy: 0.5019\n",
      "Epoch 12/500\n",
      "127/127 [==============================] - 102s 803ms/step - loss: 1.2458 - accuracy: 0.4847 - val_loss: 1.2402 - val_accuracy: 0.4669\n",
      "Epoch 13/500\n",
      "127/127 [==============================] - 98s 770ms/step - loss: 1.2346 - accuracy: 0.4995 - val_loss: 1.1801 - val_accuracy: 0.5409\n",
      "Epoch 14/500\n",
      "127/127 [==============================] - 104s 819ms/step - loss: 1.1973 - accuracy: 0.5071 - val_loss: 1.2256 - val_accuracy: 0.4812\n",
      "Epoch 15/500\n",
      "127/127 [==============================] - 103s 809ms/step - loss: 1.1797 - accuracy: 0.5187 - val_loss: 1.1726 - val_accuracy: 0.4994\n",
      "Epoch 16/500\n",
      "127/127 [==============================] - 101s 795ms/step - loss: 1.1703 - accuracy: 0.5195 - val_loss: 1.1349 - val_accuracy: 0.5590\n",
      "Epoch 17/500\n",
      "127/127 [==============================] - 101s 797ms/step - loss: 1.1578 - accuracy: 0.5309 - val_loss: 1.2270 - val_accuracy: 0.5045\n",
      "Epoch 18/500\n",
      "127/127 [==============================] - 105s 825ms/step - loss: 1.1397 - accuracy: 0.5351 - val_loss: 1.2432 - val_accuracy: 0.4981\n",
      "Epoch 19/500\n",
      "127/127 [==============================] - 106s 831ms/step - loss: 1.1285 - accuracy: 0.5488 - val_loss: 1.0801 - val_accuracy: 0.5850\n",
      "Epoch 20/500\n",
      "127/127 [==============================] - 97s 765ms/step - loss: 1.1140 - accuracy: 0.5525 - val_loss: 1.1120 - val_accuracy: 0.5175\n",
      "Epoch 21/500\n",
      "127/127 [==============================] - 103s 807ms/step - loss: 1.0887 - accuracy: 0.5673 - val_loss: 1.0762 - val_accuracy: 0.5850\n",
      "Epoch 22/500\n",
      "127/127 [==============================] - 104s 817ms/step - loss: 1.0771 - accuracy: 0.5641 - val_loss: 1.1755 - val_accuracy: 0.5422\n",
      "Epoch 23/500\n",
      "127/127 [==============================] - 102s 800ms/step - loss: 1.0821 - accuracy: 0.5741 - val_loss: 1.0449 - val_accuracy: 0.5577\n",
      "Epoch 24/500\n",
      "127/127 [==============================] - 100s 788ms/step - loss: 1.0614 - accuracy: 0.5757 - val_loss: 1.0220 - val_accuracy: 0.6031\n",
      "Epoch 25/500\n",
      "127/127 [==============================] - 103s 810ms/step - loss: 1.0329 - accuracy: 0.5960 - val_loss: 1.0308 - val_accuracy: 0.6005\n",
      "Epoch 26/500\n",
      "127/127 [==============================] - 103s 812ms/step - loss: 1.0400 - accuracy: 0.5966 - val_loss: 0.9952 - val_accuracy: 0.6044\n",
      "Epoch 27/500\n",
      "127/127 [==============================] - 97s 764ms/step - loss: 1.0282 - accuracy: 0.5913 - val_loss: 0.9743 - val_accuracy: 0.5992\n",
      "Epoch 28/500\n",
      "127/127 [==============================] - 105s 825ms/step - loss: 0.9898 - accuracy: 0.6111 - val_loss: 0.9657 - val_accuracy: 0.6161\n",
      "Epoch 29/500\n",
      "127/127 [==============================] - 105s 831ms/step - loss: 0.9689 - accuracy: 0.6338 - val_loss: 0.9206 - val_accuracy: 0.6252\n",
      "Epoch 30/500\n",
      "127/127 [==============================] - 102s 804ms/step - loss: 0.9712 - accuracy: 0.6282 - val_loss: 0.9153 - val_accuracy: 0.6420\n",
      "Epoch 31/500\n",
      "127/127 [==============================] - 100s 784ms/step - loss: 0.9408 - accuracy: 0.6396 - val_loss: 0.9152 - val_accuracy: 0.6498\n",
      "Epoch 32/500\n",
      "127/127 [==============================] - 103s 812ms/step - loss: 0.9195 - accuracy: 0.6565 - val_loss: 0.9522 - val_accuracy: 0.6407\n",
      "Epoch 33/500\n",
      "127/127 [==============================] - 104s 820ms/step - loss: 0.9539 - accuracy: 0.6383 - val_loss: 1.0339 - val_accuracy: 0.6031\n",
      "Epoch 34/500\n",
      "127/127 [==============================] - 98s 769ms/step - loss: 0.9258 - accuracy: 0.6528 - val_loss: 0.8737 - val_accuracy: 0.6965\n",
      "Epoch 35/500\n",
      "127/127 [==============================] - 106s 834ms/step - loss: 0.8879 - accuracy: 0.6715 - val_loss: 0.9196 - val_accuracy: 0.6265\n",
      "Epoch 36/500\n",
      "127/127 [==============================] - 104s 816ms/step - loss: 0.8854 - accuracy: 0.6723 - val_loss: 0.8271 - val_accuracy: 0.6887\n",
      "Epoch 37/500\n",
      "127/127 [==============================] - 104s 815ms/step - loss: 0.8576 - accuracy: 0.6768 - val_loss: 0.8107 - val_accuracy: 0.6978\n",
      "Epoch 38/500\n",
      "127/127 [==============================] - 98s 769ms/step - loss: 0.8614 - accuracy: 0.6760 - val_loss: 0.9302 - val_accuracy: 0.6628\n",
      "Epoch 39/500\n",
      "127/127 [==============================] - 105s 824ms/step - loss: 0.8476 - accuracy: 0.6865 - val_loss: 0.8991 - val_accuracy: 0.6667\n",
      "Epoch 40/500\n",
      "127/127 [==============================] - 106s 832ms/step - loss: 0.8329 - accuracy: 0.6947 - val_loss: 0.7941 - val_accuracy: 0.7043\n",
      "Epoch 41/500\n",
      "127/127 [==============================] - 100s 784ms/step - loss: 0.8167 - accuracy: 0.6947 - val_loss: 0.8029 - val_accuracy: 0.7095\n",
      "Epoch 42/500\n",
      "127/127 [==============================] - 102s 804ms/step - loss: 0.8140 - accuracy: 0.6995 - val_loss: 0.7162 - val_accuracy: 0.7432\n",
      "Epoch 43/500\n",
      "127/127 [==============================] - 102s 806ms/step - loss: 0.7776 - accuracy: 0.7137 - val_loss: 0.7367 - val_accuracy: 0.7224\n",
      "Epoch 44/500\n",
      "127/127 [==============================] - 105s 826ms/step - loss: 0.7953 - accuracy: 0.7084 - val_loss: 0.7493 - val_accuracy: 0.7315\n",
      "Epoch 45/500\n",
      "127/127 [==============================] - 98s 775ms/step - loss: 0.7679 - accuracy: 0.7161 - val_loss: 0.8441 - val_accuracy: 0.6796\n",
      "Epoch 46/500\n",
      "127/127 [==============================] - 104s 818ms/step - loss: 0.7590 - accuracy: 0.7137 - val_loss: 0.7823 - val_accuracy: 0.7108\n",
      "Epoch 47/500\n",
      "127/127 [==============================] - 103s 810ms/step - loss: 0.7775 - accuracy: 0.7103 - val_loss: 0.8152 - val_accuracy: 0.6861\n",
      "Epoch 48/500\n",
      "127/127 [==============================] - 101s 799ms/step - loss: 0.7731 - accuracy: 0.7222 - val_loss: 0.8157 - val_accuracy: 0.7160\n",
      "Epoch 49/500\n",
      "127/127 [==============================] - 100s 785ms/step - loss: 0.7643 - accuracy: 0.7259 - val_loss: 0.7187 - val_accuracy: 0.7276\n",
      "Epoch 50/500\n",
      "127/127 [==============================] - 104s 817ms/step - loss: 0.7555 - accuracy: 0.7195 - val_loss: 0.7730 - val_accuracy: 0.7185\n",
      "Epoch 51/500\n",
      "127/127 [==============================] - 103s 813ms/step - loss: 0.7376 - accuracy: 0.7253 - val_loss: 0.6971 - val_accuracy: 0.7601\n",
      "Epoch 52/500\n",
      "127/127 [==============================] - 98s 771ms/step - loss: 0.7290 - accuracy: 0.7280 - val_loss: 0.6919 - val_accuracy: 0.7536\n",
      "Epoch 53/500\n",
      "127/127 [==============================] - 104s 815ms/step - loss: 0.7203 - accuracy: 0.7264 - val_loss: 0.6835 - val_accuracy: 0.7393\n",
      "Epoch 54/500\n",
      "127/127 [==============================] - 102s 805ms/step - loss: 0.6949 - accuracy: 0.7493 - val_loss: 0.7098 - val_accuracy: 0.7354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "127/127 [==============================] - 104s 817ms/step - loss: 0.7041 - accuracy: 0.7454 - val_loss: 0.8191 - val_accuracy: 0.6939\n",
      "Epoch 56/500\n",
      "127/127 [==============================] - 97s 765ms/step - loss: 0.7318 - accuracy: 0.7259 - val_loss: 0.7663 - val_accuracy: 0.7211\n",
      "Epoch 57/500\n",
      "127/127 [==============================] - 103s 814ms/step - loss: 0.6802 - accuracy: 0.7430 - val_loss: 0.6936 - val_accuracy: 0.7354\n",
      "Epoch 58/500\n",
      "127/127 [==============================] - 101s 797ms/step - loss: 0.6774 - accuracy: 0.7604 - val_loss: 0.7280 - val_accuracy: 0.7289\n",
      "Epoch 59/500\n",
      "127/127 [==============================] - 100s 791ms/step - loss: 0.6604 - accuracy: 0.7573 - val_loss: 0.6418 - val_accuracy: 0.7639\n",
      "Epoch 60/500\n",
      "127/127 [==============================] - 102s 804ms/step - loss: 0.6770 - accuracy: 0.7520 - val_loss: 0.7809 - val_accuracy: 0.7147\n",
      "Epoch 61/500\n",
      "127/127 [==============================] - 104s 819ms/step - loss: 0.6868 - accuracy: 0.7446 - val_loss: 0.6566 - val_accuracy: 0.7419\n",
      "Epoch 62/500\n",
      "127/127 [==============================] - 105s 827ms/step - loss: 0.6790 - accuracy: 0.7433 - val_loss: 0.6334 - val_accuracy: 0.7613\n",
      "Epoch 63/500\n",
      "127/127 [==============================] - 102s 805ms/step - loss: 0.6291 - accuracy: 0.7675 - val_loss: 0.6546 - val_accuracy: 0.7523\n",
      "Epoch 64/500\n",
      "127/127 [==============================] - 104s 818ms/step - loss: 0.6450 - accuracy: 0.7559 - val_loss: 0.6409 - val_accuracy: 0.7626\n",
      "Epoch 65/500\n",
      "127/127 [==============================] - 103s 809ms/step - loss: 0.6633 - accuracy: 0.7480 - val_loss: 0.6716 - val_accuracy: 0.7510\n",
      "Epoch 66/500\n",
      "127/127 [==============================] - 101s 798ms/step - loss: 0.6407 - accuracy: 0.7646 - val_loss: 0.6683 - val_accuracy: 0.7613\n",
      "Epoch 67/500\n",
      "127/127 [==============================] - 101s 797ms/step - loss: 0.6545 - accuracy: 0.7546 - val_loss: 0.6187 - val_accuracy: 0.7691\n",
      "Epoch 68/500\n",
      "127/127 [==============================] - 102s 803ms/step - loss: 0.6384 - accuracy: 0.7699 - val_loss: 0.5842 - val_accuracy: 0.7795\n",
      "Epoch 69/500\n",
      "127/127 [==============================] - 104s 821ms/step - loss: 0.6199 - accuracy: 0.7702 - val_loss: 0.6346 - val_accuracy: 0.7704\n",
      "Epoch 70/500\n",
      "127/127 [==============================] - 99s 777ms/step - loss: 0.5946 - accuracy: 0.7852 - val_loss: 0.5391 - val_accuracy: 0.7964\n",
      "Epoch 71/500\n",
      "127/127 [==============================] - 103s 810ms/step - loss: 0.6362 - accuracy: 0.7649 - val_loss: 0.6538 - val_accuracy: 0.7678\n",
      "Epoch 72/500\n",
      "127/127 [==============================] - 106s 836ms/step - loss: 0.6094 - accuracy: 0.7802 - val_loss: 0.7580 - val_accuracy: 0.7263\n",
      "Epoch 73/500\n",
      "127/127 [==============================] - 103s 810ms/step - loss: 0.7029 - accuracy: 0.7367 - val_loss: 0.6278 - val_accuracy: 0.7821\n",
      "Epoch 74/500\n",
      "127/127 [==============================] - 103s 815ms/step - loss: 0.6311 - accuracy: 0.7699 - val_loss: 0.6520 - val_accuracy: 0.7562\n",
      "Epoch 75/500\n",
      "127/127 [==============================] - 110s 863ms/step - loss: 0.6021 - accuracy: 0.7815 - val_loss: 0.8686 - val_accuracy: 0.7030\n",
      "Epoch 76/500\n",
      "127/127 [==============================] - 104s 821ms/step - loss: 0.6085 - accuracy: 0.7818 - val_loss: 0.5689 - val_accuracy: 0.7938\n",
      "Epoch 77/500\n",
      "127/127 [==============================] - 99s 779ms/step - loss: 0.6178 - accuracy: 0.7675 - val_loss: 0.5950 - val_accuracy: 0.7795\n",
      "Epoch 78/500\n",
      "127/127 [==============================] - 103s 814ms/step - loss: 0.5834 - accuracy: 0.7865 - val_loss: 0.8162 - val_accuracy: 0.7043\n",
      "Epoch 79/500\n",
      "127/127 [==============================] - 105s 825ms/step - loss: 0.5745 - accuracy: 0.7905 - val_loss: 0.5534 - val_accuracy: 0.7938\n",
      "Epoch 80/500\n",
      "127/127 [==============================] - 104s 816ms/step - loss: 0.6029 - accuracy: 0.7726 - val_loss: 0.5581 - val_accuracy: 0.7938\n",
      "Epoch 81/500\n",
      "127/127 [==============================] - 98s 771ms/step - loss: 0.5779 - accuracy: 0.7823 - val_loss: 0.5765 - val_accuracy: 0.7756\n",
      "Epoch 82/500\n",
      "127/127 [==============================] - 104s 819ms/step - loss: 0.5821 - accuracy: 0.7871 - val_loss: 0.5834 - val_accuracy: 0.7717\n",
      "Epoch 83/500\n",
      "127/127 [==============================] - 105s 826ms/step - loss: 0.6079 - accuracy: 0.7815 - val_loss: 0.5832 - val_accuracy: 0.7925\n",
      "Epoch 84/500\n",
      "127/127 [==============================] - 100s 787ms/step - loss: 0.5537 - accuracy: 0.7958 - val_loss: 0.5730 - val_accuracy: 0.7912\n",
      "Epoch 85/500\n",
      "127/127 [==============================] - 102s 800ms/step - loss: 0.5508 - accuracy: 0.8053 - val_loss: 0.5739 - val_accuracy: 0.7847\n",
      "Epoch 86/500\n",
      "127/127 [==============================] - 104s 822ms/step - loss: 0.5476 - accuracy: 0.7979 - val_loss: 0.5050 - val_accuracy: 0.8158\n",
      "Epoch 87/500\n",
      "127/127 [==============================] - 104s 818ms/step - loss: 0.5525 - accuracy: 0.7916 - val_loss: 0.5673 - val_accuracy: 0.7873\n",
      "Epoch 88/500\n",
      "127/127 [==============================] - 97s 760ms/step - loss: 0.5925 - accuracy: 0.7799 - val_loss: 0.7671 - val_accuracy: 0.7108\n",
      "Epoch 89/500\n",
      "127/127 [==============================] - 105s 831ms/step - loss: 0.5418 - accuracy: 0.7979 - val_loss: 0.5213 - val_accuracy: 0.8249\n",
      "Epoch 90/500\n",
      "127/127 [==============================] - 107s 841ms/step - loss: 0.5670 - accuracy: 0.7929 - val_loss: 0.7906 - val_accuracy: 0.7069\n",
      "Epoch 91/500\n",
      "127/127 [==============================] - 105s 827ms/step - loss: 0.5402 - accuracy: 0.8045 - val_loss: 0.6339 - val_accuracy: 0.7717\n",
      "Epoch 92/500\n",
      "127/127 [==============================] - 101s 793ms/step - loss: 0.5376 - accuracy: 0.8008 - val_loss: 0.6039 - val_accuracy: 0.7769\n",
      "Epoch 93/500\n",
      "127/127 [==============================] - 104s 819ms/step - loss: 0.5752 - accuracy: 0.7921 - val_loss: 0.5141 - val_accuracy: 0.8184\n",
      "Epoch 94/500\n",
      "127/127 [==============================] - 104s 823ms/step - loss: 0.5416 - accuracy: 0.8063 - val_loss: 0.5665 - val_accuracy: 0.8054\n",
      "Epoch 95/500\n",
      "127/127 [==============================] - 105s 828ms/step - loss: 0.5381 - accuracy: 0.8008 - val_loss: 0.5614 - val_accuracy: 0.8080\n",
      "Epoch 96/500\n",
      "127/127 [==============================] - 105s 827ms/step - loss: 0.5645 - accuracy: 0.8034 - val_loss: 0.5304 - val_accuracy: 0.8093\n",
      "Epoch 97/500\n",
      "127/127 [==============================] - 104s 820ms/step - loss: 0.5251 - accuracy: 0.8024 - val_loss: 0.5701 - val_accuracy: 0.7847\n",
      "Epoch 98/500\n",
      "127/127 [==============================] - 103s 812ms/step - loss: 0.4904 - accuracy: 0.8185 - val_loss: 0.4865 - val_accuracy: 0.8093\n",
      "Epoch 99/500\n",
      "127/127 [==============================] - 99s 778ms/step - loss: 0.5407 - accuracy: 0.8074 - val_loss: 0.5920 - val_accuracy: 0.7912\n",
      "Epoch 100/500\n",
      "127/127 [==============================] - 106s 831ms/step - loss: 0.5197 - accuracy: 0.8129 - val_loss: 0.5190 - val_accuracy: 0.8080\n",
      "Epoch 101/500\n",
      "127/127 [==============================] - 104s 821ms/step - loss: 0.5253 - accuracy: 0.8058 - val_loss: 0.5292 - val_accuracy: 0.7951\n",
      "Epoch 102/500\n",
      "127/127 [==============================] - 99s 783ms/step - loss: 0.5182 - accuracy: 0.8047 - val_loss: 0.5199 - val_accuracy: 0.8275\n",
      "Epoch 103/500\n",
      "127/127 [==============================] - 104s 817ms/step - loss: 0.5167 - accuracy: 0.8098 - val_loss: 0.4921 - val_accuracy: 0.8223\n",
      "Epoch 104/500\n",
      "127/127 [==============================] - 104s 817ms/step - loss: 0.5204 - accuracy: 0.8195 - val_loss: 0.5326 - val_accuracy: 0.8223\n",
      "Epoch 105/500\n",
      "127/127 [==============================] - 104s 822ms/step - loss: 0.5256 - accuracy: 0.8119 - val_loss: 0.4951 - val_accuracy: 0.8184\n",
      "Epoch 106/500\n",
      "127/127 [==============================] - 97s 767ms/step - loss: 0.5063 - accuracy: 0.8137 - val_loss: 0.5583 - val_accuracy: 0.7951\n",
      "Epoch 107/500\n",
      "127/127 [==============================] - 103s 812ms/step - loss: 0.4910 - accuracy: 0.8172 - val_loss: 0.4910 - val_accuracy: 0.8236\n",
      "Epoch 108/500\n",
      "127/127 [==============================] - 103s 811ms/step - loss: 0.4907 - accuracy: 0.8211 - val_loss: 0.4614 - val_accuracy: 0.8262\n",
      "Epoch 109/500\n",
      "127/127 [==============================] - 100s 791ms/step - loss: 0.5020 - accuracy: 0.8156 - val_loss: 0.4665 - val_accuracy: 0.8327\n",
      "Epoch 110/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 101s 792ms/step - loss: 0.5016 - accuracy: 0.8195 - val_loss: 0.4493 - val_accuracy: 0.8288\n",
      "Epoch 111/500\n",
      "127/127 [==============================] - 105s 828ms/step - loss: 0.4808 - accuracy: 0.8293 - val_loss: 0.5547 - val_accuracy: 0.8223\n",
      "Epoch 112/500\n",
      "127/127 [==============================] - 104s 818ms/step - loss: 0.4504 - accuracy: 0.8348 - val_loss: 0.5791 - val_accuracy: 0.7821\n",
      "Epoch 113/500\n",
      "127/127 [==============================] - 98s 775ms/step - loss: 0.4898 - accuracy: 0.8203 - val_loss: 0.4506 - val_accuracy: 0.8145\n",
      "Epoch 114/500\n",
      "127/127 [==============================] - 105s 824ms/step - loss: 0.4810 - accuracy: 0.8243 - val_loss: 0.4519 - val_accuracy: 0.8495\n",
      "Epoch 115/500\n",
      "127/127 [==============================] - 103s 814ms/step - loss: 0.4559 - accuracy: 0.8348 - val_loss: 0.5605 - val_accuracy: 0.8029\n",
      "Epoch 116/500\n",
      "127/127 [==============================] - 103s 814ms/step - loss: 0.4920 - accuracy: 0.8277 - val_loss: 0.4037 - val_accuracy: 0.8470\n",
      "Epoch 117/500\n",
      "127/127 [==============================] - 100s 784ms/step - loss: 0.4866 - accuracy: 0.8127 - val_loss: 0.5372 - val_accuracy: 0.8145\n",
      "Epoch 118/500\n",
      "127/127 [==============================] - 105s 826ms/step - loss: 0.4591 - accuracy: 0.8348 - val_loss: 0.4641 - val_accuracy: 0.8223\n",
      "Epoch 119/500\n",
      "127/127 [==============================] - 103s 811ms/step - loss: 0.4779 - accuracy: 0.8322 - val_loss: 0.4857 - val_accuracy: 0.8275\n",
      "Epoch 120/500\n",
      "127/127 [==============================] - 98s 769ms/step - loss: 0.4476 - accuracy: 0.8401 - val_loss: 0.5505 - val_accuracy: 0.8080\n",
      "Epoch 121/500\n",
      "127/127 [==============================] - 106s 831ms/step - loss: 0.4591 - accuracy: 0.8298 - val_loss: 0.5299 - val_accuracy: 0.7925\n",
      "Epoch 122/500\n",
      "127/127 [==============================] - 103s 812ms/step - loss: 0.4758 - accuracy: 0.8306 - val_loss: 0.5462 - val_accuracy: 0.8067\n",
      "Epoch 123/500\n",
      "127/127 [==============================] - 104s 818ms/step - loss: 0.4394 - accuracy: 0.8398 - val_loss: 0.5374 - val_accuracy: 0.8080\n",
      "Epoch 124/500\n",
      "127/127 [==============================] - 97s 766ms/step - loss: 0.4659 - accuracy: 0.8327 - val_loss: 0.6187 - val_accuracy: 0.7951\n",
      "Epoch 125/500\n",
      "127/127 [==============================] - 104s 816ms/step - loss: 0.4487 - accuracy: 0.8383 - val_loss: 0.5144 - val_accuracy: 0.8119\n",
      "Epoch 126/500\n",
      "127/127 [==============================] - 104s 820ms/step - loss: 0.4837 - accuracy: 0.8248 - val_loss: 0.4434 - val_accuracy: 0.8288\n",
      "Epoch 127/500\n",
      "127/127 [==============================] - 100s 789ms/step - loss: 0.4580 - accuracy: 0.8361 - val_loss: 0.5318 - val_accuracy: 0.8158\n",
      "Epoch 128/500\n",
      "127/127 [==============================] - 102s 800ms/step - loss: 0.4707 - accuracy: 0.8253 - val_loss: 0.4167 - val_accuracy: 0.8521\n",
      "Epoch 129/500\n",
      "127/127 [==============================] - 105s 828ms/step - loss: 0.4618 - accuracy: 0.8393 - val_loss: 0.4459 - val_accuracy: 0.8470\n",
      "Epoch 130/500\n",
      "127/127 [==============================] - 103s 811ms/step - loss: 0.4745 - accuracy: 0.8261 - val_loss: 0.4799 - val_accuracy: 0.8314\n",
      "Epoch 131/500\n",
      "127/127 [==============================] - 100s 790ms/step - loss: 0.4706 - accuracy: 0.8277 - val_loss: 0.4637 - val_accuracy: 0.8366\n",
      "Epoch 132/500\n",
      "127/127 [==============================] - 104s 816ms/step - loss: 0.4600 - accuracy: 0.8354 - val_loss: 0.4190 - val_accuracy: 0.8547\n",
      "Epoch 133/500\n",
      "127/127 [==============================] - 105s 830ms/step - loss: 0.4751 - accuracy: 0.8259 - val_loss: 0.4646 - val_accuracy: 0.8210\n",
      "Epoch 134/500\n",
      "127/127 [==============================] - 102s 806ms/step - loss: 0.4729 - accuracy: 0.8309 - val_loss: 0.4480 - val_accuracy: 0.8262\n",
      "Epoch 135/500\n",
      "127/127 [==============================] - 102s 805ms/step - loss: 0.4289 - accuracy: 0.8459 - val_loss: 0.5169 - val_accuracy: 0.8158\n",
      "Epoch 136/500\n",
      "127/127 [==============================] - 106s 836ms/step - loss: 0.4495 - accuracy: 0.8367 - val_loss: 0.4857 - val_accuracy: 0.8340\n",
      "Epoch 137/500\n",
      "127/127 [==============================] - 106s 833ms/step - loss: 0.4533 - accuracy: 0.8356 - val_loss: 0.3863 - val_accuracy: 0.8716\n",
      "Epoch 138/500\n",
      "127/127 [==============================] - 97s 766ms/step - loss: 0.3929 - accuracy: 0.8575 - val_loss: 0.3832 - val_accuracy: 0.8677\n",
      "Epoch 139/500\n",
      "127/127 [==============================] - 107s 840ms/step - loss: 0.4326 - accuracy: 0.8467 - val_loss: 0.4461 - val_accuracy: 0.8495\n",
      "Epoch 140/500\n",
      "127/127 [==============================] - 103s 813ms/step - loss: 0.4229 - accuracy: 0.8512 - val_loss: 0.3855 - val_accuracy: 0.8638\n",
      "Epoch 141/500\n",
      "127/127 [==============================] - 104s 822ms/step - loss: 0.4399 - accuracy: 0.8406 - val_loss: 0.4640 - val_accuracy: 0.8275\n",
      "Epoch 142/500\n",
      "127/127 [==============================] - 99s 781ms/step - loss: 0.4434 - accuracy: 0.8380 - val_loss: 0.4103 - val_accuracy: 0.8560\n",
      "Epoch 143/500\n",
      "127/127 [==============================] - 105s 825ms/step - loss: 0.4074 - accuracy: 0.8546 - val_loss: 0.5402 - val_accuracy: 0.8067\n",
      "Epoch 144/500\n",
      "127/127 [==============================] - 105s 823ms/step - loss: 0.4495 - accuracy: 0.8377 - val_loss: 0.4058 - val_accuracy: 0.8573\n",
      "Epoch 145/500\n",
      "127/127 [==============================] - 100s 785ms/step - loss: 0.4025 - accuracy: 0.8520 - val_loss: 0.4934 - val_accuracy: 0.8314\n",
      "Epoch 146/500\n",
      "127/127 [==============================] - 103s 811ms/step - loss: 0.4340 - accuracy: 0.8449 - val_loss: 0.3471 - val_accuracy: 0.8612\n",
      "Epoch 147/500\n",
      "127/127 [==============================] - 104s 823ms/step - loss: 0.4050 - accuracy: 0.8507 - val_loss: 0.4584 - val_accuracy: 0.8275\n",
      "Epoch 148/500\n",
      "127/127 [==============================] - 105s 823ms/step - loss: 0.4335 - accuracy: 0.8422 - val_loss: 0.4347 - val_accuracy: 0.8379\n",
      "Epoch 149/500\n",
      "127/127 [==============================] - 99s 783ms/step - loss: 0.4459 - accuracy: 0.8485 - val_loss: 0.4065 - val_accuracy: 0.8716\n",
      "Epoch 150/500\n",
      "127/127 [==============================] - 108s 847ms/step - loss: 0.4031 - accuracy: 0.8538 - val_loss: 0.4000 - val_accuracy: 0.8625\n",
      "Epoch 151/500\n",
      "127/127 [==============================] - 105s 824ms/step - loss: 0.4363 - accuracy: 0.8375 - val_loss: 0.3826 - val_accuracy: 0.8651\n",
      "Epoch 152/500\n",
      "127/127 [==============================] - 101s 798ms/step - loss: 0.4292 - accuracy: 0.8478 - val_loss: 0.3540 - val_accuracy: 0.8807\n",
      "Epoch 153/500\n",
      "127/127 [==============================] - 101s 799ms/step - loss: 0.4075 - accuracy: 0.8512 - val_loss: 0.5316 - val_accuracy: 0.8042\n",
      "Epoch 154/500\n",
      "127/127 [==============================] - 104s 818ms/step - loss: 0.4091 - accuracy: 0.8483 - val_loss: 0.5479 - val_accuracy: 0.8119\n",
      "Epoch 155/500\n",
      "127/127 [==============================] - 107s 844ms/step - loss: 0.3840 - accuracy: 0.8628 - val_loss: 0.4055 - val_accuracy: 0.8586\n",
      "Epoch 156/500\n",
      "127/127 [==============================] - 99s 780ms/step - loss: 0.3853 - accuracy: 0.8620 - val_loss: 0.4190 - val_accuracy: 0.8547\n",
      "Epoch 157/500\n",
      "127/127 [==============================] - 106s 832ms/step - loss: 0.3979 - accuracy: 0.8570 - val_loss: 0.4090 - val_accuracy: 0.8444\n",
      "Epoch 158/500\n",
      "127/127 [==============================] - 103s 807ms/step - loss: 0.4160 - accuracy: 0.8515 - val_loss: 0.5324 - val_accuracy: 0.8249\n",
      "Epoch 159/500\n",
      "127/127 [==============================] - 103s 811ms/step - loss: 0.4142 - accuracy: 0.8499 - val_loss: 0.5285 - val_accuracy: 0.8132\n",
      "Epoch 160/500\n",
      "127/127 [==============================] - 101s 794ms/step - loss: 0.4282 - accuracy: 0.8480 - val_loss: 0.3888 - val_accuracy: 0.8690\n",
      "Epoch 161/500\n",
      "127/127 [==============================] - 105s 829ms/step - loss: 0.3971 - accuracy: 0.8567 - val_loss: 0.4323 - val_accuracy: 0.8392\n",
      "Epoch 162/500\n",
      "127/127 [==============================] - 104s 820ms/step - loss: 0.4140 - accuracy: 0.8538 - val_loss: 0.4170 - val_accuracy: 0.8444\n",
      "Epoch 163/500\n",
      "127/127 [==============================] - 98s 771ms/step - loss: 0.3734 - accuracy: 0.8644 - val_loss: 0.4408 - val_accuracy: 0.8560\n",
      "Epoch 164/500\n",
      "127/127 [==============================] - 104s 819ms/step - loss: 0.4014 - accuracy: 0.8599 - val_loss: 0.3669 - val_accuracy: 0.8664\n",
      "Epoch 165/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 107s 839ms/step - loss: 0.4042 - accuracy: 0.8586 - val_loss: 0.3535 - val_accuracy: 0.8664\n",
      "Epoch 166/500\n",
      "127/127 [==============================] - 105s 828ms/step - loss: 0.4129 - accuracy: 0.8485 - val_loss: 0.4233 - val_accuracy: 0.8586\n",
      "Epoch 167/500\n",
      "127/127 [==============================] - 99s 777ms/step - loss: 0.3817 - accuracy: 0.8633 - val_loss: 0.3846 - val_accuracy: 0.8508\n",
      "Epoch 168/500\n",
      "127/127 [==============================] - 105s 823ms/step - loss: 0.4072 - accuracy: 0.8559 - val_loss: 0.4166 - val_accuracy: 0.8457\n",
      "Epoch 169/500\n",
      "127/127 [==============================] - 107s 841ms/step - loss: 0.4133 - accuracy: 0.8559 - val_loss: 0.4674 - val_accuracy: 0.8625\n",
      "Epoch 170/500\n",
      "127/127 [==============================] - 101s 796ms/step - loss: 0.3618 - accuracy: 0.8715 - val_loss: 0.3500 - val_accuracy: 0.8742\n",
      "Epoch 171/500\n",
      "127/127 [==============================] - 108s 851ms/step - loss: 0.3610 - accuracy: 0.8728 - val_loss: 0.3836 - val_accuracy: 0.8586\n",
      "Epoch 172/500\n",
      "127/127 [==============================] - 107s 841ms/step - loss: 0.3860 - accuracy: 0.8607 - val_loss: 0.4177 - val_accuracy: 0.8625\n",
      "Epoch 173/500\n",
      "127/127 [==============================] - 105s 824ms/step - loss: 0.4455 - accuracy: 0.8554 - val_loss: 0.4524 - val_accuracy: 0.8405\n",
      "Epoch 174/500\n",
      "127/127 [==============================] - 101s 794ms/step - loss: 0.3973 - accuracy: 0.8607 - val_loss: 0.3301 - val_accuracy: 0.8833\n",
      "Epoch 175/500\n",
      "127/127 [==============================] - 108s 853ms/step - loss: 0.3846 - accuracy: 0.8583 - val_loss: 0.3682 - val_accuracy: 0.8820\n",
      "Epoch 176/500\n",
      "127/127 [==============================] - 107s 844ms/step - loss: 0.3536 - accuracy: 0.8704 - val_loss: 0.5089 - val_accuracy: 0.8379\n",
      "Epoch 177/500\n",
      "127/127 [==============================] - 103s 809ms/step - loss: 0.4205 - accuracy: 0.8501 - val_loss: 0.4806 - val_accuracy: 0.8340\n",
      "Epoch 178/500\n",
      "127/127 [==============================] - 104s 821ms/step - loss: 0.3903 - accuracy: 0.8607 - val_loss: 0.4060 - val_accuracy: 0.8677\n",
      "Epoch 179/500\n",
      "127/127 [==============================] - 108s 854ms/step - loss: 0.4096 - accuracy: 0.8525 - val_loss: 0.3725 - val_accuracy: 0.8729\n",
      "Epoch 180/500\n",
      "127/127 [==============================] - 112s 880ms/step - loss: 0.3609 - accuracy: 0.8673 - val_loss: 0.3477 - val_accuracy: 0.8729\n",
      "Epoch 181/500\n",
      "127/127 [==============================] - 104s 821ms/step - loss: 0.3945 - accuracy: 0.8620 - val_loss: 0.4455 - val_accuracy: 0.8547\n",
      "Epoch 182/500\n",
      "127/127 [==============================] - 109s 855ms/step - loss: 0.3731 - accuracy: 0.8660 - val_loss: 0.4000 - val_accuracy: 0.8495\n",
      "Epoch 183/500\n",
      "127/127 [==============================] - 109s 858ms/step - loss: 0.4038 - accuracy: 0.8562 - val_loss: 0.4313 - val_accuracy: 0.8547\n",
      "Epoch 184/500\n",
      "127/127 [==============================] - 104s 820ms/step - loss: 0.3867 - accuracy: 0.8620 - val_loss: 0.3565 - val_accuracy: 0.8560\n",
      "Epoch 185/500\n",
      "127/127 [==============================] - 104s 820ms/step - loss: 0.3762 - accuracy: 0.8699 - val_loss: 0.3727 - val_accuracy: 0.8794\n",
      "Epoch 186/500\n",
      "127/127 [==============================] - 107s 843ms/step - loss: 0.3662 - accuracy: 0.8646 - val_loss: 0.3879 - val_accuracy: 0.8651\n",
      "Epoch 187/500\n",
      "127/127 [==============================] - 107s 843ms/step - loss: 0.3823 - accuracy: 0.8636 - val_loss: 0.3626 - val_accuracy: 0.8664\n",
      "Epoch 188/500\n",
      "127/127 [==============================] - 104s 818ms/step - loss: 0.3486 - accuracy: 0.8763 - val_loss: 0.3482 - val_accuracy: 0.8768\n",
      "Epoch 189/500\n",
      "127/127 [==============================] - 110s 864ms/step - loss: 0.3715 - accuracy: 0.8654 - val_loss: 0.3774 - val_accuracy: 0.8651\n",
      "Epoch 190/500\n",
      "127/127 [==============================] - 111s 873ms/step - loss: 0.3723 - accuracy: 0.8665 - val_loss: 0.3757 - val_accuracy: 0.8638\n",
      "Epoch 191/500\n",
      "127/127 [==============================] - 105s 825ms/step - loss: 0.3877 - accuracy: 0.8644 - val_loss: 0.4218 - val_accuracy: 0.8508\n",
      "Epoch 192/500\n",
      "127/127 [==============================] - 103s 814ms/step - loss: 0.3968 - accuracy: 0.8633 - val_loss: 0.3821 - val_accuracy: 0.8820\n",
      "Epoch 193/500\n",
      "127/127 [==============================] - 112s 880ms/step - loss: 0.3273 - accuracy: 0.8815 - val_loss: 0.3774 - val_accuracy: 0.8664\n",
      "Epoch 194/500\n",
      "127/127 [==============================] - 108s 853ms/step - loss: 0.3734 - accuracy: 0.8628 - val_loss: 0.3588 - val_accuracy: 0.8716\n",
      "Epoch 195/500\n",
      "127/127 [==============================] - 103s 808ms/step - loss: 0.3686 - accuracy: 0.8699 - val_loss: 0.4201 - val_accuracy: 0.8547\n",
      "Epoch 196/500\n",
      "127/127 [==============================] - 111s 875ms/step - loss: 0.3717 - accuracy: 0.8689 - val_loss: 0.3552 - val_accuracy: 0.8703\n",
      "Epoch 197/500\n",
      "127/127 [==============================] - 105s 829ms/step - loss: 0.3566 - accuracy: 0.8673 - val_loss: 0.4985 - val_accuracy: 0.8444\n",
      "Epoch 198/500\n",
      "127/127 [==============================] - 102s 804ms/step - loss: 0.4587 - accuracy: 0.8507 - val_loss: 0.3826 - val_accuracy: 0.8703\n",
      "Epoch 199/500\n",
      "127/127 [==============================] - 100s 786ms/step - loss: 0.3866 - accuracy: 0.8683 - val_loss: 0.3341 - val_accuracy: 0.8898\n",
      "Epoch 200/500\n",
      "127/127 [==============================] - 105s 829ms/step - loss: 0.3466 - accuracy: 0.8823 - val_loss: 0.3680 - val_accuracy: 0.8716\n",
      "Epoch 201/500\n",
      "127/127 [==============================] - 108s 854ms/step - loss: 0.3602 - accuracy: 0.8699 - val_loss: 0.5335 - val_accuracy: 0.8275\n",
      "Epoch 202/500\n",
      "127/127 [==============================] - 99s 777ms/step - loss: 0.3728 - accuracy: 0.8757 - val_loss: 0.4640 - val_accuracy: 0.8457\n",
      "Epoch 203/500\n",
      "127/127 [==============================] - 105s 824ms/step - loss: 0.4061 - accuracy: 0.8668 - val_loss: 0.4146 - val_accuracy: 0.8651\n",
      "Epoch 204/500\n",
      "127/127 [==============================] - 104s 819ms/step - loss: 0.3662 - accuracy: 0.8763 - val_loss: 0.3495 - val_accuracy: 0.8742\n",
      "Epoch 205/500\n",
      "127/127 [==============================] - 103s 809ms/step - loss: 0.3374 - accuracy: 0.8773 - val_loss: 0.3885 - val_accuracy: 0.8651\n",
      "Epoch 206/500\n",
      "127/127 [==============================] - 99s 779ms/step - loss: 0.3343 - accuracy: 0.8818 - val_loss: 0.5179 - val_accuracy: 0.8340\n",
      "Epoch 207/500\n",
      "127/127 [==============================] - 104s 819ms/step - loss: 0.3816 - accuracy: 0.8734 - val_loss: 0.3786 - val_accuracy: 0.8573\n",
      "Epoch 208/500\n",
      "127/127 [==============================] - 105s 826ms/step - loss: 0.3354 - accuracy: 0.8786 - val_loss: 0.3694 - val_accuracy: 0.8742\n",
      "Epoch 209/500\n",
      "127/127 [==============================] - 99s 782ms/step - loss: 0.3485 - accuracy: 0.8778 - val_loss: 0.3624 - val_accuracy: 0.8898\n",
      "Epoch 210/500\n",
      "127/127 [==============================] - 102s 805ms/step - loss: 0.3698 - accuracy: 0.8694 - val_loss: 0.4150 - val_accuracy: 0.8521\n",
      "Epoch 211/500\n",
      "127/127 [==============================] - 104s 816ms/step - loss: 0.3826 - accuracy: 0.8773 - val_loss: 0.4031 - val_accuracy: 0.8664\n",
      "Epoch 212/500\n",
      "127/127 [==============================] - 107s 846ms/step - loss: 0.3232 - accuracy: 0.8831 - val_loss: 0.3608 - val_accuracy: 0.8755\n",
      "Epoch 213/500\n",
      "127/127 [==============================] - 103s 809ms/step - loss: 0.3602 - accuracy: 0.8760 - val_loss: 0.3375 - val_accuracy: 0.8820\n",
      "Epoch 214/500\n",
      "127/127 [==============================] - 108s 854ms/step - loss: 0.3183 - accuracy: 0.8863 - val_loss: 0.4769 - val_accuracy: 0.8560\n",
      "Epoch 215/500\n",
      "127/127 [==============================] - 109s 855ms/step - loss: 0.3648 - accuracy: 0.8810 - val_loss: 0.4292 - val_accuracy: 0.8612\n",
      "Epoch 216/500\n",
      "127/127 [==============================] - 109s 857ms/step - loss: 0.3475 - accuracy: 0.8797 - val_loss: 0.3577 - val_accuracy: 0.8677\n",
      "Epoch 217/500\n",
      "127/127 [==============================] - 109s 862ms/step - loss: 0.3242 - accuracy: 0.8913 - val_loss: 0.2989 - val_accuracy: 0.8872\n",
      "Epoch 218/500\n",
      "127/127 [==============================] - 109s 856ms/step - loss: 0.3207 - accuracy: 0.8789 - val_loss: 0.4385 - val_accuracy: 0.8586\n",
      "Epoch 219/500\n",
      "127/127 [==============================] - 110s 867ms/step - loss: 0.3274 - accuracy: 0.8910 - val_loss: 0.4030 - val_accuracy: 0.8703\n",
      "Epoch 220/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 105s 826ms/step - loss: 0.3511 - accuracy: 0.8768 - val_loss: 0.3470 - val_accuracy: 0.8833\n",
      "Epoch 221/500\n",
      "127/127 [==============================] - 109s 856ms/step - loss: 0.3577 - accuracy: 0.8799 - val_loss: 0.3473 - val_accuracy: 0.8885\n",
      "Epoch 222/500\n",
      "127/127 [==============================] - 111s 874ms/step - loss: 0.3635 - accuracy: 0.8773 - val_loss: 0.3613 - val_accuracy: 0.8794\n",
      "Epoch 223/500\n",
      "127/127 [==============================] - 105s 825ms/step - loss: 0.3776 - accuracy: 0.8741 - val_loss: 0.4709 - val_accuracy: 0.8573\n",
      "Epoch 224/500\n",
      "127/127 [==============================] - 115s 902ms/step - loss: 0.3451 - accuracy: 0.8813 - val_loss: 0.3072 - val_accuracy: 0.8898\n",
      "Epoch 225/500\n",
      "127/127 [==============================] - 113s 886ms/step - loss: 0.3383 - accuracy: 0.8807 - val_loss: 0.5286 - val_accuracy: 0.8366\n",
      "Epoch 226/500\n",
      "127/127 [==============================] - 108s 852ms/step - loss: 0.3271 - accuracy: 0.8905 - val_loss: 0.3869 - val_accuracy: 0.8599\n",
      "Epoch 227/500\n",
      "127/127 [==============================] - 105s 823ms/step - loss: 0.3338 - accuracy: 0.8860 - val_loss: 0.3054 - val_accuracy: 0.8820\n",
      "Epoch 228/500\n",
      "127/127 [==============================] - 115s 908ms/step - loss: 0.3160 - accuracy: 0.8842 - val_loss: 0.4690 - val_accuracy: 0.8288\n",
      "Epoch 229/500\n",
      "127/127 [==============================] - 106s 838ms/step - loss: 0.3681 - accuracy: 0.8736 - val_loss: 0.3540 - val_accuracy: 0.8846\n",
      "Epoch 230/500\n",
      "127/127 [==============================] - 107s 844ms/step - loss: 0.3382 - accuracy: 0.8802 - val_loss: 0.4016 - val_accuracy: 0.8846\n",
      "Epoch 231/500\n",
      "127/127 [==============================] - 103s 810ms/step - loss: 0.3324 - accuracy: 0.8852 - val_loss: 0.2896 - val_accuracy: 0.8962\n",
      "Epoch 232/500\n",
      "127/127 [==============================] - 107s 846ms/step - loss: 0.2890 - accuracy: 0.8955 - val_loss: 0.3801 - val_accuracy: 0.8729\n",
      "Epoch 233/500\n",
      "127/127 [==============================] - 116s 912ms/step - loss: 0.3378 - accuracy: 0.8757 - val_loss: 0.3503 - val_accuracy: 0.8807\n",
      "Epoch 234/500\n",
      "127/127 [==============================] - 102s 804ms/step - loss: 0.3185 - accuracy: 0.8884 - val_loss: 0.3814 - val_accuracy: 0.8547\n",
      "Epoch 235/500\n",
      "127/127 [==============================] - 107s 846ms/step - loss: 0.3228 - accuracy: 0.8799 - val_loss: 0.3316 - val_accuracy: 0.8794\n",
      "Epoch 236/500\n",
      "127/127 [==============================] - 110s 866ms/step - loss: 0.3246 - accuracy: 0.8871 - val_loss: 0.3595 - val_accuracy: 0.8794\n",
      "Epoch 237/500\n",
      "127/127 [==============================] - 111s 873ms/step - loss: 0.3318 - accuracy: 0.8847 - val_loss: 0.3369 - val_accuracy: 0.8833\n",
      "Epoch 238/500\n",
      "127/127 [==============================] - 110s 864ms/step - loss: 0.3485 - accuracy: 0.8847 - val_loss: 0.3502 - val_accuracy: 0.8820\n",
      "Epoch 239/500\n",
      "127/127 [==============================] - 113s 890ms/step - loss: 0.3630 - accuracy: 0.8760 - val_loss: 0.3263 - val_accuracy: 0.8781\n",
      "Epoch 240/500\n",
      "127/127 [==============================] - 107s 841ms/step - loss: 0.3357 - accuracy: 0.8831 - val_loss: 0.3689 - val_accuracy: 0.8638\n",
      "Epoch 241/500\n",
      "127/127 [==============================] - 98s 774ms/step - loss: 0.3304 - accuracy: 0.8863 - val_loss: 0.3134 - val_accuracy: 0.8911\n",
      "Epoch 242/500\n",
      "127/127 [==============================] - 106s 834ms/step - loss: 0.2844 - accuracy: 0.8974 - val_loss: 0.4500 - val_accuracy: 0.8612\n",
      "Epoch 243/500\n",
      "127/127 [==============================] - 105s 826ms/step - loss: 0.3326 - accuracy: 0.8897 - val_loss: 0.3762 - val_accuracy: 0.8911\n",
      "Epoch 244/500\n",
      "127/127 [==============================] - 104s 823ms/step - loss: 0.3308 - accuracy: 0.8913 - val_loss: 0.3364 - val_accuracy: 0.8859\n",
      "Epoch 245/500\n",
      "127/127 [==============================] - 99s 781ms/step - loss: 0.3232 - accuracy: 0.8844 - val_loss: 0.2864 - val_accuracy: 0.8846\n",
      "Epoch 246/500\n",
      "127/127 [==============================] - 106s 836ms/step - loss: 0.3020 - accuracy: 0.8974 - val_loss: 0.4402 - val_accuracy: 0.8573\n",
      "Epoch 247/500\n",
      "127/127 [==============================] - 105s 827ms/step - loss: 0.2866 - accuracy: 0.9003 - val_loss: 0.3098 - val_accuracy: 0.8729\n",
      "Epoch 248/500\n",
      "127/127 [==============================] - 100s 788ms/step - loss: 0.3292 - accuracy: 0.8823 - val_loss: 0.3422 - val_accuracy: 0.8911\n",
      "Epoch 249/500\n",
      "127/127 [==============================] - 103s 810ms/step - loss: 0.3426 - accuracy: 0.8821 - val_loss: 0.3313 - val_accuracy: 0.8923\n",
      "Epoch 250/500\n",
      "127/127 [==============================] - 105s 825ms/step - loss: 0.3035 - accuracy: 0.8913 - val_loss: 0.3887 - val_accuracy: 0.8781\n",
      "Epoch 251/500\n",
      "127/127 [==============================] - 105s 827ms/step - loss: 0.3527 - accuracy: 0.8847 - val_loss: 0.4009 - val_accuracy: 0.8690\n",
      "Epoch 252/500\n",
      "127/127 [==============================] - 99s 782ms/step - loss: 0.3042 - accuracy: 0.8947 - val_loss: 0.3171 - val_accuracy: 0.8742\n",
      "Epoch 253/500\n",
      "127/127 [==============================] - 105s 829ms/step - loss: 0.3143 - accuracy: 0.8971 - val_loss: 0.4198 - val_accuracy: 0.8625\n",
      "Epoch 254/500\n",
      "127/127 [==============================] - 107s 841ms/step - loss: 0.2951 - accuracy: 0.8960 - val_loss: 0.4391 - val_accuracy: 0.8573\n",
      "Epoch 255/500\n",
      "127/127 [==============================] - 102s 805ms/step - loss: 0.4031 - accuracy: 0.8726 - val_loss: 0.3948 - val_accuracy: 0.8586\n",
      "Epoch 256/500\n",
      "127/127 [==============================] - 101s 794ms/step - loss: 0.3480 - accuracy: 0.8810 - val_loss: 0.3081 - val_accuracy: 0.8911\n",
      "Epoch 257/500\n",
      "127/127 [==============================] - 105s 830ms/step - loss: 0.3059 - accuracy: 0.8950 - val_loss: 0.4446 - val_accuracy: 0.8457\n",
      "Epoch 258/500\n",
      "127/127 [==============================] - 106s 837ms/step - loss: 0.3016 - accuracy: 0.8968 - val_loss: 0.4522 - val_accuracy: 0.8664\n",
      "Epoch 259/500\n",
      "127/127 [==============================] - 100s 785ms/step - loss: 0.2889 - accuracy: 0.9026 - val_loss: 0.3201 - val_accuracy: 0.8781\n",
      "Epoch 260/500\n",
      "127/127 [==============================] - 105s 826ms/step - loss: 0.2886 - accuracy: 0.9003 - val_loss: 0.3377 - val_accuracy: 0.8716\n",
      "Epoch 261/500\n",
      "127/127 [==============================] - 106s 836ms/step - loss: 0.3003 - accuracy: 0.8934 - val_loss: 0.3270 - val_accuracy: 0.8872\n",
      "Epoch 262/500\n",
      "127/127 [==============================] - 104s 819ms/step - loss: 0.3010 - accuracy: 0.8982 - val_loss: 0.3020 - val_accuracy: 0.8923\n",
      "Epoch 263/500\n",
      "127/127 [==============================] - 99s 779ms/step - loss: 0.3083 - accuracy: 0.8971 - val_loss: 0.3603 - val_accuracy: 0.8755\n",
      "Epoch 264/500\n",
      "127/127 [==============================] - 106s 832ms/step - loss: 0.3112 - accuracy: 0.8947 - val_loss: 0.3688 - val_accuracy: 0.8781\n",
      "Epoch 265/500\n",
      "127/127 [==============================] - 104s 815ms/step - loss: 0.2917 - accuracy: 0.8995 - val_loss: 0.2904 - val_accuracy: 0.8962\n",
      "Epoch 266/500\n",
      "127/127 [==============================] - 100s 790ms/step - loss: 0.2726 - accuracy: 0.9045 - val_loss: 0.2726 - val_accuracy: 0.9040\n",
      "Epoch 267/500\n",
      "127/127 [==============================] - 106s 833ms/step - loss: 0.2909 - accuracy: 0.9000 - val_loss: 0.3491 - val_accuracy: 0.8975\n",
      "Epoch 268/500\n",
      "127/127 [==============================] - 104s 821ms/step - loss: 0.3153 - accuracy: 0.8929 - val_loss: 0.2708 - val_accuracy: 0.9261\n",
      "Epoch 269/500\n",
      "127/127 [==============================] - 105s 827ms/step - loss: 0.2865 - accuracy: 0.8963 - val_loss: 0.3271 - val_accuracy: 0.8872\n",
      "Epoch 270/500\n",
      "127/127 [==============================] - 99s 783ms/step - loss: 0.2928 - accuracy: 0.8910 - val_loss: 0.3677 - val_accuracy: 0.8677\n",
      "Epoch 271/500\n",
      "127/127 [==============================] - 106s 834ms/step - loss: 0.3056 - accuracy: 0.8960 - val_loss: 0.3443 - val_accuracy: 0.8988\n",
      "Epoch 272/500\n",
      "127/127 [==============================] - 107s 843ms/step - loss: 0.3034 - accuracy: 0.8979 - val_loss: 0.2725 - val_accuracy: 0.9040\n",
      "Epoch 273/500\n",
      "127/127 [==============================] - 102s 805ms/step - loss: 0.3257 - accuracy: 0.8913 - val_loss: 0.3661 - val_accuracy: 0.8820\n",
      "Epoch 274/500\n",
      "127/127 [==============================] - 103s 812ms/step - loss: 0.3119 - accuracy: 0.8950 - val_loss: 0.4289 - val_accuracy: 0.8625\n",
      "Epoch 275/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 104s 823ms/step - loss: 0.3200 - accuracy: 0.8894 - val_loss: 0.2806 - val_accuracy: 0.9053\n",
      "Epoch 276/500\n",
      "127/127 [==============================] - 105s 829ms/step - loss: 0.3072 - accuracy: 0.8974 - val_loss: 0.3224 - val_accuracy: 0.8975\n",
      "Epoch 277/500\n",
      "127/127 [==============================] - 99s 781ms/step - loss: 0.3261 - accuracy: 0.8913 - val_loss: 0.2769 - val_accuracy: 0.9001\n",
      "Epoch 278/500\n",
      "127/127 [==============================] - 105s 825ms/step - loss: 0.2973 - accuracy: 0.8995 - val_loss: 0.3193 - val_accuracy: 0.9040\n",
      "Epoch 279/500\n",
      "127/127 [==============================] - 107s 845ms/step - loss: 0.2885 - accuracy: 0.9040 - val_loss: 0.2985 - val_accuracy: 0.8911\n",
      "Epoch 280/500\n",
      "127/127 [==============================] - 103s 809ms/step - loss: 0.2885 - accuracy: 0.9026 - val_loss: 0.3395 - val_accuracy: 0.8911\n",
      "Epoch 281/500\n",
      "127/127 [==============================] - 102s 805ms/step - loss: 0.2971 - accuracy: 0.8984 - val_loss: 0.2491 - val_accuracy: 0.9066\n",
      "Epoch 282/500\n",
      "127/127 [==============================] - 106s 831ms/step - loss: 0.3155 - accuracy: 0.8931 - val_loss: 0.3533 - val_accuracy: 0.8898\n",
      "Epoch 283/500\n",
      "127/127 [==============================] - 104s 820ms/step - loss: 0.2871 - accuracy: 0.8989 - val_loss: 0.4382 - val_accuracy: 0.8664\n",
      "Epoch 284/500\n",
      "127/127 [==============================] - 99s 782ms/step - loss: 0.2997 - accuracy: 0.8992 - val_loss: 0.3605 - val_accuracy: 0.8911\n",
      "Epoch 285/500\n",
      "127/127 [==============================] - 106s 832ms/step - loss: 0.3185 - accuracy: 0.8889 - val_loss: 0.4251 - val_accuracy: 0.8703\n",
      "Epoch 286/500\n",
      "127/127 [==============================] - 105s 825ms/step - loss: 0.2837 - accuracy: 0.8955 - val_loss: 0.2969 - val_accuracy: 0.8898\n",
      "Epoch 287/500\n",
      "127/127 [==============================] - 105s 823ms/step - loss: 0.2829 - accuracy: 0.9005 - val_loss: 0.3452 - val_accuracy: 0.8846\n",
      "Epoch 288/500\n",
      "127/127 [==============================] - 99s 781ms/step - loss: 0.2913 - accuracy: 0.8960 - val_loss: 0.3432 - val_accuracy: 0.8975\n",
      "Epoch 289/500\n",
      "127/127 [==============================] - 105s 828ms/step - loss: 0.2868 - accuracy: 0.9040 - val_loss: 0.2936 - val_accuracy: 0.9040\n",
      "Epoch 290/500\n",
      "127/127 [==============================] - 105s 826ms/step - loss: 0.2538 - accuracy: 0.9090 - val_loss: 0.2491 - val_accuracy: 0.9144\n",
      "Epoch 291/500\n",
      "127/127 [==============================] - 100s 790ms/step - loss: 0.2618 - accuracy: 0.9129 - val_loss: 0.3003 - val_accuracy: 0.9053\n",
      "Epoch 292/500\n",
      "127/127 [==============================] - 104s 817ms/step - loss: 0.3333 - accuracy: 0.8900 - val_loss: 0.4739 - val_accuracy: 0.8612\n",
      "Epoch 293/500\n",
      "127/127 [==============================] - 105s 827ms/step - loss: 0.3022 - accuracy: 0.9003 - val_loss: 0.3686 - val_accuracy: 0.8742\n",
      "Epoch 294/500\n",
      "127/127 [==============================] - 105s 824ms/step - loss: 0.2841 - accuracy: 0.8995 - val_loss: 0.3530 - val_accuracy: 0.8949\n",
      "Epoch 295/500\n",
      "127/127 [==============================] - 103s 811ms/step - loss: 0.2903 - accuracy: 0.9047 - val_loss: 0.4108 - val_accuracy: 0.8820\n",
      "Epoch 296/500\n",
      "127/127 [==============================] - 106s 832ms/step - loss: 0.3054 - accuracy: 0.9021 - val_loss: 0.3504 - val_accuracy: 0.8911\n",
      "Epoch 297/500\n",
      "127/127 [==============================] - 105s 831ms/step - loss: 0.2885 - accuracy: 0.9034 - val_loss: 0.3355 - val_accuracy: 0.9014\n",
      "Epoch 298/500\n",
      "127/127 [==============================] - 102s 803ms/step - loss: 0.2834 - accuracy: 0.9013 - val_loss: 0.3790 - val_accuracy: 0.8703\n",
      "Epoch 299/500\n",
      "127/127 [==============================] - 106s 833ms/step - loss: 0.2761 - accuracy: 0.9087 - val_loss: 0.2586 - val_accuracy: 0.9131\n",
      "Epoch 300/500\n",
      "127/127 [==============================] - 106s 832ms/step - loss: 0.2724 - accuracy: 0.9095 - val_loss: 0.2620 - val_accuracy: 0.9040\n",
      "Epoch 301/500\n",
      "127/127 [==============================] - 105s 829ms/step - loss: 0.3110 - accuracy: 0.8971 - val_loss: 0.3749 - val_accuracy: 0.8716\n",
      "Epoch 302/500\n",
      "127/127 [==============================] - 99s 776ms/step - loss: 0.2867 - accuracy: 0.9024 - val_loss: 0.2912 - val_accuracy: 0.9053\n",
      "Epoch 303/500\n",
      "127/127 [==============================] - 106s 832ms/step - loss: 0.2410 - accuracy: 0.9150 - val_loss: 0.2745 - val_accuracy: 0.8911\n",
      "Epoch 304/500\n",
      "127/127 [==============================] - 106s 834ms/step - loss: 0.3045 - accuracy: 0.9026 - val_loss: 0.3379 - val_accuracy: 0.9014\n",
      "Epoch 305/500\n",
      "127/127 [==============================] - 103s 810ms/step - loss: 0.2763 - accuracy: 0.9061 - val_loss: 0.2879 - val_accuracy: 0.9105\n",
      "Epoch 306/500\n",
      "127/127 [==============================] - 114s 901ms/step - loss: 0.3303 - accuracy: 0.8892 - val_loss: 0.3555 - val_accuracy: 0.8755\n",
      "Epoch 307/500\n",
      "127/127 [==============================] - 109s 856ms/step - loss: 0.2736 - accuracy: 0.9079 - val_loss: 0.2810 - val_accuracy: 0.9079\n",
      "Epoch 308/500\n",
      "127/127 [==============================] - 106s 837ms/step - loss: 0.2701 - accuracy: 0.9077 - val_loss: 0.3100 - val_accuracy: 0.8988\n",
      "Epoch 309/500\n",
      "127/127 [==============================] - 99s 780ms/step - loss: 0.2921 - accuracy: 0.9018 - val_loss: 0.3169 - val_accuracy: 0.9079\n",
      "Epoch 310/500\n",
      "127/127 [==============================] - 106s 833ms/step - loss: 0.2777 - accuracy: 0.9029 - val_loss: 0.3262 - val_accuracy: 0.8846\n",
      "Epoch 311/500\n",
      "127/127 [==============================] - 106s 837ms/step - loss: 0.3304 - accuracy: 0.8900 - val_loss: 0.3274 - val_accuracy: 0.9001\n",
      "Epoch 312/500\n",
      "127/127 [==============================] - 105s 829ms/step - loss: 0.2662 - accuracy: 0.9069 - val_loss: 0.3087 - val_accuracy: 0.8807\n",
      "Epoch 313/500\n",
      "127/127 [==============================] - 100s 790ms/step - loss: 0.3023 - accuracy: 0.8984 - val_loss: 0.3131 - val_accuracy: 0.8936\n",
      "Epoch 314/500\n",
      "127/127 [==============================] - 104s 817ms/step - loss: 0.2623 - accuracy: 0.9113 - val_loss: 0.3284 - val_accuracy: 0.8975\n",
      "Epoch 315/500\n",
      "127/127 [==============================] - 107s 839ms/step - loss: 0.2773 - accuracy: 0.9098 - val_loss: 0.3985 - val_accuracy: 0.8820\n",
      "Epoch 316/500\n",
      "127/127 [==============================] - 105s 826ms/step - loss: 0.3006 - accuracy: 0.9026 - val_loss: 0.3014 - val_accuracy: 0.9092\n",
      "Epoch 317/500\n",
      "127/127 [==============================] - 111s 876ms/step - loss: 0.3058 - accuracy: 0.8947 - val_loss: 0.3089 - val_accuracy: 0.8911\n",
      "Epoch 318/500\n",
      "127/127 [==============================] - 112s 884ms/step - loss: 0.3298 - accuracy: 0.8947 - val_loss: 0.3351 - val_accuracy: 0.8898\n",
      "Epoch 319/500\n",
      "127/127 [==============================] - 119s 937ms/step - loss: 0.3387 - accuracy: 0.8900 - val_loss: 0.3342 - val_accuracy: 0.8833\n",
      "Epoch 320/500\n",
      "127/127 [==============================] - 119s 939ms/step - loss: 0.2556 - accuracy: 0.9161 - val_loss: 0.2990 - val_accuracy: 0.8949\n",
      "Epoch 321/500\n",
      "127/127 [==============================] - 117s 920ms/step - loss: 0.3133 - accuracy: 0.8963 - val_loss: 0.4910 - val_accuracy: 0.8651\n",
      "Epoch 322/500\n",
      "127/127 [==============================] - 89s 698ms/step - loss: 0.2668 - accuracy: 0.9092 - val_loss: 0.2764 - val_accuracy: 0.9105\n",
      "Epoch 323/500\n",
      "127/127 [==============================] - 78s 615ms/step - loss: 0.2568 - accuracy: 0.9135 - val_loss: 0.3950 - val_accuracy: 0.8768\n",
      "Epoch 324/500\n",
      "127/127 [==============================] - 79s 624ms/step - loss: 0.2812 - accuracy: 0.9092 - val_loss: 0.2826 - val_accuracy: 0.9079\n",
      "Epoch 325/500\n",
      "127/127 [==============================] - 78s 613ms/step - loss: 0.3019 - accuracy: 0.9037 - val_loss: 0.2241 - val_accuracy: 0.9183\n",
      "Epoch 326/500\n",
      "127/127 [==============================] - 78s 611ms/step - loss: 0.2750 - accuracy: 0.9042 - val_loss: 0.2540 - val_accuracy: 0.9066\n",
      "Epoch 327/500\n",
      "127/127 [==============================] - 77s 607ms/step - loss: 0.3070 - accuracy: 0.9069 - val_loss: 0.2823 - val_accuracy: 0.9053\n",
      "Epoch 328/500\n",
      "127/127 [==============================] - 79s 620ms/step - loss: 0.2594 - accuracy: 0.9148 - val_loss: 0.3820 - val_accuracy: 0.8846\n",
      "Epoch 329/500\n",
      "127/127 [==============================] - 77s 607ms/step - loss: 0.2966 - accuracy: 0.9029 - val_loss: 0.3591 - val_accuracy: 0.8898\n",
      "Epoch 330/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 78s 615ms/step - loss: 0.3060 - accuracy: 0.8963 - val_loss: 0.2934 - val_accuracy: 0.9001\n",
      "Epoch 331/500\n",
      "127/127 [==============================] - 77s 607ms/step - loss: 0.2477 - accuracy: 0.9132 - val_loss: 0.3378 - val_accuracy: 0.9001\n",
      "Epoch 332/500\n",
      "127/127 [==============================] - 78s 610ms/step - loss: 0.2922 - accuracy: 0.9145 - val_loss: 0.2417 - val_accuracy: 0.9066\n",
      "Epoch 333/500\n",
      "127/127 [==============================] - 78s 612ms/step - loss: 0.2801 - accuracy: 0.9082 - val_loss: 0.2893 - val_accuracy: 0.9092\n",
      "Epoch 334/500\n",
      "127/127 [==============================] - 78s 612ms/step - loss: 0.3116 - accuracy: 0.9077 - val_loss: 0.2814 - val_accuracy: 0.8988\n",
      "Epoch 335/500\n",
      "127/127 [==============================] - 77s 610ms/step - loss: 0.3061 - accuracy: 0.8963 - val_loss: 0.2685 - val_accuracy: 0.9183\n",
      "Epoch 336/500\n",
      "127/127 [==============================] - 77s 607ms/step - loss: 0.3057 - accuracy: 0.8989 - val_loss: 0.2802 - val_accuracy: 0.8936\n",
      "Epoch 337/500\n",
      "127/127 [==============================] - 78s 614ms/step - loss: 0.2908 - accuracy: 0.9061 - val_loss: 0.2272 - val_accuracy: 0.9144\n",
      "Epoch 338/500\n",
      "127/127 [==============================] - 77s 610ms/step - loss: 0.2634 - accuracy: 0.9098 - val_loss: 0.2902 - val_accuracy: 0.9014\n",
      "Epoch 339/500\n",
      "127/127 [==============================] - 78s 613ms/step - loss: 0.2904 - accuracy: 0.9053 - val_loss: 0.3706 - val_accuracy: 0.8768\n",
      "Epoch 340/500\n",
      "127/127 [==============================] - 78s 613ms/step - loss: 0.2752 - accuracy: 0.9055 - val_loss: 0.2853 - val_accuracy: 0.9105\n",
      "Epoch 341/500\n",
      "127/127 [==============================] - 77s 610ms/step - loss: 0.2816 - accuracy: 0.9077 - val_loss: 0.3668 - val_accuracy: 0.8923\n",
      "Epoch 342/500\n",
      "127/127 [==============================] - 78s 612ms/step - loss: 0.2661 - accuracy: 0.9121 - val_loss: 0.2629 - val_accuracy: 0.9066\n",
      "Epoch 343/500\n",
      "127/127 [==============================] - 84s 660ms/step - loss: 0.2441 - accuracy: 0.9158 - val_loss: 0.2917 - val_accuracy: 0.9040\n",
      "Epoch 344/500\n",
      "127/127 [==============================] - 109s 855ms/step - loss: 0.2557 - accuracy: 0.9172 - val_loss: 0.2634 - val_accuracy: 0.9196\n",
      "Epoch 345/500\n",
      "127/127 [==============================] - 101s 798ms/step - loss: 0.2927 - accuracy: 0.9092 - val_loss: 0.3184 - val_accuracy: 0.8975\n",
      "Epoch 346/500\n",
      "127/127 [==============================] - 101s 796ms/step - loss: 0.2843 - accuracy: 0.9106 - val_loss: 0.2971 - val_accuracy: 0.9118\n",
      "Epoch 347/500\n",
      "127/127 [==============================] - 103s 808ms/step - loss: 0.2723 - accuracy: 0.9108 - val_loss: 0.2514 - val_accuracy: 0.9131\n",
      "Epoch 348/500\n",
      "127/127 [==============================] - 96s 759ms/step - loss: 0.2966 - accuracy: 0.9032 - val_loss: 0.3098 - val_accuracy: 0.9040\n",
      "Epoch 349/500\n",
      "127/127 [==============================] - 102s 803ms/step - loss: 0.2760 - accuracy: 0.9108 - val_loss: 0.2825 - val_accuracy: 0.9092\n",
      "Epoch 350/500\n",
      "127/127 [==============================] - 108s 854ms/step - loss: 0.2426 - accuracy: 0.9193 - val_loss: 0.2935 - val_accuracy: 0.9014\n",
      "Epoch 351/500\n",
      "127/127 [==============================] - 106s 838ms/step - loss: 0.2853 - accuracy: 0.9047 - val_loss: 0.2554 - val_accuracy: 0.9183\n",
      "Epoch 352/500\n",
      "127/127 [==============================] - 99s 780ms/step - loss: 0.2642 - accuracy: 0.9132 - val_loss: 0.3698 - val_accuracy: 0.8872\n",
      "Epoch 353/500\n",
      "127/127 [==============================] - 105s 825ms/step - loss: 0.2691 - accuracy: 0.9098 - val_loss: 0.3817 - val_accuracy: 0.8846\n",
      "Epoch 354/500\n",
      "127/127 [==============================] - 105s 829ms/step - loss: 0.2617 - accuracy: 0.9103 - val_loss: 0.2226 - val_accuracy: 0.9326\n",
      "Epoch 355/500\n",
      "127/127 [==============================] - 107s 844ms/step - loss: 0.2699 - accuracy: 0.9164 - val_loss: 0.2422 - val_accuracy: 0.9196\n",
      "Epoch 356/500\n",
      "127/127 [==============================] - 100s 791ms/step - loss: 0.2836 - accuracy: 0.9092 - val_loss: 0.4139 - val_accuracy: 0.8872\n",
      "Epoch 357/500\n",
      "127/127 [==============================] - 97s 761ms/step - loss: 0.2872 - accuracy: 0.9063 - val_loss: 0.2958 - val_accuracy: 0.8949\n",
      "Epoch 358/500\n",
      "127/127 [==============================] - 96s 760ms/step - loss: 0.2652 - accuracy: 0.9172 - val_loss: 0.3307 - val_accuracy: 0.9014\n",
      "Epoch 359/500\n",
      "127/127 [==============================] - 101s 794ms/step - loss: 0.2652 - accuracy: 0.9145 - val_loss: 0.3326 - val_accuracy: 0.8911\n",
      "Epoch 360/500\n",
      "127/127 [==============================] - 102s 799ms/step - loss: 0.3056 - accuracy: 0.9090 - val_loss: 0.2484 - val_accuracy: 0.9261\n",
      "Epoch 361/500\n",
      "127/127 [==============================] - 94s 741ms/step - loss: 0.2512 - accuracy: 0.9169 - val_loss: 0.4176 - val_accuracy: 0.8833\n",
      "Epoch 362/500\n",
      "127/127 [==============================] - 101s 799ms/step - loss: 0.3530 - accuracy: 0.8902 - val_loss: 0.4014 - val_accuracy: 0.8820\n",
      "Epoch 363/500\n",
      "127/127 [==============================] - 101s 792ms/step - loss: 0.2915 - accuracy: 0.9127 - val_loss: 0.2762 - val_accuracy: 0.9066\n",
      "Epoch 364/500\n",
      "127/127 [==============================] - 98s 768ms/step - loss: 0.2859 - accuracy: 0.9084 - val_loss: 0.2926 - val_accuracy: 0.9118\n",
      "Epoch 365/500\n",
      "127/127 [==============================] - 96s 756ms/step - loss: 0.2674 - accuracy: 0.9148 - val_loss: 0.2942 - val_accuracy: 0.9118\n",
      "Epoch 366/500\n",
      "127/127 [==============================] - 100s 785ms/step - loss: 0.2892 - accuracy: 0.9058 - val_loss: 0.3853 - val_accuracy: 0.8833\n",
      "Epoch 367/500\n",
      "127/127 [==============================] - 100s 786ms/step - loss: 0.2879 - accuracy: 0.9100 - val_loss: 0.2052 - val_accuracy: 0.9287\n",
      "Epoch 368/500\n",
      "127/127 [==============================] - 94s 737ms/step - loss: 0.2840 - accuracy: 0.9121 - val_loss: 0.2668 - val_accuracy: 0.9118\n",
      "Epoch 369/500\n",
      "127/127 [==============================] - 101s 797ms/step - loss: 0.2479 - accuracy: 0.9164 - val_loss: 0.3236 - val_accuracy: 0.9092\n",
      "Epoch 370/500\n",
      "127/127 [==============================] - 101s 798ms/step - loss: 0.2537 - accuracy: 0.9140 - val_loss: 0.2910 - val_accuracy: 0.9105\n",
      "Epoch 371/500\n",
      "127/127 [==============================] - 100s 788ms/step - loss: 0.2756 - accuracy: 0.9084 - val_loss: 0.2670 - val_accuracy: 0.9170\n",
      "Epoch 372/500\n",
      "127/127 [==============================] - 94s 742ms/step - loss: 0.2567 - accuracy: 0.9111 - val_loss: 0.2757 - val_accuracy: 0.9066\n",
      "Epoch 373/500\n",
      "127/127 [==============================] - 101s 796ms/step - loss: 0.2514 - accuracy: 0.9142 - val_loss: 0.2757 - val_accuracy: 0.9027\n",
      "Epoch 374/500\n",
      "127/127 [==============================] - 101s 794ms/step - loss: 0.2718 - accuracy: 0.9187 - val_loss: 0.3035 - val_accuracy: 0.8923\n",
      "Epoch 375/500\n",
      "127/127 [==============================] - 97s 763ms/step - loss: 0.2938 - accuracy: 0.9092 - val_loss: 0.2691 - val_accuracy: 0.9157\n",
      "Epoch 376/500\n",
      "127/127 [==============================] - 99s 777ms/step - loss: 0.3015 - accuracy: 0.9042 - val_loss: 0.2439 - val_accuracy: 0.9222\n",
      "Epoch 377/500\n",
      "127/127 [==============================] - 100s 790ms/step - loss: 0.2352 - accuracy: 0.9187 - val_loss: 0.3369 - val_accuracy: 0.9040\n",
      "Epoch 378/500\n",
      "127/127 [==============================] - 101s 796ms/step - loss: 0.2444 - accuracy: 0.9182 - val_loss: 0.2681 - val_accuracy: 0.9131\n",
      "Epoch 379/500\n",
      "127/127 [==============================] - 95s 745ms/step - loss: 0.2930 - accuracy: 0.9145 - val_loss: 0.2700 - val_accuracy: 0.9183\n",
      "Epoch 380/500\n",
      "127/127 [==============================] - 101s 799ms/step - loss: 0.2785 - accuracy: 0.9116 - val_loss: 0.3970 - val_accuracy: 0.8768\n",
      "Epoch 381/500\n",
      "127/127 [==============================] - 100s 788ms/step - loss: 0.2873 - accuracy: 0.9127 - val_loss: 0.2912 - val_accuracy: 0.9183\n",
      "Epoch 382/500\n",
      "127/127 [==============================] - 97s 767ms/step - loss: 0.2754 - accuracy: 0.9156 - val_loss: 0.2523 - val_accuracy: 0.9274\n",
      "Epoch 383/500\n",
      "127/127 [==============================] - 98s 771ms/step - loss: 0.2712 - accuracy: 0.9142 - val_loss: 0.2829 - val_accuracy: 0.9105\n",
      "Epoch 384/500\n",
      "127/127 [==============================] - 102s 803ms/step - loss: 0.2124 - accuracy: 0.9348 - val_loss: 0.2502 - val_accuracy: 0.9222\n",
      "Epoch 385/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 102s 801ms/step - loss: 0.2888 - accuracy: 0.9124 - val_loss: 0.3116 - val_accuracy: 0.9040\n",
      "Epoch 386/500\n",
      "127/127 [==============================] - 96s 753ms/step - loss: 0.2630 - accuracy: 0.9119 - val_loss: 0.3983 - val_accuracy: 0.8872\n",
      "Epoch 387/500\n",
      "127/127 [==============================] - 102s 802ms/step - loss: 0.2362 - accuracy: 0.9201 - val_loss: 0.2692 - val_accuracy: 0.9222\n",
      "Epoch 388/500\n",
      "127/127 [==============================] - 103s 813ms/step - loss: 0.2529 - accuracy: 0.9166 - val_loss: 0.2768 - val_accuracy: 0.9196\n",
      "Epoch 389/500\n",
      "127/127 [==============================] - 99s 776ms/step - loss: 0.3143 - accuracy: 0.9050 - val_loss: 0.4135 - val_accuracy: 0.8807\n",
      "Epoch 390/500\n",
      "127/127 [==============================] - 97s 763ms/step - loss: 0.2764 - accuracy: 0.9132 - val_loss: 0.2196 - val_accuracy: 0.9300\n",
      "Epoch 391/500\n",
      "127/127 [==============================] - 100s 788ms/step - loss: 0.2378 - accuracy: 0.9235 - val_loss: 0.2831 - val_accuracy: 0.9079\n",
      "Epoch 392/500\n",
      "127/127 [==============================] - 102s 801ms/step - loss: 0.2615 - accuracy: 0.9198 - val_loss: 0.3046 - val_accuracy: 0.8949\n",
      "Epoch 393/500\n",
      "127/127 [==============================] - 94s 744ms/step - loss: 0.2934 - accuracy: 0.9053 - val_loss: 0.2828 - val_accuracy: 0.9092\n",
      "Epoch 394/500\n",
      "127/127 [==============================] - 102s 801ms/step - loss: 0.2714 - accuracy: 0.9164 - val_loss: 0.3618 - val_accuracy: 0.8898\n",
      "Epoch 395/500\n",
      "127/127 [==============================] - 100s 787ms/step - loss: 0.2716 - accuracy: 0.9164 - val_loss: 0.3357 - val_accuracy: 0.9027\n",
      "Epoch 396/500\n",
      "127/127 [==============================] - 98s 773ms/step - loss: 0.2669 - accuracy: 0.9108 - val_loss: 0.2746 - val_accuracy: 0.9196\n",
      "Epoch 397/500\n",
      "127/127 [==============================] - 95s 751ms/step - loss: 0.2124 - accuracy: 0.9303 - val_loss: 0.2968 - val_accuracy: 0.9261\n",
      "Epoch 398/500\n",
      "127/127 [==============================] - 100s 788ms/step - loss: 0.3026 - accuracy: 0.9098 - val_loss: 0.4096 - val_accuracy: 0.8794\n",
      "Epoch 399/500\n",
      "127/127 [==============================] - 100s 791ms/step - loss: 0.2728 - accuracy: 0.9129 - val_loss: 0.2817 - val_accuracy: 0.9144\n",
      "Epoch 400/500\n",
      "127/127 [==============================] - 96s 760ms/step - loss: 0.2693 - accuracy: 0.9219 - val_loss: 0.2699 - val_accuracy: 0.9170\n",
      "Epoch 401/500\n",
      "127/127 [==============================] - 100s 791ms/step - loss: 0.2237 - accuracy: 0.9266 - val_loss: 0.2753 - val_accuracy: 0.9287\n",
      "Epoch 402/500\n",
      "127/127 [==============================] - 100s 785ms/step - loss: 0.2735 - accuracy: 0.9142 - val_loss: 0.2876 - val_accuracy: 0.8949\n",
      "Epoch 403/500\n",
      "127/127 [==============================] - 100s 791ms/step - loss: 0.2673 - accuracy: 0.9161 - val_loss: 0.3097 - val_accuracy: 0.9014\n",
      "Epoch 404/500\n",
      "127/127 [==============================] - 95s 745ms/step - loss: 0.2485 - accuracy: 0.9237 - val_loss: 0.3828 - val_accuracy: 0.8885\n",
      "Epoch 405/500\n",
      "127/127 [==============================] - 101s 796ms/step - loss: 0.2715 - accuracy: 0.9172 - val_loss: 0.2707 - val_accuracy: 0.9066\n",
      "Epoch 406/500\n",
      "127/127 [==============================] - 100s 787ms/step - loss: 0.2522 - accuracy: 0.9243 - val_loss: 0.2612 - val_accuracy: 0.9118\n",
      "Epoch 407/500\n",
      "127/127 [==============================] - 97s 763ms/step - loss: 0.2678 - accuracy: 0.9216 - val_loss: 0.3191 - val_accuracy: 0.9053\n",
      "Epoch 408/500\n",
      "127/127 [==============================] - 101s 795ms/step - loss: 0.2727 - accuracy: 0.9140 - val_loss: 0.2291 - val_accuracy: 0.9222\n",
      "Epoch 409/500\n",
      "127/127 [==============================] - 101s 792ms/step - loss: 0.2628 - accuracy: 0.9219 - val_loss: 0.2845 - val_accuracy: 0.9092\n",
      "Epoch 410/500\n",
      "127/127 [==============================] - 102s 800ms/step - loss: 0.2414 - accuracy: 0.9237 - val_loss: 0.3366 - val_accuracy: 0.8872\n",
      "Epoch 411/500\n",
      "127/127 [==============================] - 95s 749ms/step - loss: 0.2957 - accuracy: 0.9069 - val_loss: 0.3035 - val_accuracy: 0.9118\n",
      "Epoch 412/500\n",
      "127/127 [==============================] - 100s 788ms/step - loss: 0.3055 - accuracy: 0.9084 - val_loss: 0.3649 - val_accuracy: 0.8962\n",
      "Epoch 413/500\n",
      "127/127 [==============================] - 101s 793ms/step - loss: 0.2756 - accuracy: 0.9172 - val_loss: 0.2756 - val_accuracy: 0.9118\n",
      "Epoch 414/500\n",
      "127/127 [==============================] - 99s 776ms/step - loss: 0.2888 - accuracy: 0.9137 - val_loss: 0.2902 - val_accuracy: 0.9066\n",
      "Epoch 415/500\n",
      "127/127 [==============================] - 98s 772ms/step - loss: 0.2819 - accuracy: 0.9127 - val_loss: 0.3709 - val_accuracy: 0.8923\n",
      "Epoch 416/500\n",
      "127/127 [==============================] - 99s 780ms/step - loss: 0.2727 - accuracy: 0.9153 - val_loss: 0.3013 - val_accuracy: 0.9105\n",
      "Epoch 417/500\n",
      "127/127 [==============================] - 101s 794ms/step - loss: 0.2400 - accuracy: 0.9211 - val_loss: 0.2784 - val_accuracy: 0.9248\n",
      "Epoch 418/500\n",
      "127/127 [==============================] - 96s 756ms/step - loss: 0.2466 - accuracy: 0.9211 - val_loss: 0.3782 - val_accuracy: 0.8898\n",
      "Epoch 419/500\n",
      "127/127 [==============================] - 100s 790ms/step - loss: 0.2549 - accuracy: 0.9232 - val_loss: 0.2581 - val_accuracy: 0.9092\n",
      "Epoch 420/500\n",
      "127/127 [==============================] - 101s 796ms/step - loss: 0.2497 - accuracy: 0.9227 - val_loss: 0.2369 - val_accuracy: 0.9183\n",
      "Epoch 421/500\n",
      "127/127 [==============================] - 100s 787ms/step - loss: 0.2800 - accuracy: 0.9185 - val_loss: 0.2598 - val_accuracy: 0.9170\n",
      "Epoch 422/500\n",
      "127/127 [==============================] - 98s 773ms/step - loss: 0.2775 - accuracy: 0.9129 - val_loss: 0.3083 - val_accuracy: 0.9144\n",
      "Epoch 423/500\n",
      "127/127 [==============================] - 101s 797ms/step - loss: 0.2785 - accuracy: 0.9206 - val_loss: 0.2093 - val_accuracy: 0.9390\n",
      "Epoch 424/500\n",
      "127/127 [==============================] - 100s 787ms/step - loss: 0.2505 - accuracy: 0.9222 - val_loss: 0.3430 - val_accuracy: 0.9001\n",
      "Epoch 425/500\n",
      "127/127 [==============================] - 96s 756ms/step - loss: 0.2816 - accuracy: 0.9135 - val_loss: 0.2074 - val_accuracy: 0.9326\n",
      "Epoch 426/500\n",
      "127/127 [==============================] - 102s 804ms/step - loss: 0.2581 - accuracy: 0.9179 - val_loss: 0.2812 - val_accuracy: 0.9092\n",
      "Epoch 427/500\n",
      "127/127 [==============================] - 100s 790ms/step - loss: 0.2324 - accuracy: 0.9266 - val_loss: 0.2960 - val_accuracy: 0.9157\n",
      "Epoch 428/500\n",
      "127/127 [==============================] - 101s 798ms/step - loss: 0.3038 - accuracy: 0.9153 - val_loss: 0.4364 - val_accuracy: 0.8936\n",
      "Epoch 429/500\n",
      "127/127 [==============================] - 95s 750ms/step - loss: 0.2496 - accuracy: 0.9235 - val_loss: 0.2538 - val_accuracy: 0.9261\n",
      "Epoch 430/500\n",
      "127/127 [==============================] - 100s 791ms/step - loss: 0.2656 - accuracy: 0.9195 - val_loss: 0.2624 - val_accuracy: 0.9079\n",
      "Epoch 431/500\n",
      "127/127 [==============================] - 100s 789ms/step - loss: 0.2960 - accuracy: 0.9111 - val_loss: 0.2607 - val_accuracy: 0.9196\n",
      "Epoch 432/500\n",
      "127/127 [==============================] - 96s 760ms/step - loss: 0.2863 - accuracy: 0.9156 - val_loss: 0.3770 - val_accuracy: 0.9053\n",
      "Epoch 433/500\n",
      "127/127 [==============================] - 100s 784ms/step - loss: 0.2639 - accuracy: 0.9156 - val_loss: 0.2380 - val_accuracy: 0.9261\n",
      "Epoch 434/500\n",
      "127/127 [==============================] - 101s 793ms/step - loss: 0.2699 - accuracy: 0.9264 - val_loss: 0.3138 - val_accuracy: 0.9261\n",
      "Epoch 435/500\n",
      "127/127 [==============================] - 100s 789ms/step - loss: 0.3104 - accuracy: 0.9061 - val_loss: 0.2952 - val_accuracy: 0.9157\n",
      "Epoch 436/500\n",
      "127/127 [==============================] - 95s 750ms/step - loss: 0.2378 - accuracy: 0.9245 - val_loss: 0.2926 - val_accuracy: 0.9105\n",
      "Epoch 437/500\n",
      "127/127 [==============================] - 102s 806ms/step - loss: 0.2782 - accuracy: 0.9153 - val_loss: 0.5220 - val_accuracy: 0.8742\n",
      "Epoch 438/500\n",
      "127/127 [==============================] - 101s 798ms/step - loss: 0.3059 - accuracy: 0.9145 - val_loss: 0.2570 - val_accuracy: 0.9313\n",
      "Epoch 439/500\n",
      "127/127 [==============================] - 97s 762ms/step - loss: 0.2446 - accuracy: 0.9227 - val_loss: 0.3276 - val_accuracy: 0.9079\n",
      "Epoch 440/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 97s 764ms/step - loss: 0.2298 - accuracy: 0.9367 - val_loss: 0.3078 - val_accuracy: 0.9144\n",
      "Epoch 441/500\n",
      "127/127 [==============================] - 100s 789ms/step - loss: 0.2738 - accuracy: 0.9127 - val_loss: 0.3061 - val_accuracy: 0.9118\n",
      "Epoch 442/500\n",
      "127/127 [==============================] - 102s 802ms/step - loss: 0.2514 - accuracy: 0.9211 - val_loss: 0.3202 - val_accuracy: 0.9040\n",
      "Epoch 443/500\n",
      "127/127 [==============================] - 95s 751ms/step - loss: 0.2590 - accuracy: 0.9237 - val_loss: 0.2442 - val_accuracy: 0.9248\n",
      "Epoch 444/500\n",
      "127/127 [==============================] - 100s 790ms/step - loss: 0.2413 - accuracy: 0.9285 - val_loss: 0.3882 - val_accuracy: 0.8872\n",
      "Epoch 445/500\n",
      "127/127 [==============================] - 101s 798ms/step - loss: 0.2430 - accuracy: 0.9222 - val_loss: 0.3056 - val_accuracy: 0.8936\n",
      "Epoch 446/500\n",
      "127/127 [==============================] - 99s 780ms/step - loss: 0.2457 - accuracy: 0.9243 - val_loss: 0.3347 - val_accuracy: 0.9118\n",
      "Epoch 447/500\n",
      "127/127 [==============================] - 98s 770ms/step - loss: 0.2265 - accuracy: 0.9298 - val_loss: 0.2346 - val_accuracy: 0.9157\n",
      "Epoch 448/500\n",
      "127/127 [==============================] - 101s 799ms/step - loss: 0.2752 - accuracy: 0.9142 - val_loss: 0.2848 - val_accuracy: 0.9235\n",
      "Epoch 449/500\n",
      "127/127 [==============================] - 101s 797ms/step - loss: 0.2817 - accuracy: 0.9245 - val_loss: 0.2990 - val_accuracy: 0.9118\n",
      "Epoch 450/500\n",
      "127/127 [==============================] - 96s 756ms/step - loss: 0.2551 - accuracy: 0.9211 - val_loss: 0.4532 - val_accuracy: 0.9027\n",
      "Epoch 451/500\n",
      "127/127 [==============================] - 100s 791ms/step - loss: 0.2952 - accuracy: 0.9161 - val_loss: 0.2425 - val_accuracy: 0.9300\n",
      "Epoch 452/500\n",
      "127/127 [==============================] - 101s 799ms/step - loss: 0.2332 - accuracy: 0.9280 - val_loss: 0.2661 - val_accuracy: 0.9157\n",
      "Epoch 453/500\n",
      "127/127 [==============================] - 100s 791ms/step - loss: 0.2650 - accuracy: 0.9214 - val_loss: 0.2598 - val_accuracy: 0.9170\n",
      "Epoch 454/500\n",
      "127/127 [==============================] - 96s 753ms/step - loss: 0.2660 - accuracy: 0.9251 - val_loss: 0.2465 - val_accuracy: 0.9274\n",
      "Epoch 455/500\n",
      "127/127 [==============================] - 100s 789ms/step - loss: 0.2489 - accuracy: 0.9301 - val_loss: 0.3815 - val_accuracy: 0.9092\n",
      "Epoch 456/500\n",
      "127/127 [==============================] - 101s 795ms/step - loss: 0.2463 - accuracy: 0.9216 - val_loss: 0.3109 - val_accuracy: 0.9144\n",
      "Epoch 457/500\n",
      "127/127 [==============================] - 96s 757ms/step - loss: 0.2475 - accuracy: 0.9245 - val_loss: 0.3198 - val_accuracy: 0.8988\n",
      "Epoch 458/500\n",
      "127/127 [==============================] - 101s 792ms/step - loss: 0.2511 - accuracy: 0.9219 - val_loss: 0.3426 - val_accuracy: 0.8923\n",
      "Epoch 459/500\n",
      "127/127 [==============================] - 101s 799ms/step - loss: 0.2509 - accuracy: 0.9290 - val_loss: 0.4456 - val_accuracy: 0.8936\n",
      "Epoch 460/500\n",
      "127/127 [==============================] - 100s 789ms/step - loss: 0.2313 - accuracy: 0.9303 - val_loss: 0.3267 - val_accuracy: 0.9066\n",
      "Epoch 461/500\n",
      "127/127 [==============================] - 95s 749ms/step - loss: 0.2371 - accuracy: 0.9293 - val_loss: 0.3127 - val_accuracy: 0.9040\n",
      "Epoch 462/500\n",
      "127/127 [==============================] - 103s 812ms/step - loss: 0.2528 - accuracy: 0.9211 - val_loss: 0.2789 - val_accuracy: 0.9183\n",
      "Epoch 463/500\n",
      "127/127 [==============================] - 101s 796ms/step - loss: 0.2587 - accuracy: 0.9251 - val_loss: 0.2330 - val_accuracy: 0.9196\n",
      "Epoch 464/500\n",
      "127/127 [==============================] - 96s 758ms/step - loss: 0.2887 - accuracy: 0.9198 - val_loss: 0.3231 - val_accuracy: 0.9183\n",
      "Epoch 465/500\n",
      "127/127 [==============================] - 101s 792ms/step - loss: 0.2987 - accuracy: 0.9174 - val_loss: 0.3177 - val_accuracy: 0.9183\n",
      "Epoch 466/500\n",
      "127/127 [==============================] - 102s 802ms/step - loss: 0.2898 - accuracy: 0.9172 - val_loss: 0.5730 - val_accuracy: 0.8872\n",
      "Epoch 467/500\n",
      "127/127 [==============================] - 102s 800ms/step - loss: 0.2660 - accuracy: 0.9290 - val_loss: 0.2186 - val_accuracy: 0.9351\n",
      "Epoch 468/500\n",
      "127/127 [==============================] - 96s 755ms/step - loss: 0.2641 - accuracy: 0.9243 - val_loss: 0.2443 - val_accuracy: 0.9326\n",
      "Epoch 469/500\n",
      "127/127 [==============================] - 102s 801ms/step - loss: 0.2849 - accuracy: 0.9187 - val_loss: 0.2827 - val_accuracy: 0.9183\n",
      "Epoch 470/500\n",
      "127/127 [==============================] - 101s 795ms/step - loss: 0.2214 - accuracy: 0.9317 - val_loss: 0.2653 - val_accuracy: 0.9287\n",
      "Epoch 471/500\n",
      "127/127 [==============================] - 96s 759ms/step - loss: 0.2864 - accuracy: 0.9208 - val_loss: 0.2386 - val_accuracy: 0.9364\n",
      "Epoch 472/500\n",
      "127/127 [==============================] - 100s 786ms/step - loss: 0.1978 - accuracy: 0.9393 - val_loss: 0.2450 - val_accuracy: 0.9287\n",
      "Epoch 473/500\n",
      "127/127 [==============================] - 100s 791ms/step - loss: 0.3376 - accuracy: 0.9074 - val_loss: 0.2225 - val_accuracy: 0.9339\n",
      "Epoch 474/500\n",
      "127/127 [==============================] - 101s 798ms/step - loss: 0.2317 - accuracy: 0.9301 - val_loss: 0.3364 - val_accuracy: 0.9092\n",
      "Epoch 475/500\n",
      "127/127 [==============================] - 94s 742ms/step - loss: 0.2324 - accuracy: 0.9361 - val_loss: 0.2837 - val_accuracy: 0.9014\n",
      "Epoch 476/500\n",
      "127/127 [==============================] - 101s 796ms/step - loss: 0.2352 - accuracy: 0.9372 - val_loss: 0.2922 - val_accuracy: 0.9235\n",
      "Epoch 477/500\n",
      "127/127 [==============================] - 101s 797ms/step - loss: 0.2500 - accuracy: 0.9253 - val_loss: 0.3212 - val_accuracy: 0.8975\n",
      "Epoch 478/500\n",
      "127/127 [==============================] - 99s 776ms/step - loss: 0.2701 - accuracy: 0.9179 - val_loss: 0.3105 - val_accuracy: 0.9157\n",
      "Epoch 479/500\n",
      "127/127 [==============================] - 98s 772ms/step - loss: 0.2435 - accuracy: 0.9319 - val_loss: 0.2708 - val_accuracy: 0.9326\n",
      "Epoch 480/500\n",
      "127/127 [==============================] - 101s 798ms/step - loss: 0.2661 - accuracy: 0.9296 - val_loss: 0.2704 - val_accuracy: 0.9364\n",
      "Epoch 481/500\n",
      "127/127 [==============================] - 101s 793ms/step - loss: 0.2749 - accuracy: 0.9208 - val_loss: 0.2492 - val_accuracy: 0.9300\n",
      "Epoch 482/500\n",
      "127/127 [==============================] - 96s 758ms/step - loss: 0.2506 - accuracy: 0.9314 - val_loss: 0.3484 - val_accuracy: 0.9053\n",
      "Epoch 483/500\n",
      "127/127 [==============================] - 101s 793ms/step - loss: 0.1935 - accuracy: 0.9354 - val_loss: 0.2765 - val_accuracy: 0.9157\n",
      "Epoch 484/500\n",
      "127/127 [==============================] - 100s 784ms/step - loss: 0.2600 - accuracy: 0.9274 - val_loss: 0.2302 - val_accuracy: 0.9313\n",
      "Epoch 485/500\n",
      "127/127 [==============================] - 99s 779ms/step - loss: 0.2533 - accuracy: 0.9301 - val_loss: 0.2951 - val_accuracy: 0.9144\n",
      "Epoch 486/500\n",
      "127/127 [==============================] - 99s 777ms/step - loss: 0.2688 - accuracy: 0.9227 - val_loss: 0.3116 - val_accuracy: 0.9183\n",
      "Epoch 487/500\n",
      "127/127 [==============================] - 101s 798ms/step - loss: 0.2398 - accuracy: 0.9298 - val_loss: 0.3639 - val_accuracy: 0.9027\n",
      "Epoch 488/500\n",
      "127/127 [==============================] - 101s 798ms/step - loss: 0.2393 - accuracy: 0.9290 - val_loss: 0.2596 - val_accuracy: 0.9326\n",
      "Epoch 489/500\n",
      "127/127 [==============================] - 95s 752ms/step - loss: 0.2572 - accuracy: 0.9259 - val_loss: 0.3083 - val_accuracy: 0.9092\n",
      "Epoch 490/500\n",
      "127/127 [==============================] - 101s 794ms/step - loss: 0.2705 - accuracy: 0.9222 - val_loss: 0.2125 - val_accuracy: 0.9468\n",
      "Epoch 491/500\n",
      "127/127 [==============================] - 102s 800ms/step - loss: 0.2168 - accuracy: 0.9372 - val_loss: 0.3279 - val_accuracy: 0.9092\n",
      "Epoch 492/500\n",
      "127/127 [==============================] - 100s 784ms/step - loss: 0.2492 - accuracy: 0.9277 - val_loss: 0.3460 - val_accuracy: 0.9066\n",
      "Epoch 493/500\n",
      "127/127 [==============================] - 97s 763ms/step - loss: 0.2689 - accuracy: 0.9296 - val_loss: 0.3911 - val_accuracy: 0.9053\n",
      "Epoch 494/500\n",
      "127/127 [==============================] - 101s 797ms/step - loss: 0.2845 - accuracy: 0.9219 - val_loss: 0.3149 - val_accuracy: 0.9066\n",
      "Epoch 495/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 102s 803ms/step - loss: 0.3258 - accuracy: 0.9166 - val_loss: 0.3736 - val_accuracy: 0.9027\n",
      "Epoch 496/500\n",
      "127/127 [==============================] - 96s 754ms/step - loss: 0.2687 - accuracy: 0.9261 - val_loss: 0.3205 - val_accuracy: 0.9079\n",
      "Epoch 497/500\n",
      "127/127 [==============================] - 100s 789ms/step - loss: 0.2643 - accuracy: 0.9272 - val_loss: 0.2549 - val_accuracy: 0.9157\n",
      "Epoch 498/500\n",
      "127/127 [==============================] - 100s 787ms/step - loss: 0.2552 - accuracy: 0.9251 - val_loss: 0.2409 - val_accuracy: 0.9196\n",
      "Epoch 499/500\n",
      "127/127 [==============================] - 101s 794ms/step - loss: 0.2530 - accuracy: 0.9266 - val_loss: 0.2758 - val_accuracy: 0.9196\n",
      "Epoch 500/500\n",
      "127/127 [==============================] - 95s 752ms/step - loss: 0.2315 - accuracy: 0.9367 - val_loss: 0.3165 - val_accuracy: 0.9222\n"
     ]
    }
   ],
   "source": [
    "model2.compile(Adam(lr=.0002), loss='categorical_crossentropy', metrics= ['accuracy'])\n",
    "history2= model2.fit_generator(train_batches, steps_per_epoch= len(train_batches) , \n",
    "                             validation_data=test_batches, validation_steps= len(test_batches), \n",
    "                             epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_callback=tf.keras.callbacks.ModelCheckpoint(filepath=os.getcwd(),save_weights_only=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('model_2d6_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_json = model2.to_json()\n",
    "with open(\"model_2d6_final.json\", \"w\") as json_file:\n",
    "    json_file.write(model2_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/save-load-keras-deep-learning-models/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
